{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import os \n",
                "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(20, 7)\n"
                    ]
                }
            ],
            "source": [
                "import numpy as jnp\n",
                "\n",
                "n_el = 7\n",
                "def flatten(lol):\n",
                "    return [x for lst in lol for x in lst]\n",
                "\n",
                "kpoints = jnp.random.uniform(0, 1, (21, 3))\n",
                "inputs = jnp.random.uniform(0, 1, (n_el, 3))\n",
                "iterator = iter(kpoints[1:, :])\n",
                "rho_k = [[jnp.cos(inputs @ k1), jnp.sin(inputs @ k2)] for (k1, k2) in list(zip(iterator, iterator))]\n",
                "rho_k = flatten(rho_k)\n",
                "rho_k = jnp.array(rho_k)\n",
                "print(rho_k.shape)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "def f(r):\n",
                "    return [r**3, r**2, r, 1]\n",
                "\n",
                "def df(r):\n",
                "    return [3*r**2, 2*r, 1, 0]\n",
                "\n",
                "def u(r, A, F):\n",
                "    return (A / r) * (1 - np.exp(-r/F))\n",
                "\n",
                "def du(r, A, F):\n",
                "    return (- A / r**2) * (1 - np.exp(-r/F)) + (A/(r*F)) * np.exp(-r/F)\n",
                "\n",
                "r_boundary = 1/4\n",
                "r_edge = 1/2\n",
                "\n",
                "\n",
                "\n",
                "coefs = [f(r_boundary),\n",
                "     df(r_boundary),\n",
                "     f(r_edge),\n",
                "     df(r_boundary)]\n",
                "\n",
                "res = [[u(r_boundary)],\n",
                "     [du(r_boundary)],\n",
                "     [u(r_edge)],\n",
                "     [du(r_edge)]]\n",
                "\n",
                "np.inverse(coefs).dot(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy import curve_fit \n",
                "\n",
                "def fn(x):\n",
                "    return ((jnp.cos(2 * jnp.pi * x) * -1.) + 1.) / 4."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import jax\n",
                "import jax.random as rnd\n",
                "import jax.numpy as jnp\n",
                "from jax import vmap, jit, grad, pmap\n",
                "from jax.experimental.optimizers import adam\n",
                "from jax import tree_util\n",
                "from tqdm.notebook import trange\n",
                "\n",
                "from functools import partial\n",
                "\n",
                "from nn_ansatz import *"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "Error",
                    "evalue": "Session cannot generate requests",
                    "output_type": "error",
                    "traceback": [
                        "Error: Session cannot generate requests",
                        "at S.executeCodeCell (/home/amawi/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1001414422/out/client/extension.js:66:301742)",
                        "at S.execute (/home/amawi/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1001414422/out/client/extension.js:66:300732)",
                        "at S.start (/home/amawi/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1001414422/out/client/extension.js:66:296408)",
                        "at async t.CellExecutionQueue.executeQueuedCells (/home/amawi/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1001414422/out/client/extension.js:66:312326)",
                        "at async t.CellExecutionQueue.start (/home/amawi/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1001414422/out/client/extension.js:66:311862)"
                    ]
                }
            ],
            "source": [
                "x = [jnp.sin(1) for i in range(2)]\n",
                "y = jnp.concatenate([*x], axis=0)\n",
                "y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cell: \n",
                        " basis: \n",
                        " [[3.0836296 3.0836296 3.0836296]] \n",
                        " inv_basis: \n",
                        " [[0.32429317 0.32429317 0.32429317]] \n",
                        " scale_cell:  \n",
                        " 3.0836296752162995 \n",
                        " reciprocal_basis: \n",
                        " [[2.0375938 0.        0.       ]\n",
                        " [0.        2.0375938 0.       ]\n",
                        " [0.        0.        2.0375938]] \n",
                        " kappa            = 0.50 \n",
                        " volume           = 29.32 \n",
                        "\n",
                        "System: \n",
                        " n_atoms = 0 \n",
                        " n_up    = 7 \n",
                        " n_down  = 0 \n",
                        " n_el    = 7 \n",
                        "\n",
                        "Ansatz: \n",
                        " n_layers = 2 \n",
                        " n_det    = 4 \n",
                        " n_sh     = 64 \n",
                        " n_ph     = 32 \n",
                        "\n",
                        "creating wf\n",
                        "sampling no infs, this could take a while\n",
                        "end sampling no infs\n",
                        "kappa 0.250 || reciprocal_cut 1 || previous pe 100000000.0000000 || pe 0.0000001 || isclose False\n",
                        "kappa 0.250 || reciprocal_cut 2 || previous pe 0.0000001 || pe 0.0000001 || isclose True\n",
                        "kappa 0.250 || real_cut 1 || reciprocal_cut 2 || previous pe 100000000.0000000 || pe 35.2320099 || isclose False\n",
                        "kappa 0.250 || real_cut 2 || reciprocal_cut 2 || previous pe 35.2320099 || pe 39.6947784 || isclose False\n",
                        "kappa 0.250 || real_cut 3 || reciprocal_cut 2 || previous pe 39.6947784 || pe 39.8993073 || isclose False\n",
                        "kappa 0.250 || real_cut 4 || reciprocal_cut 2 || previous pe 39.8993073 || pe 39.9027786 || isclose False\n",
                        "kappa 0.250 || real_cut 5 || reciprocal_cut 2 || previous pe 39.9027786 || pe 39.9028015 || isclose False\n",
                        "kappa 0.250 || real_cut 6 || reciprocal_cut 2 || previous pe 39.9028015 || pe 39.9028015 || isclose True\n",
                        "kappa 0.750 || reciprocal_cut 1 || previous pe 100000000.0000000 || pe 0.4132525 || isclose False\n",
                        "kappa 0.750 || reciprocal_cut 2 || previous pe 0.4132525 || pe 0.4137761 || isclose False\n",
                        "kappa 0.750 || reciprocal_cut 3 || previous pe 0.4137761 || pe 0.4137762 || isclose True\n",
                        "kappa 0.750 || real_cut 1 || reciprocal_cut 3 || previous pe 100000000.0000000 || pe 4.1302147 || isclose False\n",
                        "kappa 0.750 || real_cut 2 || reciprocal_cut 3 || previous pe 4.1302147 || pe 4.1303482 || isclose False\n",
                        "kappa 0.750 || real_cut 3 || reciprocal_cut 3 || previous pe 4.1303482 || pe 4.1303482 || isclose True\n",
                        "Taking kappa 0.750, real cut 2, and reciprocal cut 2\n",
                        "step 0 energy 3.1914\n",
                        "step 100 energy 1.1531\n",
                        "kappa 0.250 || reciprocal_cut 1 || previous pe 100000000.0000000 || pe 0.0000001 || isclose False\n",
                        "kappa 0.250 || reciprocal_cut 2 || previous pe 0.0000001 || pe 0.0000001 || isclose True\n",
                        "kappa 0.250 || real_cut 1 || reciprocal_cut 2 || previous pe 100000000.0000000 || pe 35.2320099 || isclose False\n",
                        "kappa 0.250 || real_cut 2 || reciprocal_cut 2 || previous pe 35.2320099 || pe 39.6947784 || isclose False\n",
                        "kappa 0.250 || real_cut 3 || reciprocal_cut 2 || previous pe 39.6947784 || pe 39.8993073 || isclose False\n",
                        "kappa 0.250 || real_cut 4 || reciprocal_cut 2 || previous pe 39.8993073 || pe 39.9027786 || isclose False\n",
                        "kappa 0.250 || real_cut 5 || reciprocal_cut 2 || previous pe 39.9027786 || pe 39.9028015 || isclose False\n",
                        "kappa 0.250 || real_cut 6 || reciprocal_cut 2 || previous pe 39.9028015 || pe 39.9028015 || isclose True\n",
                        "kappa 0.750 || reciprocal_cut 1 || previous pe 100000000.0000000 || pe 0.4132525 || isclose False\n",
                        "kappa 0.750 || reciprocal_cut 2 || previous pe 0.4132525 || pe 0.4137761 || isclose False\n",
                        "kappa 0.750 || reciprocal_cut 3 || previous pe 0.4137761 || pe 0.4137762 || isclose True\n",
                        "kappa 0.750 || real_cut 1 || reciprocal_cut 3 || previous pe 100000000.0000000 || pe 4.1302147 || isclose False\n",
                        "kappa 0.750 || real_cut 2 || reciprocal_cut 3 || previous pe 4.1302147 || pe 4.1303482 || isclose False\n",
                        "kappa 0.750 || real_cut 3 || reciprocal_cut 3 || previous pe 4.1303482 || pe 4.1303482 || isclose True\n",
                        "Taking kappa 0.750, real cut 2, and reciprocal cut 2\n",
                        "[12.421867  12.44177   12.477533  12.436006  12.397021  12.435419\n",
                        " 12.464715  12.466223  12.475363  12.447179  12.4309225 12.456038\n",
                        " 12.444603  12.488239  12.441434  12.437525  12.459573  12.461916\n",
                        " 12.480272  12.45999   12.448635  12.466087  12.43449   12.442947\n",
                        " 12.474627  12.4620075 12.439163  12.479377  12.472317  12.465092\n",
                        " 12.460747  12.453817  12.465593  12.470759  12.461512  12.447901\n",
                        " 12.412499  12.458053  12.442763  12.471678  12.458722  12.479443\n",
                        " 12.440208  12.491982  12.459401  12.449124  12.433397  12.454619\n",
                        " 12.480737  12.440405  12.445164  12.459515  12.459101  12.457774\n",
                        " 12.445518  12.461448  12.465314  12.477576  12.419964  12.439357\n",
                        " 12.444927  12.453905  12.462144  12.457628  12.469214  12.44087\n",
                        " 12.442601  12.441044  12.478268  12.482895  12.441748  12.470231\n",
                        " 12.440519  12.438564  12.449612  12.408102  12.443772  12.472229\n",
                        " 12.510937  12.469209  12.451275  12.534251  12.450389  12.472015\n",
                        " 12.443514  12.451465  12.452662  12.470316  12.44741   12.490316\n",
                        " 12.457686  12.47134   12.45256   12.386312  12.454225  12.428934\n",
                        " 12.441742  12.47576   12.407223  12.444642  12.469486  12.464645\n",
                        " 12.444281  12.458079  12.407614  12.426512  12.449441  12.453073\n",
                        " 12.443011  12.481401  12.454861  12.440431  12.455841  12.476748\n",
                        " 12.464934  12.462724  12.486607  12.448485  12.448725  12.411706\n",
                        " 12.416058  12.444019  12.449273  12.461996  12.445993  12.402306\n",
                        " 12.430523  12.420109  12.434401  12.449995  12.449339  12.487988\n",
                        " 12.458633  12.475186  12.444175  12.481299  12.437901  12.569238\n",
                        " 12.485144  12.429641  12.461451  12.436906  12.457603  12.450727\n",
                        " 12.441809  12.490583  12.441694  12.4496975 12.43162   12.441312\n",
                        " 12.455128  12.470908  12.452918  12.451089  12.429198  12.468759\n",
                        " 12.434073  12.429066  12.462057  12.446375  12.455911  12.444594\n",
                        " 12.445399  12.443966  12.459294  12.472554  12.433652  12.440932\n",
                        " 12.441264  12.416347  12.431056  12.453203  12.46879   12.501395\n",
                        " 12.45566   12.459401  12.4308605 12.451035  12.452577  12.452517\n",
                        " 12.448387  12.4601965 12.450202  12.455276  12.440889  12.439312\n",
                        " 12.427364  12.454803  12.477842  12.449669  12.461431  12.486847\n",
                        " 12.456925  12.462625  12.422117  12.460757  12.453247  12.452607\n",
                        " 12.468284  12.459817  12.473749  12.483219  12.488339  12.474343\n",
                        " 12.463561  12.4635935 12.4446335 12.479821  12.450624  12.462824\n",
                        " 12.44012   12.461649  12.450362  12.463892  12.431225  12.447397\n",
                        " 12.435882  12.465857  12.45556   12.497231  12.423677  12.430485\n",
                        " 12.441778  12.486881  12.417654  12.467947  12.459572  12.433761\n",
                        " 12.491508  12.455378  12.437075  12.451463  12.443969  12.460011\n",
                        " 12.447781  12.453655  12.473756  12.485605  12.451104  12.4827\n",
                        " 12.4557495 12.49269   12.450939  12.441633  12.455662  12.45231\n",
                        " 12.449245  12.461373  12.468999  12.463385  12.443811  12.468056\n",
                        " 12.431068  12.441579  12.481675  12.400058  12.453037  12.446396\n",
                        " 12.440316  12.413761  12.45238   12.456482  12.439974  12.464402\n",
                        " 12.441449  12.456981  12.452964  12.427619  12.443743  12.445282\n",
                        " 12.487925  12.451025  12.456173  12.47418   12.385629  12.485288\n",
                        " 12.476117  12.445396  12.458962  12.467964  12.442104  12.407861\n",
                        " 12.425481  12.468838  12.452884  12.458326  12.460566  12.445864\n",
                        " 12.439992  12.456077  12.454429  12.402628  12.463668  12.451952\n",
                        " 12.458546  12.46634   12.457946  12.440606  12.448117  12.461678\n",
                        " 12.479054  12.498003  12.478371  12.463035  12.418358  12.375672\n",
                        " 12.449619  12.467464  12.458103  12.424109  12.437947  12.439375\n",
                        " 12.405642  12.439417  12.439366  12.442291  12.468617  12.461293\n",
                        " 12.465752  12.459459  12.482106  12.451606  12.435578  12.439451\n",
                        " 12.447083  12.463349  12.45821   12.462028  12.404673  12.478713\n",
                        " 12.424597  12.465629  12.462167  12.45697   12.44659   12.446445\n",
                        " 12.447721  12.455784  12.457815  12.434801  12.472911  12.479106\n",
                        " 12.434439  12.473349  12.462385  12.441591  12.44872   12.424762\n",
                        " 12.4499855 12.430517  12.47225   12.4395    12.453223  12.472283\n",
                        " 12.448568  12.463669  12.479688  12.456706  12.436654  12.407\n",
                        " 12.45485   12.4769745 12.451073  12.463764  12.492381  12.447391\n",
                        " 12.455381  12.445351  12.450265  12.454505  12.438699  12.470837\n",
                        " 12.496136  12.468984  12.473797  12.440573  12.478261  12.436055\n",
                        " 12.461657  12.427133  12.483557  12.481377  12.46012   12.469022\n",
                        " 12.434699  12.41418   12.461074  12.46041   12.439526  12.462516\n",
                        " 12.46935   12.4275675 12.481627  12.466788  12.468107  12.414758\n",
                        " 12.446821  12.479926  12.443457  12.455429  12.441573  12.434236\n",
                        " 12.473231  12.439667  12.500638  12.492112  12.475716  12.465731\n",
                        " 12.449263  12.403655  12.476277  12.456176  12.473467  12.492992\n",
                        " 12.439312  12.504921  12.439032  12.436941  12.486385  12.445849\n",
                        " 12.454578  12.454403  12.4642    12.462321  12.437937  12.459029\n",
                        " 12.472438  12.444058  12.508013  12.391927  12.47066   12.452728\n",
                        " 12.477852  12.463629  12.448419  12.455836  12.451367  12.480962\n",
                        " 12.447688  12.463751  12.46431   12.471264  12.458809  12.444564\n",
                        " 12.4556875 12.475439  12.441618  12.44213   12.469867  12.44357\n",
                        " 12.447271  12.455321  12.464297  12.452798  12.452541  12.445141\n",
                        " 12.448132  12.480496  12.442501  12.456176  12.467158  12.445951\n",
                        " 12.470282  12.45447   12.447174  12.438764  12.463405  12.459065\n",
                        " 12.469671  12.444223  12.443624  12.440942  12.455807  12.4504385\n",
                        " 12.446409  12.528422  12.45177   12.459483  12.56781   12.43142\n",
                        " 12.428557  12.464662  12.441132  12.44176   12.446635  12.4275055\n",
                        " 12.449265  12.478062  12.439228  12.439595  12.452821  12.458009\n",
                        " 12.456485  12.449211  12.412449  12.489085  12.479821  12.477557\n",
                        " 12.402789  12.450973  12.429604  12.444206  12.469249  12.461684\n",
                        " 12.456371  12.443207  12.474843  12.501584  12.46243   12.451567\n",
                        " 12.415487  12.472823 ]\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "\n",
                "cfg = setup(system='HEG',\n",
                "                    n_pre_it=10,\n",
                "                    pretrain=False,\n",
                "                    n_walkers=512,\n",
                "                    n_layers=2,\n",
                "                    n_sh=64,\n",
                "                    step_size=0.05,\n",
                "                    n_ph=16,\n",
                "                    n_el=7,\n",
                "                    orbitals='real_plane_waves',\n",
                "                    simulation_cell=(1, 1, 1),\n",
                "                    density_parameter=1., \n",
                "                    opt='kfac',\n",
                "                    n_det=1,\n",
                "                    print_every=10,\n",
                "                    save_every=2500,\n",
                "                    lr=1e-3,\n",
                "                    n_it=10000,\n",
                "                    name='junk')\n",
                "\n",
                "walkers = None\n",
                "\n",
                "mol, vwf, walkers, params, sampler, keys = initialise_system_wf_and_sampler(cfg, walkers)\n",
                "\n",
                "walkers = equilibrate(params, walkers, keys, mol=mol, vwf=vwf, sampler=sampler, compute_energy=True, n_it=200)\n",
                "energy_function = create_energy_fn(mol, vwf, separate=True)\n",
                "\n",
                "if bool(os.environ.get('DISTRIBUTE')) is True:\n",
                "    energy_function = pmap(energy_function, in_axes=(None, 0))\n",
                "\n",
                "local_kinetic_energy = create_local_kinetic_energy(vwf)\n",
                "if bool(os.environ.get('DISTRIBUTE')) is True:\n",
                "    local_kinetic_energy = pmap(local_kinetic_energy, in_axes=(None, 0))\n",
                "\n",
                "ke = local_kinetic_energy(params, walkers)\n",
                "print(ke)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "creating wf\n"
                    ]
                }
            ],
            "source": [
                "cfg = setup(system='HEG',\n",
                "                    n_pre_it=10,\n",
                "                    jastrow=True,\n",
                "                    pretrain=False,\n",
                "                    n_walkers=512,\n",
                "                    n_layers=2,\n",
                "                    n_sh=64,\n",
                "                    step_size=0.05,\n",
                "                    n_ph=16,\n",
                "                    n_el=7,\n",
                "                    orbitals='real_plane_waves',\n",
                "                    simulation_cell=(1, 1, 1),\n",
                "                    density_parameter=1., \n",
                "                    opt='kfac',\n",
                "                    n_det=1,\n",
                "                    print_every=10,\n",
                "                    save_every=2500,\n",
                "                    lr=1e-3,\n",
                "                    n_it=10000,\n",
                "                    name='junk')\n",
                "mol, vwf, walkers, params, sampler, keys = initialise_system_wf_and_sampler(cfg, walkers)\n",
                "swf = create_wf(mol, signed=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "5.8206024 5.823107 -1.0 1.0\n",
                        "[[ 0.          0.          0.        ]\n",
                        " [-0.48445106 -2.9283144   1.6237472 ]\n",
                        " [ 0.          0.          0.        ]\n",
                        " [ 0.          0.          0.        ]\n",
                        " [ 0.          0.          0.        ]\n",
                        " [ 0.48445106  2.9283144  -1.6237472 ]\n",
                        " [ 0.          0.          0.        ]]\n",
                        "[0.99956995 1.0004404  0.99970305 0.9999225  1.0007887  1.0011865\n",
                        " 1.000126   1.0000138  1.0003499  0.9997377  1.0001544  0.99982363\n",
                        " 0.9994917  0.99955195 0.99939054 1.0004374  0.99943644 1.0001827\n",
                        " 0.9999601  0.9997928  1.0001702  1.00054    1.0000774  0.9995893\n",
                        " 1.0032189  0.99995685 0.9998985  0.9987163  0.9990638  1.0006207\n",
                        " 1.0018669  1.0000327  1.0001091  0.9987996  1.0002587  0.9996086\n",
                        " 1.0000695  1.0003542  0.9992015  0.9997097  1.000418   1.0001761\n",
                        " 0.99884343 1.000611   0.9996799  1.0001367  1.0004418  1.0000947\n",
                        " 0.99980825 1.0000958  1.0000376  1.0001705  0.9993744  1.000228\n",
                        " 0.99981713 1.0001215  0.9999779  1.0009571  1.0000376  0.9997661\n",
                        " 1.0004642  1.0011065  1.0006057  0.99962544 1.0010338  0.9997163\n",
                        " 1.000109   0.99969566 1.0005405  1.0013442  0.9991672  1.0029433\n",
                        " 0.9999958  1.0022762  1.0001566  1.000002   0.9999     1.0002533\n",
                        " 0.9994143  1.0014923  1.0002738  1.0044838  0.99964976 1.0003308\n",
                        " 1.0000437  1.0001223  0.9999133  1.0000808  1.0003444  0.99813914\n",
                        " 0.9997067  1.0007039  0.9998137  0.99963313 0.9997626  0.9995698\n",
                        " 1.0000563  0.9990554  0.9995739  0.9998131  1.0000725  0.9999169\n",
                        " 1.0001929  1.0000532  1.0009067  1.0015444  0.9996173  1.0000017\n",
                        " 0.9998828  1.0002223  0.99936646 0.99981475 1.000049   0.9988382\n",
                        " 1.0000557  0.99962056 1.0002043  1.0005766  1.0001649  1.0001699\n",
                        " 0.9991486  1.000125   0.9996537  0.99985564 0.9998092  1.0014665\n",
                        " 0.9988832  0.9993942  0.9980766  0.9999982  0.99959934 0.9996644\n",
                        " 1.0000582  0.9997462  0.99968    0.99992955 1.0003395  1.000813\n",
                        " 1.0003241  0.9997578  1.0000136  1.0000845  1.0004233  0.9989478\n",
                        " 0.999867   1.0001994  0.9995934  1.0002435  0.9987043  1.0001781\n",
                        " 0.99970573 0.99904794 1.0001026  1.0002244  0.9997901  1.0006988\n",
                        " 0.9998306  0.9996837  1.0001143  1.0000156  0.9990103  1.000415\n",
                        " 0.99981683 1.0005333  0.99932384 0.999744   0.9998766  0.9991596\n",
                        " 0.99958897 0.999309   0.999916   1.0001465  0.9998431  1.0000077\n",
                        " 1.0000985  0.99970514 0.99987334 0.9997461  0.9996398  0.99995965\n",
                        " 1.000643   0.9990092  0.9997015  1.0003608  0.999821   1.0001574\n",
                        " 1.000435   1.0007511  0.9997734  1.0000278  0.99996924 1.000401\n",
                        " 0.99962676 1.0003779  1.0001768  0.99983853 1.000112   1.0003344\n",
                        " 0.99985063 0.99782544 1.0003437  0.9999352  0.99878377 1.0004878\n",
                        " 0.999021   1.0001794  1.0001206  0.999562   0.9998913  0.9979722\n",
                        " 0.9995486  0.999534   1.0002686  0.99980503 1.0008414  0.99997556\n",
                        " 0.9998169  1.0021765  1.0000684  1.0003695  0.9998337  0.9996661\n",
                        " 1.000341   1.0013314  0.99994105 0.99949986 1.0000281  0.9994426\n",
                        " 0.9997189  1.0001155  0.99997413 1.0001708  0.999997   0.9998309\n",
                        " 0.9996202  0.99939203 1.0001863  1.0000832  1.0008346  1.0007665\n",
                        " 0.99984646 1.0014462  1.001148   0.9999748  0.9996653  0.9997656\n",
                        " 0.9992321  1.0012305  1.000077   1.0010133  0.9996597  1.0020267\n",
                        " 0.99959457 0.99913853 0.99969876 0.9993665  0.9999658  1.0002517\n",
                        " 0.99988973 0.9986805  0.999423   0.9993757  0.9996802  0.99997085\n",
                        " 0.9998733  0.999767   0.9998866  1.002278   0.99992794 1.0002513\n",
                        " 0.9999075  0.99982256 1.0008018  1.0000561  1.0002606  0.99927956\n",
                        " 1.0018402  0.9996692  1.000064   1.0001266  1.001504   0.9994276\n",
                        " 0.9998732  0.99992144 1.000272   0.99948335 1.0002584  0.9999837\n",
                        " 0.9993775  0.9998276  0.99946445 1.0005589  1.0003209  1.0001878\n",
                        " 0.9997432  0.9999789  0.9993292  1.0000337  0.999861   0.99978054\n",
                        " 0.998939   1.0007987  1.000547   0.999112   0.99823064 0.9991749\n",
                        " 1.0000434  0.9998268  0.99967074 1.0000273  0.99983275 0.9999372\n",
                        " 0.9984691  0.99868995 0.9999802  1.0002325  1.0001519  0.9996079\n",
                        " 0.9999272  0.9989498  0.99960005 1.0003477  0.9995616  0.99946415\n",
                        " 1.0005388  1.0011544  0.9991713  0.99999166 1.0008013  1.000007\n",
                        " 1.0008832  0.9999307  0.9991267  0.9999883  0.9996043  1.0000395\n",
                        " 1.0004718  1.0000489  0.999748   0.99992776 1.0002458  1.0014977\n",
                        " 0.99971473 1.0004555  1.0013332  0.9997816  0.99934673 1.0005113\n",
                        " 1.0000526  0.9960288  0.99874717 1.0001168  1.000655   0.999801\n",
                        " 1.0002882  1.0002369  1.0005456  0.9998552  0.9991781  0.99992335\n",
                        " 1.0000048  1.0025635  1.0002735  1.0005889  1.0003268  0.9994857\n",
                        " 1.0001082  0.9997317  0.9992388  1.0009263  0.9990158  1.0001616\n",
                        " 1.0009379  1.0002444  0.9998489  0.9997271  1.000941   0.9999588\n",
                        " 0.9993785  0.9994602  0.99965227 0.99926406 1.0001429  1.0001632\n",
                        " 0.9977783  0.9999635  1.0004104  0.9998378  0.99933743 0.9993979\n",
                        " 0.9996422  0.9998172  0.9999343  1.0007602  1.0000486  0.99855214\n",
                        " 1.0011512  0.99999976 1.0005572  0.9986042  0.9997924  0.9990109\n",
                        " 1.001313   0.99993265 1.0003854  1.0003622  0.99881804 1.0002414\n",
                        " 0.99956036 1.0000594  1.00013    0.9998196  1.0002775  0.9987844\n",
                        " 0.9994681  0.9987303  1.0000387  1.0000875  0.99927753 0.9993566\n",
                        " 0.999738   0.9994482  0.99954134 1.0006865  1.0000615  1.0002354\n",
                        " 0.9997061  0.99983835 0.9990285  0.99762344 0.9996361  0.998829\n",
                        " 1.0001092  1.0009305  0.999663   0.99972045 1.0000023  0.9999525\n",
                        " 1.0003453  0.99959254 1.0001972  1.0000577  1.0000043  1.0007102\n",
                        " 0.99903136 1.0019832  1.0000145  0.9996794  1.0005804  1.0000533\n",
                        " 0.9999371  0.99976325 0.9997125  0.99962693 1.0003326  0.99931955\n",
                        " 0.9999905  0.99947697 0.9999053  1.0001202  0.9999597  1.0009043\n",
                        " 1.0002261  1.0008445  1.0004609  1.0004668  0.9998543  1.00016\n",
                        " 1.0006735  1.000891   0.9997866  1.0000076  1.0004848  0.9999548\n",
                        " 1.0001025  1.000259   0.99995166 1.0000381  1.005085   1.0006715\n",
                        " 0.9994959  0.99952555 1.0000035  0.9995418  1.0002112  0.9999783\n",
                        " 1.0001267  0.9996015  0.9995971  0.99998266 0.99985254 0.9996307\n",
                        " 0.99993867 0.9994974  0.999476   1.0006145  1.0002452  1.0006064\n",
                        " 0.99937814 0.99956363 0.9991504  0.9987671  0.9998768  1.000219\n",
                        " 0.99982417 0.99937654 1.0004985  0.9998218  1.0003386  1.0001919\n",
                        " 0.9996782  0.99996275]\n"
                    ]
                }
            ],
            "source": [
                "log_psi, sign = swf(params, walkers)\n",
                "new_walkers = jnp.array(np.array(walkers)[:, [0, 5, 2, 3, 4, 1, 6], :])\n",
                "log_psi_sim, sign_sim = swf(params, new_walkers)\n",
                "\n",
                "# print(log_psi / log_psi_sim, sign / sign_sim)\n",
                "\n",
                "print(log_psi[0], log_psi_sim[0], sign[0], sign_sim[0])\n",
                "\n",
                "print((walkers - new_walkers)[0])\n",
                "\n",
                "print(log_psi / log_psi_sim)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "version \t\t 091121\n",
                        "seed \t\t 369\n",
                        "n_devices \t\t 1\n",
                        "save_every \t\t 5000\n",
                        "print_every \t\t 1000\n",
                        "exp_dir \t\t /home/amawi/projects/nn_ansatz/src/experiments/HSolid/sim_test/kfac_1lr-4_1d-3_1nc-4_m512_s64_p32_l2_det4/run0\n",
                        "events_dir \t\t /home/amawi/projects/nn_ansatz/src/experiments/HSolid/sim_test/kfac_1lr-4_1d-3_1nc-4_m512_s64_p32_l2_det4/run0/events\n",
                        "models_dir \t\t /home/amawi/projects/nn_ansatz/src/experiments/HSolid/sim_test/kfac_1lr-4_1d-3_1nc-4_m512_s64_p32_l2_det4/run0/models\n",
                        "opt_state_dir \t\t /home/amawi/projects/nn_ansatz/src/experiments/HSolid/sim_test/kfac_1lr-4_1d-3_1nc-4_m512_s64_p32_l2_det4/run0/models/opt_state\n",
                        "pre_path \t\t /home/amawi/projects/nn_ansatz/src/experiments/HSolid/pretrained/s64_p32_l2_det4_1lr-4_i0.pk\n",
                        "timing_dir \t\t /home/amawi/projects/nn_ansatz/src/experiments/HSolid/sim_test/kfac_1lr-4_1d-3_1nc-4_m512_s64_p32_l2_det4/run0/events/timing\n",
                        "csv_cfg_path \t\t /home/amawi/projects/nn_ansatz/src/experiments/HSolid/sim_test/kfac_1lr-4_1d-3_1nc-4_m512_s64_p32_l2_det4/run0/config1.csv\n",
                        "pk_cfg_path \t\t /home/amawi/projects/nn_ansatz/src/experiments/HSolid/sim_test/kfac_1lr-4_1d-3_1nc-4_m512_s64_p32_l2_det4/run0/config1.pk\n",
                        "pbc \t\t True\n",
                        "atoms_from_unit_cell \t\t True\n",
                        "basis \t\t [[1. 0. 0.]\n",
                        " [0. 1. 0.]\n",
                        " [0. 0. 1.]]\n",
                        "scale_cell \t\t 1.0\n",
                        "r_atoms \t\t [[0.5 0.5 0.5]]\n",
                        "z_atoms \t\t [1.]\n",
                        "n_el_atoms \t\t [1]\n",
                        "n_el \t\t 1\n",
                        "system \t\t HSolid\n",
                        "real_cut \t\t 6\n",
                        "reciprocal_cut \t\t 6\n",
                        "kappa \t\t 0.5\n",
                        "simulation_cell \t\t (2, 1, 1)\n",
                        "n_layers \t\t 2\n",
                        "n_sh \t\t 64\n",
                        "n_ph \t\t 32\n",
                        "n_det \t\t 4\n",
                        "scalar_inputs \t\t False\n",
                        "n_periodic_input \t\t 1\n",
                        "orbitals \t\t anisotropic\n",
                        "einsum \t\t False\n",
                        "nonlinearity \t\t tanh\n",
                        "input_activation_nonlinearity \t\t sin\n",
                        "opt \t\t kfac\n",
                        "lr \t\t 0.0001\n",
                        "damping \t\t 0.001\n",
                        "norm_constraint \t\t 0.0001\n",
                        "n_it \t\t 30000\n",
                        "load_it \t\t 0\n",
                        "n_walkers \t\t 512\n",
                        "n_walkers_per_device \t\t 512\n",
                        "step_size \t\t 0.05\n",
                        "correlation_length \t\t 10\n",
                        "pre_lr \t\t 0.0001\n",
                        "n_pre_it \t\t 0\n",
                        "load_pretrain \t\t False\n",
                        "pretrain \t\t False\n",
                        "Cell: \n",
                        " basis: \n",
                        " [[2. 1. 1.]] \n",
                        " inv_basis: \n",
                        " [[0.5 1.  1. ]] \n",
                        " reciprocal_basis: \n",
                        " [[3.1415927 0.        0.       ]\n",
                        " [0.        6.2831855 0.       ]\n",
                        " [0.        0.        6.2831855]] \n",
                        " real_cut         = 6.00 \n",
                        " reciprocal_cut   = 6 \n",
                        " kappa            = 0.50 \n",
                        " volume           = 2.00 \n",
                        " n_periodic_input = 1 \n",
                        "\n",
                        "System: \n",
                        " n_atoms = 2 \n",
                        " n_up    = 1 \n",
                        " n_down  = 1 \n",
                        " n_el    = 2 \n",
                        "\n",
                        "Ansatz: \n",
                        " n_layers = 2 \n",
                        " n_det    = 4 \n",
                        " n_sh     = 64 \n",
                        " n_ph     = 32 \n",
                        "\n",
                        "creating wf\n",
                        "sampling no infs, this could take a while\n",
                        "end sampling no infs\n",
                        "creating wf\n",
                        "step 1000 | e_mean -4.7029 | e_std 1.9401 | e_mean_mean -4.6438 | acceptance 0.4895 | t_per_it 0.0282 |\n",
                        "step 2000 | e_mean -4.5546 | e_std 1.6824 | e_mean_mean -4.6423 | acceptance 0.5098 | t_per_it 0.0287 |\n",
                        "step 3000 | e_mean -4.5927 | e_std 1.7843 | e_mean_mean -4.6340 | acceptance 0.5035 | t_per_it 0.0287 |\n",
                        "step 4000 | e_mean -4.6399 | e_std 1.8298 | e_mean_mean -4.6299 | acceptance 0.5191 | t_per_it 0.0287 |\n",
                        "step 5000 | e_mean -4.4659 | e_std 1.7820 | e_mean_mean -4.6354 | acceptance 0.4869 | t_per_it 0.0287 |\n",
                        "step 6000 | e_mean -4.7278 | e_std 2.8517 | e_mean_mean -4.6335 | acceptance 0.4980 | t_per_it 0.0289 |\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-3-ff5cea2460e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     name='sim_test')\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_vmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# walkers, grads, pe, ke, probs = run_vmc_debug(cfg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/projects/nn_ansatz/src/nn_ansatz/routines.py\u001b[0m in \u001b[0;36mrun_vmc\u001b[0;34m(cfg, walkers)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{jnp.mean(e_locs):.6f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m   return lax.div(\n\u001b[0;32m-> 2221\u001b[0;31m       \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2222\u001b[0m       lax.convert_element_type(normalizer, dtype))\n\u001b[1;32m   2223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     \u001b[0mbool_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_or\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcast_f16_for_computation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                     initial=initial, where_=where, parallel_reduce=lax.psum)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_reduction\u001b[0;34m(a, name, np_fun, op, init_val, has_identity, preproc, bool_op, upcast_f16_for_computation, axis, dtype, out, keepdims, initial, where_, parallel_reduce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minitial\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_reduction_init_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(operands, init_values, computation, dimensions)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     raise ValueError('Must have same total number of operands as init_values: '\n\u001b[1;32m   1271\u001b[0m                      f' {len(flat_operands)} vs. {len(flat_init_values)}')\n\u001b[0;32m-> 1272\u001b[0;31m   \u001b[0mmonoid_reducer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_monoid_reducer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_init_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmonoid_reducer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[0;31m# monoid reducers bypass the weak_type_rule, so we set it explicitly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_get_monoid_reducer\u001b[0;34m(monoid_op, xs)\u001b[0m\n\u001b[1;32m   1316\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mConcreteArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmonoid_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_reduce_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmonoid_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mmul\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_reduce_prod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "cfg = setup(system='HSolid',\n",
                "                    n_walkers=512,\n",
                "                    n_layers=2,\n",
                "                    n_sh=64,\n",
                "                    n_ph=32,\n",
                "                    orbitals='anisotropic',\n",
                "                    simulation_cell=(2, 1, 1),\n",
                "                    opt='kfac',\n",
                "                    n_det=4,\n",
                "                    n_it=30000,\n",
                "                    name='sim_test')\n",
                "\n",
                "log = run_vmc(cfg)\n",
                "# walkers, grads, pe, ke, probs = run_vmc_debug(cfg)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cell: \n",
                        " basis: \n",
                        " [[2. 1. 1.]] \n",
                        " inv_basis: \n",
                        " [[0.5 1.  1. ]] \n",
                        " reciprocal_basis: \n",
                        " [[3.1415927 0.        0.       ]\n",
                        " [0.        6.2831855 0.       ]\n",
                        " [0.        0.        6.2831855]] \n",
                        " real_cut         = 6.00 \n",
                        " reciprocal_cut   = 6 \n",
                        " kappa            = 0.50 \n",
                        " volume           = 2.00 \n",
                        " n_periodic_input = 1 \n",
                        "\n",
                        "System: \n",
                        " n_atoms = 2 \n",
                        " n_up    = 1 \n",
                        " n_down  = 1 \n",
                        " n_el    = 2 \n",
                        "\n",
                        "Ansatz: \n",
                        " n_layers = 2 \n",
                        " n_det    = 2 \n",
                        " n_sh     = 32 \n",
                        " n_ph     = 16 \n",
                        "\n",
                        "creating wf\n",
                        "creating wf\n"
                    ]
                }
            ],
            "source": [
                "mol, vwf, walkers, params, sampler, keys = initialise_system_wf_and_sampler(cfg, walkers)\n",
                "pwf = pmap(vwf, in_axes=(None, 0))\n",
                "owf = pmap(create_wf(mol, orbitals=True), in_axes=(None, 0))\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[[[[0.        ]]\n",
                        "\n",
                        "   [[0.        ]]]\n",
                        "\n",
                        "\n",
                        "  [[[0.40252614]]\n",
                        "\n",
                        "   [[0.7156686 ]]]]]\n"
                    ]
                }
            ],
            "source": [
                "walkers_tmp = walkers[:, idxs]\n",
                "orb_up, orb_down = owf(params, walkers_tmp)\n",
                "\n",
                "if orb_up.shape[-1] == 1:\n",
                "    s_up, log_up = (jnp.sign(jnp.abs(orb_up)).squeeze(), jnp.log(jnp.abs(orb_up)).squeeze())\n",
                "else: \n",
                "    s_up, log_up = jnp.linalg.slogdet(orb_up)\n",
                "\n",
                "if orb_down is None:\n",
                "    s_down, log_down = (jnp.ones_like(s_up), jnp.zeros_like(log_up))\n",
                "else:\n",
                "    if orb_down.shape[-1] == 1:\n",
                "        s_down, log_down = (jnp.sign(jnp.abs(orb_down)).squeeze(), jnp.log(jnp.abs(orb_down)).squeeze())\n",
                "    else:\n",
                "        s_down, log_down = jnp.linalg.slogdet(orb_down)\n",
                "\n",
                "logdet_sum = log_up + log_down\n",
                "logdet_max = jnp.max(logdet_sum)\n",
                "\n",
                "argument = s_up * s_down * jnp.exp(logdet_sum - logdet_max)\n",
                "sum_argument = jnp.sum(argument, axis=1)\n",
                "sign = jnp.sign(sum_argument)\n",
                "\n",
                "log_psi = jnp.log(jnp.abs(sum_argument)) + logdet_max\n",
                "print(orb_up)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "True\n",
                        "True\n",
                        "(1, 2, 2, 3)\n",
                        "[[nan nan]]\n"
                    ]
                }
            ],
            "source": [
                "logpsi = pwf(params, walkers)\n",
                "print(check_inf_nan(logpsi))\n",
                "print(check_inf_nan(probs))\n",
                "idxs =  jnp.where(jnp.isnan(probs))[1]\n",
                "print(walkers_tmp.shape)\n",
                "logpsi = pwf(params, walkers_tmp)\n",
                "print(logpsi)\n",
                "# print(probs)\n",
                "# print(walkers)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "version \t\t 100921\n",
                        "seed \t\t 369\n",
                        "n_devices \t\t 1\n",
                        "save_every \t\t 5000\n",
                        "print_every \t\t 100\n",
                        "exp_dir \t\t /home/amawi/projects/nn_ansatz/src/experiments/LiSolidBCC/100921/isotropic/adam_1lr-4_1d-3_1nc-4_m256_s32_p8_l2_det2/run0\n",
                        "events_dir \t\t /home/amawi/projects/nn_ansatz/src/experiments/LiSolidBCC/100921/isotropic/adam_1lr-4_1d-3_1nc-4_m256_s32_p8_l2_det2/run0/events\n",
                        "models_dir \t\t /home/amawi/projects/nn_ansatz/src/experiments/LiSolidBCC/100921/isotropic/adam_1lr-4_1d-3_1nc-4_m256_s32_p8_l2_det2/run0/models\n",
                        "opt_state_dir \t\t /home/amawi/projects/nn_ansatz/src/experiments/LiSolidBCC/100921/isotropic/adam_1lr-4_1d-3_1nc-4_m256_s32_p8_l2_det2/run0/models/opt_state\n",
                        "pre_path \t\t /home/amawi/projects/nn_ansatz/src/experiments/LiSolidBCC/pretrained/s32_p8_l2_det2_1lr-4_i0.pk\n",
                        "timing_dir \t\t /home/amawi/projects/nn_ansatz/src/experiments/LiSolidBCC/100921/isotropic/adam_1lr-4_1d-3_1nc-4_m256_s32_p8_l2_det2/run0/events/timing\n",
                        "system \t\t LiSolidBCC\n",
                        "r_atoms \t\t [[0.  0.  0. ]\n",
                        " [0.5 0.5 0.5]]\n",
                        "z_atoms \t\t [3. 3.]\n",
                        "n_el \t\t 6\n",
                        "n_el_atoms \t\t [3 3]\n",
                        "periodic_boundaries \t\t True\n",
                        "real_basis \t\t [[1. 0. 0.]\n",
                        " [0. 1. 0.]\n",
                        " [0. 0. 1.]]\n",
                        "unit_cell_length \t\t 6.63\n",
                        "real_cut \t\t 6\n",
                        "reciprocal_cut \t\t 6\n",
                        "kappa \t\t 0.5\n",
                        "n_layers \t\t 2\n",
                        "n_sh \t\t 32\n",
                        "n_ph \t\t 8\n",
                        "n_det \t\t 2\n",
                        "scalar_inputs \t\t False\n",
                        "n_periodic_input \t\t 3\n",
                        "orbitals \t\t isotropic\n",
                        "opt \t\t adam\n",
                        "lr \t\t 0.0001\n",
                        "damping \t\t 0.001\n",
                        "norm_constraint \t\t 0.0001\n",
                        "n_it \t\t 20000\n",
                        "load_it \t\t 0\n",
                        "n_walkers \t\t 256\n",
                        "n_walkers_per_device \t\t 256\n",
                        "step_size \t\t 0.02\n",
                        "correlation_length \t\t 10\n",
                        "pre_lr \t\t 0.0001\n",
                        "n_pre_it \t\t 0\n",
                        "load_pretrain \t\t False\n",
                        "pretrain \t\t False\n",
                        "System: \n",
                        " n_atoms = 2 \n",
                        " n_up    = 3 \n",
                        " n_down  = 3 \n",
                        " n_el    = 6 \n",
                        "\n",
                        "Ansatz: \n",
                        " n_layers = 2 \n",
                        " n_det    = 2 \n",
                        " n_sh     = 32 \n",
                        " n_ph     = 8 \n",
                        "\n",
                        "Cell: \n",
                        " real_basis: \n",
                        " [[6.63 0.   0.  ]\n",
                        " [0.   6.63 0.  ]\n",
                        " [0.   0.   6.63]] \n",
                        " reciprocal_basis: \n",
                        " [[0.94769007 0.         0.        ]\n",
                        " [0.         0.94769007 0.        ]\n",
                        " [0.         0.         0.94769007]] \n",
                        " real_cut         = 6.00 \n",
                        " reciprocal_cut   = 6 \n",
                        " kappa            = 0.50 \n",
                        " volume           = 291.43 \n",
                        " min_cell_width   = 6.63 \n",
                        " n_periodic_input = 3 \n",
                        " unit_cell_length = 6.63 \n",
                        "\n",
                        "converged SCF energy = -12.1628037018806\n",
                        "creating wf\n",
                        "creating wf\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(DeviceArray([[[[0.8582945 , 6.5696616 , 0.04186589],\n",
                            "                [6.2126694 , 1.3524095 , 6.116393  ],\n",
                            "                [3.8645022 , 2.912761  , 1.4493206 ],\n",
                            "                [5.17297   , 4.029324  , 2.7368865 ],\n",
                            "                [0.528752  , 1.3406394 , 0.7872262 ],\n",
                            "                [2.2903671 , 1.4516345 , 4.184484  ]],\n",
                            " \n",
                            "               [[0.70812196, 0.56556445, 1.2961988 ],\n",
                            "                [6.2208285 , 6.382479  , 0.6443732 ],\n",
                            "                [4.8242397 , 4.1581893 , 3.683971  ],\n",
                            "                [3.9407113 , 5.073767  , 6.0349646 ],\n",
                            "                [6.1779075 , 0.34728247, 0.12393504],\n",
                            "                [2.1068974 , 2.329549  , 5.0772657 ]],\n",
                            " \n",
                            "               [[0.33890557, 6.264277  , 0.5172672 ],\n",
                            "                [6.161936  , 0.6629444 , 0.09966614],\n",
                            "                [1.5763894 , 3.7691598 , 3.2538962 ],\n",
                            "                [2.111093  , 2.9599917 , 2.879323  ],\n",
                            "                [5.7157664 , 6.5899916 , 0.15455239],\n",
                            "                [3.3246207 , 4.7007947 , 2.2608042 ]],\n",
                            " \n",
                            "               ...,\n",
                            " \n",
                            "               [[5.4033403 , 0.01308753, 5.762343  ],\n",
                            "                [6.0717206 , 5.4711733 , 6.231761  ],\n",
                            "                [2.1788712 , 3.063895  , 4.4879103 ],\n",
                            "                [4.0371246 , 3.695079  , 1.5583582 ],\n",
                            "                [4.823694  , 6.296136  , 6.5497637 ],\n",
                            "                [3.7454    , 4.424877  , 4.0189567 ]],\n",
                            " \n",
                            "               [[0.24467419, 4.3985453 , 6.0324173 ],\n",
                            "                [0.64205873, 5.427961  , 0.5122381 ],\n",
                            "                [3.2485926 , 2.8620358 , 3.5867755 ],\n",
                            "                [2.6860697 , 3.9790668 , 2.4295838 ],\n",
                            "                [4.977576  , 5.299812  , 5.834756  ],\n",
                            "                [3.3513072 , 2.3788662 , 4.4775233 ]],\n",
                            " \n",
                            "               [[6.2230024 , 6.5551977 , 6.5791836 ],\n",
                            "                [6.109646  , 0.95914274, 1.716696  ],\n",
                            "                [3.0787692 , 3.3717687 , 2.4963248 ],\n",
                            "                [2.0894537 , 4.5257044 , 1.6657308 ],\n",
                            "                [2.2841227 , 0.5493076 , 1.762863  ],\n",
                            "                [3.8872032 , 2.4753501 , 2.413551  ]]]], dtype=float32),\n",
                            " DeviceArray([0.86015624], dtype=float32),\n",
                            " DeviceArray([0.021], dtype=float32))"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "cfg = config = setup(system='LiSolidBCC',\n",
                "               n_pre_it=0,\n",
                "               n_walkers=256,\n",
                "               n_layers=2,\n",
                "               n_sh=32,\n",
                "               step_size=0.02,\n",
                "               n_ph=8,\n",
                "               orbitals='isotropic',\n",
                "               n_periodic_input=3,\n",
                "               opt='adam',\n",
                "               n_det=2,\n",
                "               print_every=100,\n",
                "               save_every=5000,\n",
                "               n_it=20000,\n",
                "               name='isotropic')\n",
                "\n",
                "logger = Logging(**cfg)\n",
                "\n",
                "keys = rnd.PRNGKey(cfg['seed'])\n",
                "if bool(os.environ.get('DISTRIBUTE')) is True:\n",
                "    keys = rnd.split(keys, cfg['n_devices']).reshape(cfg['n_devices'], 2)\n",
                "\n",
                "mol = SystemAnsatz(**cfg)\n",
                "\n",
                "pwf = pmap(create_wf(mol), in_axes=(None, 0))\n",
                "vwf = create_wf(mol)\n",
                "pwf_grad = grad(lambda x, y: pwf(x, y).sum(), argnums=(0,1))\n",
                "\n",
                "params = initialise_params(mol, keys)\n",
                "\n",
                "sampler = create_sampler(mol, vwf)\n",
                "\n",
                "ke = pmap(create_local_kinetic_energy(vwf), in_axes=(None, 0))\n",
                "pe = pmap(create_potential_energy(mol), in_axes=(0, None, None))\n",
                "pmap_compute_ae_vectors_periodic_i = lambda x, y: compute_ae_vectors_periodic_i(x, y, mol.unit_cell_length)\n",
                "pmap_compute_ae_vectors_periodic_i = pmap(vmap(pmap_compute_ae_vectors_periodic_i, in_axes=(0, None)), in_axes=(0, None))\n",
                "pmap_compute_ee_vectors_i = pmap(vmap(compute_ee_vectors_i, in_axes=(0,)), in_axes=(0,))\n",
                "\n",
                "grad_fn = create_grad_function(mol, vwf)\n",
                "\n",
                "walkers = generate_walkers_around_nuclei(mol.n_el_atoms, mol.atom_positions, mol.n_walkers)\n",
                "walkers = walkers.reshape(mol.n_devices, -1, *walkers.shape[1:])\n",
                "walkers = keep_in_boundary(walkers, mol.real_basis, mol.inv_real_basis)\n",
                "\n",
                "log_psi = pwf(params, walkers)\n",
                "\n",
                "keys, subkeys = key_gen(keys)\n",
                "sampler(params, walkers, subkeys, mol.step_size)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d37f7005d8f144edbf48e7ed56d27e77",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "training:   0%|          | 1/20001 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "if cfg['opt'] == 'kfac':\n",
                "    update, get_params, kfac_update, state = kfac(mol, params, walkers, cfg['lr'], cfg['damping'], cfg['norm_constraint'])\n",
                "elif cfg['opt'] == 'adam':\n",
                "    init, update, get_params = adam(cfg['lr'])\n",
                "    update = jit(update)\n",
                "    state = init(params)\n",
                "else:\n",
                "    exit('Optimiser not available')\n",
                "\n",
                "steps = trange(1, cfg['n_it']+1, initial=1, total=cfg['n_it']+1, desc='training', disable=None)\n",
                "step_size = split_variables_for_pmap(cfg['n_devices'], cfg['step_size'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "step 100 | e_mean -3.4131 | e_std 4.1471 | e_mean_mean -3.0957 | acceptance 0.5539 | t_per_it 0.0518 |\n",
                        "step 200 | e_mean -5.5867 | e_std 4.3614 | e_mean_mean -5.1772 | acceptance 0.5031 | t_per_it 0.0517 |\n",
                        "step 300 | e_mean -5.9305 | e_std 4.2964 | e_mean_mean -5.6933 | acceptance 0.5121 | t_per_it 0.0516 |\n",
                        "step 400 | e_mean -5.6908 | e_std 3.3997 | e_mean_mean -6.0146 | acceptance 0.5320 | t_per_it 0.0514 |\n",
                        "step 500 | e_mean -5.9243 | e_std 3.3819 | e_mean_mean -6.0710 | acceptance 0.4941 | t_per_it 0.0513 |\n",
                        "step 600 | e_mean -5.9484 | e_std 3.6764 | e_mean_mean -6.1820 | acceptance 0.5152 | t_per_it 0.0512 |\n",
                        "step 700 | e_mean -6.1402 | e_std 2.6809 | e_mean_mean -6.2906 | acceptance 0.4934 | t_per_it 0.0512 |\n",
                        "step 800 | e_mean -6.1693 | e_std 2.8186 | e_mean_mean -6.3954 | acceptance 0.4754 | t_per_it 0.0513 |\n",
                        "step 900 | e_mean -6.3035 | e_std 2.9426 | e_mean_mean -6.4434 | acceptance 0.4875 | t_per_it 0.0513 |\n",
                        "step 1000 | e_mean -6.6934 | e_std 3.7546 | e_mean_mean -6.5475 | acceptance 0.4805 | t_per_it 0.0514 |\n",
                        "step 1100 | e_mean -7.0158 | e_std 2.8104 | e_mean_mean -6.6657 | acceptance 0.4922 | t_per_it 0.0514 |\n",
                        "step 1200 | e_mean -6.6502 | e_std 3.2587 | e_mean_mean -6.7846 | acceptance 0.5039 | t_per_it 0.0514 |\n",
                        "step 1300 | e_mean -7.1392 | e_std 5.3669 | e_mean_mean -6.8953 | acceptance 0.5086 | t_per_it 0.0514 |\n",
                        "step 1400 | e_mean -6.9640 | e_std 3.1864 | e_mean_mean -6.9858 | acceptance 0.5219 | t_per_it 0.0514 |\n",
                        "step 1500 | e_mean -7.1955 | e_std 3.4698 | e_mean_mean -7.0455 | acceptance 0.5051 | t_per_it 0.0514 |\n",
                        "step 1600 | e_mean -7.1227 | e_std 3.0987 | e_mean_mean -7.1591 | acceptance 0.5039 | t_per_it 0.0514 |\n",
                        "step 1700 | e_mean -7.4358 | e_std 3.2846 | e_mean_mean -7.2351 | acceptance 0.4891 | t_per_it 0.0514 |\n",
                        "step 1800 | e_mean -7.3848 | e_std 3.0832 | e_mean_mean -7.3283 | acceptance 0.5082 | t_per_it 0.0514 |\n",
                        "step 1900 | e_mean -7.5971 | e_std 3.4835 | e_mean_mean -7.4437 | acceptance 0.5105 | t_per_it 0.0513 |\n",
                        "step 2000 | e_mean -7.9791 | e_std 3.5090 | e_mean_mean -7.5638 | acceptance 0.5184 | t_per_it 0.0513 |\n",
                        "step 2100 | e_mean -7.5439 | e_std 3.0995 | e_mean_mean -7.6745 | acceptance 0.5117 | t_per_it 0.0513 |\n",
                        "step 2200 | e_mean -7.7974 | e_std 2.9231 | e_mean_mean -7.7572 | acceptance 0.5164 | t_per_it 0.0512 |\n",
                        "step 2300 | e_mean -8.0732 | e_std 2.8650 | e_mean_mean -7.8713 | acceptance 0.4926 | t_per_it 0.0512 |\n",
                        "step 2400 | e_mean -8.1108 | e_std 2.5523 | e_mean_mean -8.0464 | acceptance 0.5176 | t_per_it 0.0512 |\n",
                        "step 2500 | e_mean -8.9126 | e_std 4.2337 | e_mean_mean -8.2475 | acceptance 0.5055 | t_per_it 0.0512 |\n",
                        "step 2600 | e_mean -8.6696 | e_std 3.5798 | e_mean_mean -8.4056 | acceptance 0.4918 | t_per_it 0.0511 |\n",
                        "step 2700 | e_mean -9.3113 | e_std 3.5285 | e_mean_mean -8.6150 | acceptance 0.4918 | t_per_it 0.0511 |\n",
                        "step 2800 | e_mean -8.9414 | e_std 2.7752 | e_mean_mean -8.7649 | acceptance 0.5063 | t_per_it 0.0511 |\n",
                        "step 2900 | e_mean -9.0010 | e_std 2.4745 | e_mean_mean -8.9733 | acceptance 0.5066 | t_per_it 0.0512 |\n",
                        "step 3000 | e_mean -9.2108 | e_std 2.4524 | e_mean_mean -9.1287 | acceptance 0.4863 | t_per_it 0.0512 |\n",
                        "step 3100 | e_mean -9.7079 | e_std 3.1888 | e_mean_mean -9.3236 | acceptance 0.5063 | t_per_it 0.0512 |\n",
                        "step 3200 | e_mean -9.6351 | e_std 2.6851 | e_mean_mean -9.5123 | acceptance 0.5141 | t_per_it 0.0512 |\n",
                        "step 3300 | e_mean -10.2563 | e_std 3.8521 | e_mean_mean -9.6935 | acceptance 0.4980 | t_per_it 0.0512 |\n",
                        "step 3400 | e_mean -9.9260 | e_std 2.5901 | e_mean_mean -9.8458 | acceptance 0.4719 | t_per_it 0.0512 |\n",
                        "step 3500 | e_mean -10.1987 | e_std 2.7038 | e_mean_mean -10.0064 | acceptance 0.4984 | t_per_it 0.0512 |\n",
                        "step 3600 | e_mean -10.0130 | e_std 2.4734 | e_mean_mean -10.1176 | acceptance 0.4980 | t_per_it 0.0512 |\n",
                        "step 3700 | e_mean -10.4344 | e_std 3.2913 | e_mean_mean -10.1567 | acceptance 0.4996 | t_per_it 0.0512 |\n",
                        "step 3800 | e_mean -10.4507 | e_std 2.3420 | e_mean_mean -10.3068 | acceptance 0.5156 | t_per_it 0.0512 |\n",
                        "step 3900 | e_mean -10.5132 | e_std 3.1811 | e_mean_mean -10.3655 | acceptance 0.5145 | t_per_it 0.0512 |\n",
                        "step 4000 | e_mean -10.5418 | e_std 2.3339 | e_mean_mean -10.4360 | acceptance 0.5008 | t_per_it 0.0512 |\n",
                        "step 4100 | e_mean -10.3069 | e_std 2.2638 | e_mean_mean -10.5642 | acceptance 0.5074 | t_per_it 0.0512 |\n",
                        "step 4200 | e_mean -10.8539 | e_std 3.0876 | e_mean_mean -10.5927 | acceptance 0.5199 | t_per_it 0.0512 |\n",
                        "step 4300 | e_mean -10.6598 | e_std 2.5421 | e_mean_mean -10.6681 | acceptance 0.5113 | t_per_it 0.0512 |\n",
                        "step 4400 | e_mean -10.7421 | e_std 2.4850 | e_mean_mean -10.6809 | acceptance 0.5031 | t_per_it 0.0512 |\n",
                        "step 4500 | e_mean -10.8062 | e_std 2.8550 | e_mean_mean -10.7022 | acceptance 0.5168 | t_per_it 0.0512 |\n",
                        "step 4600 | e_mean -10.7124 | e_std 2.3444 | e_mean_mean -10.7282 | acceptance 0.5160 | t_per_it 0.0512 |\n",
                        "step 4700 | e_mean -11.1969 | e_std 3.7245 | e_mean_mean -10.7485 | acceptance 0.5004 | t_per_it 0.0512 |\n",
                        "step 4800 | e_mean -10.6626 | e_std 2.5120 | e_mean_mean -10.7924 | acceptance 0.4668 | t_per_it 0.0513 |\n",
                        "step 4900 | e_mean -11.0267 | e_std 2.7472 | e_mean_mean -10.8486 | acceptance 0.5070 | t_per_it 0.0513 |\n",
                        "step 5000 | e_mean -10.8389 | e_std 2.5522 | e_mean_mean -10.8744 | acceptance 0.5168 | t_per_it 0.0513 |\n",
                        "step 5100 | e_mean -11.0504 | e_std 2.5427 | e_mean_mean -10.8954 | acceptance 0.4785 | t_per_it 0.0513 |\n",
                        "step 5200 | e_mean -11.0179 | e_std 2.2936 | e_mean_mean -10.9265 | acceptance 0.4805 | t_per_it 0.0513 |\n",
                        "step 5300 | e_mean -10.7326 | e_std 3.7765 | e_mean_mean -10.9817 | acceptance 0.4926 | t_per_it 0.0513 |\n",
                        "step 5400 | e_mean -10.8391 | e_std 2.1889 | e_mean_mean -11.0032 | acceptance 0.4965 | t_per_it 0.0513 |\n",
                        "step 5500 | e_mean -11.6203 | e_std 3.6019 | e_mean_mean -11.0165 | acceptance 0.5000 | t_per_it 0.0513 |\n",
                        "step 5600 | e_mean -11.0643 | e_std 2.0826 | e_mean_mean -11.0622 | acceptance 0.5047 | t_per_it 0.0513 |\n",
                        "step 5700 | e_mean -11.1425 | e_std 2.1982 | e_mean_mean -11.0790 | acceptance 0.4785 | t_per_it 0.0513 |\n",
                        "step 5800 | e_mean -11.6657 | e_std 4.5339 | e_mean_mean -11.1293 | acceptance 0.5059 | t_per_it 0.0513 |\n",
                        "step 5900 | e_mean -10.9960 | e_std 2.4766 | e_mean_mean -11.1449 | acceptance 0.5148 | t_per_it 0.0513 |\n",
                        "step 6000 | e_mean -10.9941 | e_std 2.0213 | e_mean_mean -11.1608 | acceptance 0.5105 | t_per_it 0.0513 |\n",
                        "step 6100 | e_mean -11.6361 | e_std 2.3059 | e_mean_mean -11.2248 | acceptance 0.5074 | t_per_it 0.0513 |\n",
                        "step 6200 | e_mean -11.0863 | e_std 2.2267 | e_mean_mean -11.2518 | acceptance 0.5160 | t_per_it 0.0513 |\n",
                        "step 6300 | e_mean -11.3601 | e_std 2.4881 | e_mean_mean -11.2743 | acceptance 0.4898 | t_per_it 0.0513 |\n",
                        "step 6400 | e_mean -12.1275 | e_std 3.9688 | e_mean_mean -11.2957 | acceptance 0.4957 | t_per_it 0.0513 |\n",
                        "step 6500 | e_mean -11.6959 | e_std 2.2779 | e_mean_mean -11.3144 | acceptance 0.5094 | t_per_it 0.0513 |\n",
                        "step 6600 | e_mean -11.4399 | e_std 2.1748 | e_mean_mean -11.3543 | acceptance 0.4934 | t_per_it 0.0513 |\n",
                        "step 6700 | e_mean -11.7051 | e_std 2.6161 | e_mean_mean -11.4085 | acceptance 0.5117 | t_per_it 0.0512 |\n",
                        "step 6800 | e_mean -11.5714 | e_std 2.3220 | e_mean_mean -11.4026 | acceptance 0.4938 | t_per_it 0.0512 |\n",
                        "step 6900 | e_mean -11.3918 | e_std 2.3593 | e_mean_mean -11.4349 | acceptance 0.5000 | t_per_it 0.0512 |\n",
                        "step 7000 | e_mean -11.4414 | e_std 2.0746 | e_mean_mean -11.4895 | acceptance 0.5059 | t_per_it 0.0512 |\n",
                        "step 7100 | e_mean -11.4262 | e_std 2.2918 | e_mean_mean -11.5159 | acceptance 0.4785 | t_per_it 0.0512 |\n",
                        "step 7200 | e_mean -11.5942 | e_std 2.0353 | e_mean_mean -11.5428 | acceptance 0.5004 | t_per_it 0.0512 |\n",
                        "step 7300 | e_mean -11.4377 | e_std 1.5142 | e_mean_mean -11.5645 | acceptance 0.4770 | t_per_it 0.0513 |\n",
                        "step 7400 | e_mean -11.3552 | e_std 1.7302 | e_mean_mean -11.5756 | acceptance 0.5078 | t_per_it 0.0513 |\n",
                        "step 7500 | e_mean -11.7676 | e_std 1.8962 | e_mean_mean -11.6228 | acceptance 0.4758 | t_per_it 0.0513 |\n",
                        "step 7600 | e_mean -11.8296 | e_std 1.9798 | e_mean_mean -11.6611 | acceptance 0.4785 | t_per_it 0.0514 |\n",
                        "step 7700 | e_mean -11.8132 | e_std 2.3670 | e_mean_mean -11.6886 | acceptance 0.4926 | t_per_it 0.0515 |\n",
                        "step 7800 | e_mean -11.9214 | e_std 2.4670 | e_mean_mean -11.7102 | acceptance 0.5016 | t_per_it 0.0515 |\n",
                        "step 7900 | e_mean -11.8294 | e_std 2.2746 | e_mean_mean -11.7433 | acceptance 0.4969 | t_per_it 0.0515 |\n",
                        "step 8000 | e_mean -11.7490 | e_std 1.9112 | e_mean_mean -11.7811 | acceptance 0.5020 | t_per_it 0.0515 |\n",
                        "step 8100 | e_mean -11.9490 | e_std 2.1133 | e_mean_mean -11.8234 | acceptance 0.4930 | t_per_it 0.0515 |\n",
                        "step 8200 | e_mean -11.9512 | e_std 2.0777 | e_mean_mean -11.8694 | acceptance 0.5043 | t_per_it 0.0515 |\n",
                        "step 8300 | e_mean -12.0147 | e_std 3.1556 | e_mean_mean -11.8939 | acceptance 0.5078 | t_per_it 0.0516 |\n",
                        "step 8400 | e_mean -12.0080 | e_std 2.0088 | e_mean_mean -11.9065 | acceptance 0.4918 | t_per_it 0.0516 |\n",
                        "step 8500 | e_mean -11.9676 | e_std 1.7916 | e_mean_mean -11.9284 | acceptance 0.5195 | t_per_it 0.0516 |\n",
                        "step 8600 | e_mean -12.2069 | e_std 2.0379 | e_mean_mean -11.9760 | acceptance 0.4996 | t_per_it 0.0516 |\n",
                        "step 8700 | e_mean -12.3385 | e_std 1.8818 | e_mean_mean -12.0124 | acceptance 0.4820 | t_per_it 0.0516 |\n",
                        "step 8800 | e_mean -12.2347 | e_std 2.1340 | e_mean_mean -12.0508 | acceptance 0.4855 | t_per_it 0.0516 |\n",
                        "step 8900 | e_mean -12.2629 | e_std 1.9179 | e_mean_mean -12.0847 | acceptance 0.4859 | t_per_it 0.0516 |\n",
                        "step 9000 | e_mean -12.2192 | e_std 2.8917 | e_mean_mean -12.0986 | acceptance 0.4984 | t_per_it 0.0516 |\n",
                        "step 9100 | e_mean -12.1408 | e_std 1.7133 | e_mean_mean -12.1334 | acceptance 0.4930 | t_per_it 0.0516 |\n",
                        "step 9200 | e_mean -12.3612 | e_std 1.8058 | e_mean_mean -12.1721 | acceptance 0.5086 | t_per_it 0.0516 |\n",
                        "step 9300 | e_mean -12.3213 | e_std 2.4567 | e_mean_mean -12.2218 | acceptance 0.4973 | t_per_it 0.0516 |\n",
                        "step 9400 | e_mean -12.4514 | e_std 1.6900 | e_mean_mean -12.2643 | acceptance 0.5102 | t_per_it 0.0516 |\n",
                        "step 9500 | e_mean -12.6305 | e_std 1.7099 | e_mean_mean -12.3136 | acceptance 0.5102 | t_per_it 0.0516 |\n",
                        "step 9600 | e_mean -12.0925 | e_std 1.8450 | e_mean_mean -12.3361 | acceptance 0.4980 | t_per_it 0.0517 |\n",
                        "step 9700 | e_mean -12.4981 | e_std 2.2557 | e_mean_mean -12.3612 | acceptance 0.4883 | t_per_it 0.0517 |\n",
                        "step 9800 | e_mean -12.7151 | e_std 2.5080 | e_mean_mean -12.3915 | acceptance 0.5066 | t_per_it 0.0517 |\n",
                        "step 9900 | e_mean -13.0283 | e_std 2.1017 | e_mean_mean -12.4448 | acceptance 0.4891 | t_per_it 0.0517 |\n",
                        "step 10000 | e_mean -12.7854 | e_std 2.0684 | e_mean_mean -12.5496 | acceptance 0.4910 | t_per_it 0.0517 |\n",
                        "step 10100 | e_mean -13.0701 | e_std 2.8607 | e_mean_mean -12.6164 | acceptance 0.5184 | t_per_it 0.0518 |\n",
                        "step 10200 | e_mean -13.2116 | e_std 2.4553 | e_mean_mean -12.7132 | acceptance 0.5004 | t_per_it 0.0519 |\n",
                        "step 10300 | e_mean -13.4557 | e_std 2.3875 | e_mean_mean -12.8215 | acceptance 0.4961 | t_per_it 0.0519 |\n",
                        "step 10400 | e_mean -13.6330 | e_std 2.3868 | e_mean_mean -12.9314 | acceptance 0.5082 | t_per_it 0.0519 |\n",
                        "step 10500 | e_mean -13.4838 | e_std 1.8898 | e_mean_mean -13.0365 | acceptance 0.5121 | t_per_it 0.0519 |\n",
                        "step 10600 | e_mean -13.6212 | e_std 2.6590 | e_mean_mean -13.1102 | acceptance 0.5102 | t_per_it 0.0519 |\n",
                        "step 10700 | e_mean -13.8031 | e_std 2.2192 | e_mean_mean -13.2202 | acceptance 0.4992 | t_per_it 0.0519 |\n",
                        "step 10800 | e_mean -14.1859 | e_std 2.5206 | e_mean_mean -13.3433 | acceptance 0.5207 | t_per_it 0.0520 |\n",
                        "step 10900 | e_mean -13.6211 | e_std 2.1328 | e_mean_mean -13.4653 | acceptance 0.4949 | t_per_it 0.0521 |\n",
                        "step 11000 | e_mean -14.2054 | e_std 2.2515 | e_mean_mean -13.5487 | acceptance 0.5184 | t_per_it 0.0521 |\n",
                        "step 11100 | e_mean -13.8321 | e_std 2.2268 | e_mean_mean -13.5964 | acceptance 0.5109 | t_per_it 0.0521 |\n",
                        "step 11200 | e_mean -14.3426 | e_std 3.2657 | e_mean_mean -13.6727 | acceptance 0.4867 | t_per_it 0.0521 |\n",
                        "step 11300 | e_mean -13.9649 | e_std 2.0536 | e_mean_mean -13.7265 | acceptance 0.4980 | t_per_it 0.0521 |\n",
                        "step 11400 | e_mean -14.1082 | e_std 1.8897 | e_mean_mean -13.7728 | acceptance 0.5020 | t_per_it 0.0522 |\n",
                        "step 11500 | e_mean -14.6420 | e_std 1.9075 | e_mean_mean -13.8234 | acceptance 0.4910 | t_per_it 0.0522 |\n",
                        "step 11600 | e_mean -13.8260 | e_std 1.9667 | e_mean_mean -13.8527 | acceptance 0.5027 | t_per_it 0.0522 |\n",
                        "step 11700 | e_mean -13.8600 | e_std 2.8472 | e_mean_mean -13.8637 | acceptance 0.4938 | t_per_it 0.0522 |\n",
                        "step 11800 | e_mean -13.7633 | e_std 1.7080 | e_mean_mean -13.8722 | acceptance 0.4840 | t_per_it 0.0522 |\n",
                        "step 11900 | e_mean -13.5287 | e_std 2.0760 | e_mean_mean -13.8903 | acceptance 0.4984 | t_per_it 0.0522 |\n",
                        "step 12000 | e_mean -14.4633 | e_std 2.1896 | e_mean_mean -13.9063 | acceptance 0.5051 | t_per_it 0.0522 |\n",
                        "step 12100 | e_mean -13.6044 | e_std 1.6741 | e_mean_mean -13.9099 | acceptance 0.4957 | t_per_it 0.0522 |\n",
                        "step 12200 | e_mean -14.4027 | e_std 2.1345 | e_mean_mean -13.9236 | acceptance 0.4996 | t_per_it 0.0522 |\n",
                        "step 12300 | e_mean -14.1438 | e_std 2.0956 | e_mean_mean -13.9430 | acceptance 0.4949 | t_per_it 0.0522 |\n",
                        "step 12400 | e_mean -14.1738 | e_std 1.7857 | e_mean_mean -13.9431 | acceptance 0.4941 | t_per_it 0.0522 |\n",
                        "step 12500 | e_mean -14.0319 | e_std 1.8791 | e_mean_mean -13.9595 | acceptance 0.5063 | t_per_it 0.0523 |\n",
                        "step 12600 | e_mean -14.0345 | e_std 2.1937 | e_mean_mean -13.9642 | acceptance 0.5246 | t_per_it 0.0523 |\n",
                        "step 12700 | e_mean -14.3034 | e_std 2.3570 | e_mean_mean -13.9626 | acceptance 0.4875 | t_per_it 0.0523 |\n",
                        "step 12800 | e_mean -13.5158 | e_std 1.9870 | e_mean_mean -13.9463 | acceptance 0.4895 | t_per_it 0.0523 |\n",
                        "step 12900 | e_mean -13.6414 | e_std 1.7409 | e_mean_mean -13.9464 | acceptance 0.5000 | t_per_it 0.0523 |\n",
                        "step 13000 | e_mean -14.2421 | e_std 3.1192 | e_mean_mean -13.9494 | acceptance 0.5164 | t_per_it 0.0523 |\n",
                        "step 13100 | e_mean -14.1358 | e_std 2.5630 | e_mean_mean -13.9926 | acceptance 0.5156 | t_per_it 0.0523 |\n",
                        "step 13200 | e_mean -14.5916 | e_std 2.5790 | e_mean_mean -13.9991 | acceptance 0.4906 | t_per_it 0.0523 |\n",
                        "step 13300 | e_mean -14.1509 | e_std 1.8773 | e_mean_mean -14.0181 | acceptance 0.5047 | t_per_it 0.0524 |\n",
                        "step 13400 | e_mean -14.3825 | e_std 1.6565 | e_mean_mean -14.0334 | acceptance 0.5105 | t_per_it 0.0524 |\n",
                        "step 13500 | e_mean -14.2666 | e_std 1.6784 | e_mean_mean -14.0745 | acceptance 0.5051 | t_per_it 0.0525 |\n",
                        "step 13600 | e_mean -14.2085 | e_std 2.0008 | e_mean_mean -14.0887 | acceptance 0.5141 | t_per_it 0.0525 |\n",
                        "step 13700 | e_mean -13.4645 | e_std 1.9432 | e_mean_mean -14.0946 | acceptance 0.4988 | t_per_it 0.0525 |\n",
                        "step 13800 | e_mean -14.1871 | e_std 2.9562 | e_mean_mean -14.0695 | acceptance 0.4984 | t_per_it 0.0525 |\n",
                        "step 13900 | e_mean -13.9715 | e_std 2.4827 | e_mean_mean -14.0678 | acceptance 0.4984 | t_per_it 0.0525 |\n",
                        "step 14000 | e_mean -14.3032 | e_std 2.6817 | e_mean_mean -14.0882 | acceptance 0.4969 | t_per_it 0.0525 |\n",
                        "step 14100 | e_mean -14.5164 | e_std 3.4468 | e_mean_mean -14.0995 | acceptance 0.4852 | t_per_it 0.0525 |\n",
                        "step 14200 | e_mean -14.1569 | e_std 2.1619 | e_mean_mean -14.1105 | acceptance 0.4926 | t_per_it 0.0526 |\n",
                        "step 14300 | e_mean -14.0285 | e_std 2.1765 | e_mean_mean -14.1297 | acceptance 0.5035 | t_per_it 0.0526 |\n",
                        "step 14400 | e_mean -14.0919 | e_std 1.7697 | e_mean_mean -14.1437 | acceptance 0.5199 | t_per_it 0.0526 |\n",
                        "step 14500 | e_mean -14.3739 | e_std 1.7454 | e_mean_mean -14.1615 | acceptance 0.4992 | t_per_it 0.0526 |\n",
                        "step 14600 | e_mean -14.2803 | e_std 1.5879 | e_mean_mean -14.1869 | acceptance 0.5109 | t_per_it 0.0526 |\n",
                        "step 14700 | e_mean -14.4838 | e_std 1.6916 | e_mean_mean -14.2040 | acceptance 0.5211 | t_per_it 0.0526 |\n",
                        "step 14800 | e_mean -14.5665 | e_std 2.0544 | e_mean_mean -14.2144 | acceptance 0.4914 | t_per_it 0.0526 |\n",
                        "step 14900 | e_mean -13.7287 | e_std 2.1721 | e_mean_mean -14.1799 | acceptance 0.4914 | t_per_it 0.0526 |\n",
                        "step 15000 | e_mean -14.0549 | e_std 1.7076 | e_mean_mean -14.1462 | acceptance 0.5051 | t_per_it 0.0526 |\n",
                        "step 15100 | e_mean -14.6249 | e_std 2.2250 | e_mean_mean -14.1581 | acceptance 0.4934 | t_per_it 0.0526 |\n",
                        "step 15200 | e_mean -14.6231 | e_std 2.5259 | e_mean_mean -14.1718 | acceptance 0.4945 | t_per_it 0.0526 |\n",
                        "step 15300 | e_mean -14.5069 | e_std 2.2800 | e_mean_mean -14.2393 | acceptance 0.5277 | t_per_it 0.0526 |\n",
                        "step 15400 | e_mean -14.7105 | e_std 1.9819 | e_mean_mean -14.2605 | acceptance 0.5129 | t_per_it 0.0526 |\n",
                        "step 15500 | e_mean -14.6646 | e_std 2.1230 | e_mean_mean -14.3038 | acceptance 0.4875 | t_per_it 0.0526 |\n",
                        "step 15600 | e_mean -14.5157 | e_std 1.8963 | e_mean_mean -14.3184 | acceptance 0.4965 | t_per_it 0.0526 |\n",
                        "step 15700 | e_mean -14.2104 | e_std 2.5833 | e_mean_mean -14.3210 | acceptance 0.5070 | t_per_it 0.0526 |\n",
                        "step 15800 | e_mean -14.5593 | e_std 2.6045 | e_mean_mean -14.3410 | acceptance 0.4906 | t_per_it 0.0526 |\n",
                        "step 15900 | e_mean -14.2656 | e_std 2.5049 | e_mean_mean -14.3879 | acceptance 0.4895 | t_per_it 0.0527 |\n",
                        "step 16000 | e_mean -15.5814 | e_std 2.6666 | e_mean_mean -14.4325 | acceptance 0.4898 | t_per_it 0.0527 |\n",
                        "step 16100 | e_mean -15.1413 | e_std 2.2899 | e_mean_mean -14.4456 | acceptance 0.4992 | t_per_it 0.0527 |\n",
                        "step 16200 | e_mean -14.3639 | e_std 2.9091 | e_mean_mean -14.4597 | acceptance 0.4930 | t_per_it 0.0527 |\n",
                        "step 16300 | e_mean -13.2947 | e_std 3.2608 | e_mean_mean -14.4401 | acceptance 0.5246 | t_per_it 0.0527 |\n",
                        "step 16400 | e_mean -14.6758 | e_std 2.1786 | e_mean_mean -14.4299 | acceptance 0.4875 | t_per_it 0.0527 |\n",
                        "step 16500 | e_mean -15.0720 | e_std 3.1476 | e_mean_mean -14.4759 | acceptance 0.5074 | t_per_it 0.0527 |\n",
                        "step 16600 | e_mean -15.6897 | e_std 2.6667 | e_mean_mean -14.5545 | acceptance 0.5031 | t_per_it 0.0527 |\n",
                        "step 16700 | e_mean -14.2450 | e_std 2.6071 | e_mean_mean -14.5994 | acceptance 0.5094 | t_per_it 0.0527 |\n",
                        "step 16800 | e_mean -13.7010 | e_std 2.1226 | e_mean_mean -14.6056 | acceptance 0.4926 | t_per_it 0.0527 |\n",
                        "step 16900 | e_mean -13.7562 | e_std 1.9425 | e_mean_mean -14.5863 | acceptance 0.5172 | t_per_it 0.0527 |\n",
                        "step 17000 | e_mean -15.3757 | e_std 2.7441 | e_mean_mean -14.5716 | acceptance 0.4988 | t_per_it 0.0527 |\n",
                        "step 17100 | e_mean -15.1111 | e_std 1.8217 | e_mean_mean -14.6108 | acceptance 0.5039 | t_per_it 0.0527 |\n",
                        "step 17200 | e_mean -16.2580 | e_std 2.5517 | e_mean_mean -14.6784 | acceptance 0.4941 | t_per_it 0.0527 |\n",
                        "step 17300 | e_mean -15.8961 | e_std 2.2251 | e_mean_mean -14.7727 | acceptance 0.5102 | t_per_it 0.0527 |\n",
                        "step 17400 | e_mean -16.1323 | e_std 2.3006 | e_mean_mean -14.8363 | acceptance 0.4938 | t_per_it 0.0527 |\n",
                        "step 17500 | e_mean -15.5540 | e_std 2.4671 | e_mean_mean -14.9126 | acceptance 0.4973 | t_per_it 0.0527 |\n",
                        "step 17600 | e_mean -14.8219 | e_std 2.7286 | e_mean_mean -14.9457 | acceptance 0.5027 | t_per_it 0.0527 |\n",
                        "step 17700 | e_mean -15.5188 | e_std 2.5774 | e_mean_mean -14.9824 | acceptance 0.5098 | t_per_it 0.0527 |\n",
                        "step 17800 | e_mean -14.7256 | e_std 1.9783 | e_mean_mean -14.9851 | acceptance 0.4871 | t_per_it 0.0527 |\n",
                        "step 17900 | e_mean -16.3220 | e_std 2.1125 | e_mean_mean -15.0070 | acceptance 0.4918 | t_per_it 0.0527 |\n",
                        "step 18000 | e_mean -15.8862 | e_std 2.6868 | e_mean_mean -15.0614 | acceptance 0.4926 | t_per_it 0.0527 |\n",
                        "step 18100 | e_mean -16.0249 | e_std 2.1380 | e_mean_mean -15.1555 | acceptance 0.4887 | t_per_it 0.0527 |\n",
                        "step 18200 | e_mean -16.4111 | e_std 2.3734 | e_mean_mean -15.2513 | acceptance 0.4777 | t_per_it 0.0527 |\n",
                        "step 18300 | e_mean -14.2803 | e_std 3.1887 | e_mean_mean -15.2945 | acceptance 0.5227 | t_per_it 0.0527 |\n",
                        "step 18400 | e_mean -15.1692 | e_std 2.6998 | e_mean_mean -15.3346 | acceptance 0.5156 | t_per_it 0.0527 |\n",
                        "step 18500 | e_mean -16.4955 | e_std 2.3893 | e_mean_mean -15.3727 | acceptance 0.5047 | t_per_it 0.0527 |\n",
                        "step 18600 | e_mean -16.7732 | e_std 3.8693 | e_mean_mean -15.4628 | acceptance 0.5016 | t_per_it 0.0527 |\n",
                        "step 18700 | e_mean -16.4597 | e_std 1.9424 | e_mean_mean -15.5782 | acceptance 0.4836 | t_per_it 0.0527 |\n",
                        "step 18800 | e_mean -16.1555 | e_std 2.1589 | e_mean_mean -15.6728 | acceptance 0.4512 | t_per_it 0.0528 |\n",
                        "step 18900 | e_mean -17.3005 | e_std 2.2334 | e_mean_mean -15.7568 | acceptance 0.4984 | t_per_it 0.0528 |\n",
                        "step 19000 | e_mean -16.1776 | e_std 2.1038 | e_mean_mean -15.8411 | acceptance 0.4891 | t_per_it 0.0528 |\n",
                        "step 19100 | e_mean -17.4065 | e_std 2.7718 | e_mean_mean -15.8534 | acceptance 0.4953 | t_per_it 0.0528 |\n",
                        "step 19200 | e_mean -17.1715 | e_std 2.6650 | e_mean_mean -15.8631 | acceptance 0.4934 | t_per_it 0.0528 |\n",
                        "step 19300 | e_mean -15.7050 | e_std 2.6758 | e_mean_mean -15.9127 | acceptance 0.5098 | t_per_it 0.0528 |\n",
                        "step 19400 | e_mean -16.2900 | e_std 3.1109 | e_mean_mean -15.9433 | acceptance 0.4820 | t_per_it 0.0528 |\n",
                        "step 19500 | e_mean -16.2321 | e_std 1.9976 | e_mean_mean -16.0041 | acceptance 0.5016 | t_per_it 0.0528 |\n",
                        "step 19600 | e_mean -16.6388 | e_std 2.0869 | e_mean_mean -16.0872 | acceptance 0.4984 | t_per_it 0.0528 |\n",
                        "step 19700 | e_mean -16.5378 | e_std 2.7403 | e_mean_mean -16.1820 | acceptance 0.4816 | t_per_it 0.0528 |\n",
                        "step 19800 | e_mean -16.7050 | e_std 2.3446 | e_mean_mean -16.2863 | acceptance 0.4957 | t_per_it 0.0528 |\n",
                        "step 19900 | e_mean -16.4779 | e_std 3.1590 | e_mean_mean -16.3385 | acceptance 0.4922 | t_per_it 0.0528 |\n",
                        "step 20000 | e_mean -17.8292 | e_std 2.8119 | e_mean_mean -16.3605 | acceptance 0.4820 | t_per_it 0.0529 |\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "\n",
                "for step in steps:\n",
                "    keys, subkeys = key_gen(keys)\n",
                "\n",
                "    walkers, acceptance, step_size = sampler(params, walkers, subkeys, step_size)\n",
                "    # gparam, gwalker = pwf_grad(params, walkers)\n",
                "    # stop = capture_nan(walkers, 'walkers', False)\n",
                "\n",
                "    # pote = pe(walkers, mol.r_atoms, mol.z_atoms)\n",
                "    # pote_nan = check_if_nan(pote, 'x')\n",
                "\n",
                "    # kine = ke(params, walkers)\n",
                "    # kine_nan = check_if_nan(kine,'x')\n",
                "\n",
                "    # ae_vectors = pmap_compute_ae_vectors_periodic_i(walkers, mol.r_atoms)\n",
                "    # ee_vectors = pmap_compute_ee_vectors_i(walkers)\n",
                "    # min_im_ee_vectors = apply_minimum_image_convention(ee_vectors, mol.unit_cell_length)\n",
                "    # min_im_ae_vectors = apply_minimum_image_convention(ae_vectors, mol.unit_cell_length)\n",
                "\n",
                "    # if kine_nan:\n",
                "    #     print('nan in kinetic')\n",
                "    #     break\n",
                "    \n",
                "    grads, e_locs = grad_fn(params, walkers)\n",
                "    # stop = capture_nan(grads, 'e_locs', stop)\n",
                "    # stop = capture_nan(grads, 'grads', stop)\n",
                "\n",
                "    if cfg['opt'] == 'kfac':\n",
                "        grads, state = kfac_update(step, grads, state, walkers)\n",
                "\n",
                "    state = update(step, grads, state)\n",
                "    params = get_params(state)\n",
                "\n",
                "    steps.set_postfix(E=f'{jnp.mean(e_locs):.6f}')\n",
                "    steps.refresh()\n",
                "\n",
                "    logger.log(step,\n",
                "                opt_state=state,\n",
                "                params=params,\n",
                "                e_locs=e_locs,\n",
                "                acceptance=acceptance[0],\n",
                "                walkers=walkers)\n",
                "\n",
                "logger.walkers = walkers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "nan\n",
                        "[[[-1.3872877e-01 -5.6188392e-09 -4.2735010e-01]\n",
                        "  [ 8.6127132e-01  1.0000000e+00  5.7264996e-01]]\n",
                        "\n",
                        " [[ 8.4430242e-01  9.5665139e-01 -8.6504728e-01]\n",
                        "  [-1.5569763e-01 -4.3348670e-02  1.3495275e-01]]\n",
                        "\n",
                        " [[ 7.8833884e-01 -7.3619252e-01 -5.7768416e-01]\n",
                        "  [-2.1166119e-01  2.6380754e-01  4.2231593e-01]]\n",
                        "\n",
                        " [[ 8.0202579e-01  8.5771257e-01  7.7705044e-01]\n",
                        "  [-1.9797423e-01 -1.4228749e-01 -2.2294964e-01]]\n",
                        "\n",
                        " [[-8.8907361e-01  9.6318859e-01  7.7088475e-01]\n",
                        "  [ 1.1092643e-01 -3.6811471e-02 -2.2911531e-01]]\n",
                        "\n",
                        " [[ 1.7893118e-01 -2.0605713e-01 -2.1177055e-02]\n",
                        "  [-8.2106888e-01  7.9394299e-01  9.7882301e-01]]]\n"
                    ]
                }
            ],
            "source": [
                "idx = jnp.argwhere(jnp.isnan(kine[0]))[0, 0]\n",
                "print(kine[0, idx])\n",
                "print(ae_vectors[0, idx, ...] / (mol.unit_cell_length / 2.))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "177\n",
                        "[[4.5988584e-01 1.8626451e-08 1.4166656e+00]\n",
                        " [3.8311377e+00 3.4587009e+00 2.8676317e+00]\n",
                        " [4.0166569e+00 2.4404781e+00 1.9150229e+00]\n",
                        " [3.9712846e+00 3.7866831e+00 4.0540781e+00]\n",
                        " [2.9472790e+00 3.4370301e+00 4.0745173e+00]\n",
                        " [6.0368433e+00 6.8307936e-01 7.0201933e-02]]\n",
                        "-3.8840332\n",
                        "[ 0.1320289 -1.5310602 -0.8113647]\n"
                    ]
                }
            ],
            "source": [
                "print(idx)\n",
                "walkers[0, idx, ...]\n",
                "log_psi = pwf(params, walkers)\n",
                "print(walkers[0, idx, ...])\n",
                "print(log_psi[0, idx])\n",
                "print(gwalker[0, 0, idx, :])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "ename": "RuntimeError",
                    "evalue": "Unknown: an illegal memory access was encountered\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_asm_compiler.cc(40): 'cuLinkCreate(0, nullptr, nullptr, &link_state)'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mUnfilteredStackTrace\u001b[0m                      Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-19-486948b7e645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_basis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/numpy/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_fun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         donated_invars=donated_invars)\n\u001b[0m\u001b[1;32m    433\u001b[0m     \u001b[0mout_pytree_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1564\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1555\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mmaybe_new_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, trace, fun, tracers, params)\u001b[0m\n\u001b[1;32m   1567\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    608\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m   \u001b[0mprocess_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_xla_call_impl\u001b[0;34m(fun, device, backend, name, donated_invars, *args)\u001b[0m\n\u001b[1;32m    578\u001b[0m   compiled_fun = _xla_callable(fun, device, backend, name, donated_invars,\n\u001b[0;32m--> 579\u001b[0;31m                                *unsafe_map(arg_spec, args))\n\u001b[0m\u001b[1;32m    580\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mmemoized_fun\u001b[0;34m(fun, *args)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m       \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_xla_callable\u001b[0;34m(fun, device, backend, name, donated_invars, *arg_specs)\u001b[0m\n\u001b[1;32m    723\u001b[0m   \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter_is_tupled_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m   \u001b[0mcompiled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnreps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options)\u001b[0m\n\u001b[1;32m    344\u001b[0m   \u001b[0;31m# separately in Python profiling results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilt_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mUnfilteredStackTrace\u001b[0m: RuntimeError: Unknown: an illegal memory access was encountered\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_asm_compiler.cc(40): 'cuLinkCreate(0, nullptr, nullptr, &link_state)'\n\nThe stack trace below excludes JAX-internal frames.\nThe preceding is the original exception that occurred, unmodified.\n\n--------------------",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-19-486948b7e645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# jnp.linalg.norm(mol.real_basis, axis=-1)#.mean()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_basis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/numpy/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options)\u001b[0m\n\u001b[1;32m    343\u001b[0m   \u001b[0;31m# we use a separate function call to ensure that XLA compilation appears\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m   \u001b[0;31m# separately in Python profiling results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilt_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_execute_compiled_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mRuntimeError\u001b[0m: Unknown: an illegal memory access was encountered\nin external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_asm_compiler.cc(40): 'cuLinkCreate(0, nullptr, nullptr, &link_state)'"
                    ]
                }
            ],
            "source": [
                "from jax import lax\n",
                "from jax.tree_util import tree_flatten\n",
                "\n",
                "def create_grad_function(mol, vwf):\n",
                "    \n",
                "    compute_energy = create_energy_fn(mol, vwf)\n",
                "\n",
                "    def _forward_pass(params, walkers):\n",
                "        e_locs = lax.stop_gradient(compute_energy(params, walkers))\n",
                "\n",
                "        e_locs_centered = clip_and_center(e_locs) # takes the mean of the data on each device and does not distribute\n",
                "        log_psi = vwf(params, walkers)\n",
                "\n",
                "        return jnp.mean(e_locs_centered * log_psi), e_locs\n",
                "\n",
                "    _param_grad_fn = grad(_forward_pass, has_aux=True)  # has_aux indicates the number of outputs is greater than 1\n",
                "    \n",
                "    if bool(os.environ.get('DISTRIBUTE')) is True:\n",
                "        _param_grad_fn = pmap(_param_grad_fn, in_axes=(None, 0))\n",
                "\n",
                "    '''nb: it is not possible to undevice variables within a pmap'''\n",
                "\n",
                "    def _grad_fn(params, walkers):\n",
                "        grads, e_locs = _param_grad_fn(params, walkers)\n",
                "        grads = jax.device_put(grads, jax.devices()[0])\n",
                "        grads, tree = tree_flatten(grads)\n",
                "        grads = [g.mean(0) for g in grads]\n",
                "        grads = tree_unflatten(tree, grads)\n",
                "        return grads, jax.device_put(e_locs, jax.devices()[0]).reshape(-1)\n",
                "\n",
                "    return jit(_grad_fn)\n",
                "\n",
                "# compute_energy = create_energy_fn(mol, vwf)\n",
                "\n",
                "# jnp.linalg.norm(mol.real_basis, axis=-1)#.mean()\n",
                "\n",
                "print(jnp.linalg.norm(mol.real_basis, axis=-1))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[GpuDevice(id=0, process_index=0)]\n"
                    ]
                }
            ],
            "source": [
                "# jax.device_put(walkers, jax.devices()[0])\n",
                "print(jax.devices())\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[6.63 6.63 6.63]\n"
                    ]
                },
                {
                    "ename": "ValueError",
                    "evalue": "Internal: Failed to launch CUDA kernel: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-26-29ba8fde3339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_basis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/numpy/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mValueError\u001b[0m: Internal: Failed to launch CUDA kernel: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "print(np.linalg.norm(np.array(mol.real_basis), axis=-1))\n",
                "jnp.linalg.norm(mol.real_basis, axis=-1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[0.64362454 2.797233   2.0600808 ]\n",
                        " [1.2021452  0.6426074  2.484054  ]\n",
                        " [5.493576   5.7438507  5.119844  ]\n",
                        " [4.999399   4.46594    4.9091105 ]\n",
                        " [3.3290756  2.5294046  3.2106931 ]\n",
                        " [4.6895256  3.9742057  5.5813255 ]]\n",
                        "[[0 0 0]\n",
                        " [0 0 0]\n",
                        " [1 1 1]\n",
                        " [1 1 1]\n",
                        " [1 0 0]\n",
                        " [1 1 1]]\n",
                        "[[ 1.2872492  5.5944667  4.120162 ]\n",
                        " [ 2.4042904  1.2852148  4.9681087]\n",
                        " [10.987153  11.487702  10.239688 ]\n",
                        " [ 9.998799   8.93188    9.818221 ]\n",
                        " [ 6.6581516  5.0588093  6.4213862]\n",
                        " [ 9.379052   7.9484124 11.162652 ]]\n"
                    ]
                }
            ],
            "source": [
                "# print(apply_minimum_image_convention(walkers, unit_cell_length=mol.unit_cell_length) / mol.unit_cell_length)\n",
                "w = walkers[0, 0]\n",
                "print(w)\n",
                "print((2 * w / mol.unit_cell_length).astype(int))\n",
                "print((2 * w / mol.unit_cell_length).astype(w.dtype) * mol.unit_cell_length)\n",
                "# displace = (2. * displacement_vectors / unit_cell_length).astype(int).astype(displacement_vectors.dtype) * unit_cell_length\n",
                "    # displacement_vectors = displacement_vectors + lax.stop_gradient(displace)  # "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "False\n"
                    ]
                }
            ],
            "source": [
                "print(jnp.isinf(test).any())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-6-793317c5aaf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_grad_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvwf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'opt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'kfac'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkfac_update\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'damping'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'norm_constraint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'opt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/projects/nn_ansatz/src/nn_ansatz/vmc.py\u001b[0m in \u001b[0;36mcreate_grad_function\u001b[0;34m(mol, vwf)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_grad_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvwf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcompute_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_energy_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvwf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/projects/nn_ansatz/src/nn_ansatz/vmc.py\u001b[0m in \u001b[0;36mcreate_energy_fn\u001b[0;34m(mol, vwf, separate)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mlocal_kinetic_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_local_kinetic_energy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvwf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mcompute_potential_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_potential_energy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_local_energy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/projects/nn_ansatz/src/nn_ansatz/vmc.py\u001b[0m in \u001b[0;36mcreate_potential_energy\u001b[0;34m(mol)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mreal_lattice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_lattice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_cut\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (n_lattice, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mreciprocal_lattice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_lattice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreciprocal_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreciprocal_cut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mrl_inner_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreciprocal_lattice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreciprocal_lattice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mrl_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mrl_inner_product\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrl_inner_product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/projects/nn_ansatz/src/nn_ansatz/vmc.py\u001b[0m in \u001b[0;36mgenerate_lattice\u001b[0;34m(basis, cut)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;31m# then sum over those\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;31m# print(len(img_sets))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mimg_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_sets\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;31m# print(img_sets.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_sets\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbasis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/projects/nn_ansatz/src/nn_ansatz/vmc.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;31m# then sum over those\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;31m# print(len(img_sets))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mimg_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_sets\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;31m# print(img_sets.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_sets\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbasis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                     \u001b[0mbool_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_or\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcast_f16_for_computation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                     initial=initial, where_=where, parallel_reduce=lax.psum)\n\u001b[0m\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_reduction\u001b[0;34m(a, name, np_fun, op, init_val, has_identity, preproc, bool_op, upcast_f16_for_computation, axis, dtype, out, keepdims, initial, where_, parallel_reduce)\u001b[0m\n\u001b[1;32m   1984\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m     \u001b[0mcomputation_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m   \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcomputation_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbool_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m   \u001b[0;31m# NB: in XLA, init_val must be an identity for the op, so the user-specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mconvert_element_type\u001b[0;34m(operand, new_dtype)\u001b[0m\n\u001b[1;32m    423\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__jax_array__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0moperand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__jax_array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m def _convert_element_type(operand: Array, new_dtype: Optional[DType] = None,\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_convert_element_type\u001b[0;34m(operand, new_dtype, weak_type)\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     return convert_element_type_p.bind(operand, new_dtype=new_dtype,\n\u001b[0;32m--> 455\u001b[0;31m                                        weak_type=new_weak_type)\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbitcast_convert_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    260\u001b[0m             all(isinstance(arg, Tracer) or valid_jaxtype(arg) for arg in args)), args\n\u001b[1;32m    261\u001b[0m     top_trace = find_top_trace(\n\u001b[0;32m--> 262\u001b[0;31m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/xmax/lib/python3.7/site-packages/jax/core.py\u001b[0m in \u001b[0;36mfind_top_trace\u001b[0;34m(xs, axis_names)\u001b[0m\n\u001b[1;32m    824\u001b[0m                    default=None, key=lambda t: getattr(t, 'level', -1))\n\u001b[1;32m    825\u001b[0m   top_tracer = max((x for x in xs if isinstance(x, Tracer)),\n\u001b[0;32m--> 826\u001b[0;31m                    default=None, key=attrgetter('_trace.level'))\n\u001b[0m\u001b[1;32m    827\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtop_tracer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0mtop_tracer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_live\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "# grad_fn = create_grad_function(mol, vwf)\n",
                "\n",
                "# if cfg['opt'] == 'kfac':\n",
                "#     update, get_params, kfac_update, state = kfac(mol, params, walkers, cfg['lr'], cfg['damping'], cfg['norm_constraint'])\n",
                "# elif cfg['opt'] == 'adam':\n",
                "#     init, update, get_params = adam(cfg['lr'])\n",
                "#     update = jit(update)\n",
                "#     state = init(params)\n",
                "# else:\n",
                "#     exit('Optimiser not available')\n",
                "\n",
                "# steps = trange(1, cfg['n_it']+1, initial=1, total=cfg['n_it']+1, desc='training', disable=None)\n",
                "# step_size = split_variables_for_pmap(cfg['n_devices'], cfg['step_size'])\n",
                "\n",
                "# for step in steps:\n",
                "#     keys, subkeys = key_gen(keys)\n",
                "\n",
                "#     walkers, acceptance, step_size = sampler(params, walkers, subkeys, step_size)"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "7a752f85bebb1858ec945483ba335b9f70837721ce1b1b8baae25c9540d92ac1"
        },
        "kernelspec": {
            "display_name": "Python 3.7.10 64-bit ('xmax': conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
