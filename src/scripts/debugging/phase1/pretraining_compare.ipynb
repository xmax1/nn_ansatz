{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heavy-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "express-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ops.utils import compare\n",
    "from functools import partial\n",
    "\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random as rnd\n",
    "from jax import lax, jit, vmap, value_and_grad, grad\n",
    "from jax.tree_util import tree_structure, tree_flatten, tree_unflatten\n",
    "\n",
    "from pytorch.models.og.model import fermiNet\n",
    "from pytorch.sampling import MetropolisHasting\n",
    "from pytorch.vmc import *\n",
    "from pytorch.pretraining_v2 import Pretrainer, tile_labels, mse_error\n",
    "from pytorch.systems import Molecule as Moleculetc\n",
    "from pytorch.utils import update_state_dict, from_np\n",
    "import torch as tc\n",
    "tc.set_default_dtype(tc.float64)\n",
    "\n",
    "from ops.vmc.utils import create_atom_batch\n",
    "from ops.systems import Molecule\n",
    "from ops.wf.ferminet import create_wf, create_masks\n",
    "from ops.wf.parameters import initialise_params, count_mixed_features\n",
    "from ops.sampling import create_sampler\n",
    "from ops.vmc import create_energy_fn, local_kinetic_energy, compute_potential_energy\n",
    "from ops.pretraining import create_loss_and_sampler\n",
    "\n",
    "def df(arr_tc, arr_jax):\n",
    "    arr_tc = arr_tc.detach().cpu().numpy()\n",
    "    diff = jnp.mean(jnp.abs(arr_tc - arr_jax))\n",
    "    return diff\n",
    "    \n",
    "def compare_grads(model_tc, grads):\n",
    "    tmp = []\n",
    "    for k, value in grads.items():\n",
    "        if k == 'intermediate':\n",
    "            for intermediate in zip(*grads[k]):\n",
    "                for ps in intermediate:\n",
    "                    tmp.append(ps)\n",
    "\n",
    "        elif k == 'envelopes':\n",
    "            order = ('linear', 'sigma', 'pi')\n",
    "            for spin in (0, 1):\n",
    "                for layer in order:\n",
    "                    ps = grads[k][layer][spin]\n",
    "                    tmp.append(ps)\n",
    "\n",
    "        else:\n",
    "            tmp.append(value)\n",
    "\n",
    "    sd = model_tc.state_dict(keep_vars=True)\n",
    "    for (k, val), p in zip(sd.items(), tmp):\n",
    "        g = val.grad\n",
    "        if not (g is None): \n",
    "            print(k, df(g, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sharp-martial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: \n",
      " n_atoms = 1 \n",
      " n_up    = 2 \n",
      " n_down  = 2 \n",
      "\n",
      "converged SCF energy = -14.351880476202\n"
     ]
    }
   ],
   "source": [
    "# randomness\n",
    "key = rnd.PRNGKey(1)\n",
    "key, *subkeys = rnd.split(key, num=3)\n",
    "\n",
    "# system\n",
    "n_walkers = 1024\n",
    "n_el = 4\n",
    "r_atoms = jnp.array([[0.0, 0.0, 0.0]])\n",
    "z_atoms = jnp.array([4.])\n",
    "\n",
    "# ansatz\n",
    "n_layers = 1\n",
    "n_sh = 4\n",
    "n_ph = 2\n",
    "n_det = 1\n",
    "\n",
    "mol = Molecule(r_atoms, z_atoms, n_el, n_det=n_det, n_sh=n_sh, n_ph=n_ph, n_layers=n_layers)\n",
    "walkers = mol.initialise_walkers(n_walkers=n_walkers)\n",
    "wf, wf_orbitals = create_wf(mol)\n",
    "vwf = vmap(wf, in_axes=(None, 0, 0))\n",
    "sampler = create_sampler(wf, correlation_length=10)\n",
    "params = initialise_params(subkeys[0], mol)\n",
    "compute_energy = create_energy_fn(wf, r_atoms, z_atoms)\n",
    "laplacian_jax = jit(vmap(local_kinetic_energy(wf), in_axes=(None, 0)))\n",
    "loss_function, sampler = create_loss_and_sampler(mol, wf, wf_orbitals)\n",
    "\n",
    "loss_function2 = grad(loss_function)\n",
    "loss_function = value_and_grad(loss_function)\n",
    "\n",
    "\n",
    "# walkers_tc = from_np(walkers)\n",
    "# r_atoms_tc = from_np(create_atom_batch(r_atoms, n_walkers))\n",
    "# z_atoms_tc = from_np(z_atoms)\n",
    "\n",
    "# mol_tc = Moleculetc(r_atoms_tc, z_atoms_tc, n_el, device='cpu', dtype=r_atoms_tc.dtype)\n",
    "\n",
    "# wf_tc = fermiNet(mol_tc, diagonal=False)\n",
    "# wf_tc = update_state_dict(wf_tc, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "numerous-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class fermiNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 mol,\n",
    "                 diagonal: bool = False):\n",
    "\n",
    "        super(fermiNet, self).__init__()\n",
    "        \n",
    "        from pytorch.models.og.model import Mixer, LinearSplit, LinearSingle, LinearPairwise, EnvelopeLinear, EnvelopeSigma, EnvelopePi\n",
    "        \n",
    "        \n",
    "        self.device = mol.device\n",
    "        self.dtype = mol.dtype\n",
    "        dv, dt = self.device, self.dtype\n",
    "        self.diagonal = diagonal\n",
    "        \n",
    "        n_layers, n_sh, n_ph, n_det = mol.n_layers, mol.n_sh, mol.n_ph, mol.n_det\n",
    "        r_atoms, n_el, n_up, n_atoms = mol.r_atoms, mol.n_el, mol.n_up, mol.n_atoms\n",
    "        #r_atoms = from_np(r_atoms)\n",
    "\n",
    "        # things we need\n",
    "        self.n_layers = n_layers\n",
    "        self.r_atoms = r_atoms\n",
    "        self.n_el = int(n_el)\n",
    "        self.n_pairwise = int(n_el ** 2 - int(not diagonal) * n_el)\n",
    "        self.n_up = n_up\n",
    "        self.n_down = n_el - n_up\n",
    "        self.n_atoms = int(n_atoms)\n",
    "        n_down = n_el - n_up\n",
    "        self.n_determinants = n_det\n",
    "\n",
    "        # layers\n",
    "        s_in = 4 * n_atoms\n",
    "        p_in = 4\n",
    "        s_hidden = n_sh\n",
    "        self.s_hidden = s_hidden\n",
    "        p_hidden = n_ph\n",
    "        self.p_hidden = p_hidden\n",
    "        s_mixed_in = 4 * n_atoms + 4 * 2\n",
    "        s_mixed = n_sh * 3 + n_ph * 2\n",
    "\n",
    "        self.mix_in = Mixer(s_in, p_in, n_el, n_up, diagonal, dv, dt)\n",
    "        self.lin_split_in = LinearSplit(2 * s_in, s_hidden, dv, dt)\n",
    "\n",
    "        self.stream_s0 = LinearSingle(s_mixed_in, s_hidden, dv, dt)\n",
    "        self.stream_p0 = LinearPairwise(p_in, p_hidden, dv, dt)\n",
    "        self.m0 = Mixer(s_hidden, p_hidden, n_el, n_up, diagonal, dv, dt)\n",
    "\n",
    "        self.single_splits = \\\n",
    "            tc.nn.ModuleList([LinearSplit(2 * s_hidden, s_hidden, dv, dt) for _ in range(n_layers)])\n",
    "        self.single_intermediate = \\\n",
    "            tc.nn.ModuleList([LinearSingle(s_mixed - 2 * s_hidden, s_hidden, dv, dt) for _ in range(n_layers)])\n",
    "        self.pairwise_intermediate = \\\n",
    "            tc.nn.ModuleList([LinearPairwise(p_hidden, p_hidden, dv, dt) for _ in range(n_layers)])\n",
    "        self.intermediate_mix = Mixer(s_hidden, p_hidden, n_el, n_up, diagonal, dv, dt)\n",
    "\n",
    "        self.env_up_linear = EnvelopeLinear(s_hidden, n_up, n_det, dv, dt)\n",
    "        self.env_up_sigma = EnvelopeSigma(n_up, n_det, n_atoms, dv, dt)\n",
    "        self.env_up_pi = EnvelopePi(n_up, n_det, n_atoms, dv, dt)\n",
    "\n",
    "        self.env_down_linear = EnvelopeLinear(s_hidden, n_down, n_det, dv, dt)\n",
    "        self.env_down_sigma = EnvelopeSigma(n_down, n_det, n_atoms, dv, dt)\n",
    "        self.env_down_pi = EnvelopePi(n_down, n_det, n_atoms, dv, dt)\n",
    "\n",
    "        print('Model: \\n',\n",
    "              'device   = %s \\n' % self.device,\n",
    "              'n_sh     = %i \\n' % n_sh,\n",
    "              'n_ph     = %i \\n' % n_ph,\n",
    "              'n_layers = %i \\n' % n_layers,\n",
    "              'n_det    = %i \\n' % n_det)\n",
    "\n",
    "    def layers(self):\n",
    "        for m in self.children():\n",
    "            if len(list(m.parameters())) == 0:\n",
    "                continue\n",
    "            elif isinstance(m, tc.nn.ModuleList):\n",
    "                yield from m\n",
    "            else:\n",
    "                yield m\n",
    "\n",
    "    def forward(self, walkers):\n",
    "        from pytorch.models.og.model import logabssumdet\n",
    "\n",
    "        up_orbitals, down_orbitals = self.generate_orbitals(walkers)\n",
    "\n",
    "        # logabssumdet\n",
    "        log_psi = logabssumdet(up_orbitals, down_orbitals)\n",
    "\n",
    "        return log_psi\n",
    "\n",
    "    def generate_orbitals(self, walkers):\n",
    "        from pytorch.models.og.model import compute_ae_vectors, compute_inputs\n",
    "        #walkers = from_np(walkers)\n",
    "        n_walkers = int(walkers.shape[0])\n",
    "\n",
    "        self.single_input_residual = tc.zeros((n_walkers, self.n_el, self.s_hidden), device=walkers.device, dtype=walkers.dtype)\n",
    "        self.pairwise_input_residual = tc.zeros((n_walkers, self.n_pairwise, self.p_hidden), device=walkers.device, dtype=walkers.dtype)\n",
    "\n",
    "        ae_vectors = compute_ae_vectors(self.r_atoms, walkers)\n",
    "\n",
    "        # the inputs\n",
    "        single, pairwise = compute_inputs(walkers, n_walkers, ae_vectors, self.n_atoms, self.n_el)\n",
    "\n",
    "        if self.diagonal:\n",
    "            diagonal_pairwise_input = tc.zeros((n_walkers, self.n_el, 4), device=walkers.device, dtype=walkers.dtype)\n",
    "            pairwise = tc.cat((pairwise, diagonal_pairwise_input), dim=1)\n",
    "\n",
    "        # mix in\n",
    "        single_mixed, single_split = self.mix_in(single, pairwise)\n",
    "\n",
    "        # first layer\n",
    "        single_split = self.lin_split_in(single_split)\n",
    "        single = self.stream_s0(single_mixed, single_split, self.single_input_residual)\n",
    "        pairwise = self.stream_p0(pairwise, self.pairwise_input_residual)\n",
    "\n",
    "        # intermediate layers\n",
    "        for ss, ls, ps in zip(self.single_intermediate, self.single_splits, self.pairwise_intermediate):\n",
    "            single_mixed, single_split = self.intermediate_mix(single, pairwise)\n",
    "\n",
    "            single_split = ls(single_split)\n",
    "            single = ss(single_mixed, single_split, single)\n",
    "            pairwise = ps(pairwise, pairwise)\n",
    "\n",
    "        # single_mixed = tc.cat((single_mixed, single_split.repeat(1, self.n_el, 1)), dim=2)\n",
    "        # envelopes\n",
    "        ae_vectors_up, ae_vectors_down = ae_vectors.split([self.n_up, self.n_down], dim=1)\n",
    "        data_up, data_down = single.split([self.n_up, self.n_down], dim=1)\n",
    "\n",
    "        factor_up = self.env_up_linear(data_up)\n",
    "        factor_down = self.env_down_linear(data_down)\n",
    "\n",
    "        exponent_up = self.env_up_sigma(ae_vectors_up)\n",
    "        exponent_down = self.env_down_sigma(ae_vectors_down)\n",
    "\n",
    "        up_orbitals = self.env_up_pi(factor_up, exponent_up)\n",
    "        down_orbitals = self.env_down_pi(factor_down, exponent_down)\n",
    "\n",
    "        return up_orbitals, down_orbitals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "express-tutorial",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: \n",
      " n_atoms = 1 \n",
      " n_up    = 2 \n",
      " n_down  = 2 \n",
      "\n",
      "converged SCF energy = -14.351880476202\n",
      "System: \n",
      " Device  = cpu \n",
      " dtype   = torch.float64 \n",
      " n_atoms = 1 \n",
      " n_up    = 2 \n",
      " n_down  = 2 \n",
      "\n",
      "converged SCF energy = -14.351880476202\n",
      "Model: \n",
      " device   = cpu \n",
      " n_sh     = 4 \n",
      " n_ph     = 2 \n",
      " n_layers = 1 \n",
      " n_det    = 1 \n",
      "\n",
      "lin_split_in.w torch.Size([8, 4]) (8, 4)\n",
      "stream_s0.w torch.Size([13, 4]) (13, 4)\n",
      "stream_p0.w torch.Size([5, 2]) (5, 2)\n",
      "single_splits.0.w torch.Size([8, 4]) (8, 4)\n",
      "single_intermediate.0.w torch.Size([9, 4]) (9, 4)\n",
      "pairwise_intermediate.0.w torch.Size([3, 2]) (3, 2)\n",
      "env_up_linear.w torch.Size([1, 2, 5]) (1, 2, 5)\n",
      "env_up_sigma.sigma_einsum torch.Size([1, 2, 1, 3, 3]) (1, 2, 1, 3, 3)\n",
      "env_up_pi.pi torch.Size([1, 2, 1]) (1, 2, 1)\n",
      "env_down_linear.w torch.Size([1, 2, 5]) (1, 2, 5)\n",
      "env_down_sigma.sigma_einsum torch.Size([1, 2, 1, 3, 3]) (1, 2, 1, 3, 3)\n",
      "env_down_pi.pi torch.Size([1, 2, 1]) (1, 2, 1)\n",
      "LOSS DIFF:  1.32237970573712e-14 \n",
      "\n",
      "lin_split_in.w 8.555471364357636e-06\n",
      "stream_s0.w 4.795377086872157e-10\n",
      "stream_p0.w 8.624219560715574e-10\n",
      "single_splits.0.w 2.681938283233265e-06\n",
      "single_intermediate.0.w 3.189167448643578e-10\n",
      "env_up_linear.w 6.417891995624814e-10\n",
      "env_up_sigma.sigma_einsum 8.274304362269428e-06\n",
      "env_up_pi.pi 3.410605131648481e-13\n",
      "env_down_linear.w 9.199112582791713e-11\n",
      "env_down_sigma.sigma_einsum 7.640824696390307e-05\n",
      "env_down_pi.pi 7.958078640513122e-13\n"
     ]
    }
   ],
   "source": [
    "from ops.wf.ferminet import *\n",
    "\n",
    "def create_wf(mol):\n",
    "\n",
    "    n_up, n_down, r_atoms, n_el = mol.n_up, mol.n_down, mol.r_atoms, mol.n_el\n",
    "    masks = create_masks(mol.n_atoms, mol.n_el, mol.n_up, mol.n_layers, mol.n_sh, mol.n_ph)\n",
    "\n",
    "    def _wf_orbitals(params, walkers):\n",
    "\n",
    "        if len(walkers.shape) == 1:  # this is a hack to get around the jvp\n",
    "            walkers = walkers.reshape(n_up+n_down, 3)\n",
    "\n",
    "        ae_vectors = compute_ae_vectors_i(walkers, r_atoms)\n",
    "\n",
    "        single, pairwise = compute_inputs_i(walkers, ae_vectors)\n",
    "\n",
    "        single_mixed, split = mixer_i(single, pairwise, n_el, n_up, n_down, *masks[0])\n",
    "\n",
    "        split = linear_split(params['split0'], split)\n",
    "        single = linear(params['s0'], single_mixed, split)\n",
    "        pairwise = linear_pairwise(params['p0'], pairwise)\n",
    "\n",
    "        for (split_params, s_params, p_params), mask in zip(params['intermediate'], masks[1:]):\n",
    "\n",
    "            single_mixed, split = mixer_i(single, pairwise, n_el, n_up, n_down, *mask)\n",
    "\n",
    "            split = linear_split(split_params, split)\n",
    "            single = linear(s_params, single_mixed, split) + single\n",
    "            pairwise = linear_pairwise(p_params, pairwise) + pairwise\n",
    "\n",
    "        ae_up, ae_down = jnp.split(ae_vectors, [n_up], axis=0)\n",
    "        data_up, data_down = jnp.split(single, [n_up], axis=0)\n",
    "\n",
    "        factor_up = env_linear_i(params['envelopes']['linear'][0], data_up)\n",
    "        factor_down = env_linear_i(params['envelopes']['linear'][1], data_down)\n",
    "\n",
    "        exp_up = env_sigma_i(params['envelopes']['sigma'][0], ae_up)\n",
    "        exp_down = env_sigma_i(params['envelopes']['sigma'][1], ae_down)\n",
    "\n",
    "        orb_up = env_pi_i(params['envelopes']['pi'][0], factor_up, exp_up)\n",
    "        orb_down = env_pi_i(params['envelopes']['pi'][1], factor_down, exp_down)\n",
    "        return orb_up, orb_down\n",
    "\n",
    "    def _wf(params, walkers):\n",
    "\n",
    "        orb_up, orb_down = _wf_orbitals(params, walkers)\n",
    "        log_psi = logabssumdet(orb_up, orb_down)\n",
    "        return log_psi\n",
    "\n",
    "    return _wf, _wf_orbitals\n",
    "\n",
    "\n",
    "# system\n",
    "n_walkers = 1024\n",
    "n_el = 4\n",
    "r_atoms = jnp.array([[0.0, 0.0, 0.0]])\n",
    "z_atoms = jnp.array([4.])\n",
    "\n",
    "# ansatz\n",
    "n_layers = 1\n",
    "n_sh = 4\n",
    "n_ph = 2\n",
    "n_det = 1\n",
    "\n",
    "mol = Molecule(r_atoms, z_atoms, n_el, n_det=n_det, n_sh=n_sh, n_ph=n_ph, n_layers=n_layers)\n",
    "walkers = mol.initialise_walkers(n_walkers=n_walkers)\n",
    "params = initialise_params(subkeys[0], mol)\n",
    "\n",
    "walkers_tc = from_np(walkers)\n",
    "r_atoms_tc = from_np(create_atom_batch(r_atoms, n_walkers))\n",
    "z_atoms_tc = from_np(z_atoms)\n",
    "mol_tc = Moleculetc(r_atoms_tc, z_atoms_tc, n_el, device='cpu', dtype=r_atoms_tc.dtype, n_det=n_det, n_sh=n_sh, n_ph=n_ph, n_layers=n_layers)\n",
    "wf_tc = fermiNet(mol_tc)\n",
    "wf_tc = update_state_dict(wf_tc, params)\n",
    "\n",
    "wf, _ = create_wf(mol)\n",
    "vwf = vmap(wf, in_axes=(None, 0, 0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lp = vwf(params, walkers)\n",
    "lp_tc = wf_tc(walkers_tc)\n",
    "print('LOSS DIFF: ', df(lp_tc, lp), '\\n')\n",
    "\n",
    "wf_tc.zero_grad()\n",
    "lp_loss_tc = lp_tc.sum()\n",
    "lp_loss_tc.backward()\n",
    "\n",
    "def swf(params, walkers):\n",
    "    lp = vwf(params, walkers)\n",
    "    return jnp.sum(lp)\n",
    "\n",
    "lp_grad_fn = grad(swf)\n",
    "grads = lp_grad_fn(params, walkers)\n",
    "\n",
    "compare_grads(wf_tc, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lp, lp_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pretrainer():\n",
    "    def __init__(self,\n",
    "                 mol,\n",
    "                 n_pretrain_iterations: int = 1000):\n",
    "\n",
    "        self.mol = mol\n",
    "\n",
    "        self.n_up = mol.n_up\n",
    "        self.n_down = mol.n_down\n",
    "        self.n_el = mol.n_el\n",
    "\n",
    "        self.n_iterations = n_pretrain_iterations\n",
    "\n",
    "    def compute_orbital_probability(self, samples):\n",
    "        up_dets, down_dets = self.hf_orbitals(samples)\n",
    "\n",
    "        spin_ups = up_dets ** 2\n",
    "        spin_downs = down_dets ** 2\n",
    "\n",
    "        p_up = tc.diagonal(spin_ups, dim1=-2, dim2=-1).prod(-1)\n",
    "        p_down = tc.diagonal(spin_downs, dim1=-2, dim2=-1).prod(-1)\n",
    "        # p_up = spin_ups.prod(1).prod(1)\n",
    "        # p_down = spin_downs.prod(1).prod(1)\n",
    "\n",
    "        probabilities = p_up * p_down\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    def pyscf_call(self, samples):\n",
    "        samples = samples.cpu().numpy()\n",
    "        ao_values = self.mol.pyscf_mol.eval_gto(\"GTOval_cart\", samples)\n",
    "        return tc.from_numpy(ao_values)\n",
    "\n",
    "    def hf_orbitals(self, coord):\n",
    "        coord = coord.view((-1, 3))\n",
    "\n",
    "        number_spin_down = self.n_down\n",
    "        number_spin_up = self.n_el - number_spin_down\n",
    "\n",
    "        ao_values = self.pyscf_call(coord).to(device=coord.device, dtype=coord.dtype)\n",
    "        ao_values = ao_values.view((int(len(ao_values) / self.n_el), self.n_el, len(ao_values[0])))\n",
    "\n",
    "        spin_up = tc.stack([(self.mol.moT[orb_number, :] * ao_values[:, el_number, :]).sum(-1)\n",
    "             for orb_number in range(number_spin_up) for el_number in\n",
    "             range(number_spin_up)], dim=1).view((-1, number_spin_up, number_spin_up))\n",
    "\n",
    "        spin_down = tc.stack([(self.mol.moT[orb_number, :] * ao_values[:, el_number, :]).sum(-1)\n",
    "                            for orb_number in range(number_spin_down) for el_number in\n",
    "                            range(number_spin_up, self.n_el)], dim=1).view((-1, number_spin_down, number_spin_down))\n",
    "\n",
    "        return spin_up, spin_down\n",
    "    \n",
    "tc_hf = Pretrainer(mol_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the losses\n",
    "def compare_grads(model_tc, grads):\n",
    "    tmp = []\n",
    "    for k, value in grads.items():\n",
    "        if k == 'intermediate':\n",
    "            for intermediate in zip(*grads[k]):\n",
    "                for ps in intermediate:\n",
    "                    tmp.append(ps)\n",
    "\n",
    "        elif k == 'envelopes':\n",
    "            order = ('linear', 'sigma', 'pi')\n",
    "            for spin in (0, 1):\n",
    "                for layer in order:\n",
    "                    ps = grads[k][layer][spin]\n",
    "                    tmp.append(ps)\n",
    "\n",
    "        else:\n",
    "            tmp.append(value)\n",
    "\n",
    "    sd = model_tc.state_dict(keep_vars=True)\n",
    "    for (k, val), p in zip(sd.items(), tmp):\n",
    "#         print(k, val.shape, p.shape)\n",
    "#         print(k)\n",
    "        assert val.shape == p.shape\n",
    "        if val.grad is None:   # the hanging pairwise stream is None in pytorch\n",
    "#             print(jnp.sum(jnp.abs(p)))\n",
    "            continue\n",
    "        g = val.grad.detach().cpu().numpy()\n",
    "#         print(jnp.mean(jnp.abs(g - p)))\n",
    "        \n",
    "#         if k in ('env_up_sigma.sigma_einsum', 'env_down_sigma.sigma_einsum'):\n",
    "#             print(g[0], '\\n', p[0])\n",
    "            \n",
    "        if k in ('single_splits.0.w',):\n",
    "            print(k)\n",
    "#             print(g[0], '\\n', p[0])\n",
    "            print(g, '\\n', p)\n",
    "            print(jnp.mean(jnp.abs(p)) / jnp.mean(jnp.abs(g)))\n",
    "#         sd[kprint(g[0], '\\n', p[0]) = from_np(p)\n",
    "\n",
    "#     model_tc.load_state_dict(sd, strict=True\n",
    "    \n",
    "    \n",
    "up_dets, down_dets = tc_hf.hf_orbitals(walkers_tc)\n",
    "up_dets = tile_labels(up_dets, wf_tc.n_determinants)\n",
    "down_dets = tile_labels(down_dets, wf_tc.n_determinants)\n",
    "\n",
    "model_up_dets, model_down_dets = wf_tc.generate_orbitals(walkers_tc)\n",
    "\n",
    "loss = mse_error(up_dets, model_up_dets)\n",
    "loss += mse_error(down_dets, model_down_dets)\n",
    "wf_tc.zero_grad()\n",
    "print(loss)\n",
    "\n",
    "loss.backward()  # in order for hook to work must call backward\n",
    "\n",
    "grads1 = loss_function2(params, walkers)\n",
    "loss_value, grads2 = loss_function(params, walkers)\n",
    "print(loss_value)\n",
    "\n",
    "compare_grads(wf_tc, grads1)\n",
    "# compare_grads(wf_tc, grads2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-cursor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "device, dtype = wf_tc.device, wf_tc.dtype\n",
    "sampler = MetropolisHastingsPretrain()\n",
    "wf_walkers = walkers\n",
    "\n",
    "wf_sampler = MetropolisHasting(wf)\n",
    "for i in range(500):\n",
    "    wf_walkers, wf_acc = wf_sampler(wf_walkers)\n",
    "    e_locs = compute_local_energy(wf, wf_walkers, self.mol.r_atoms, self.mol.z_atoms)\n",
    "    print(e_locs.mean())\n",
    "\n",
    "\n",
    "opt = tc.optim.Adam(list(wf.parameters()), lr=lr)\n",
    "steps = trange(\n",
    "    0,  # init_step = 0\n",
    "    n_it,\n",
    "    initial=0,\n",
    "    total=n_it,\n",
    "    desc='pretraining',\n",
    "    disable=None,\n",
    ")\n",
    "\n",
    "# walkers = initialize_walkers(self.mol.n_el_atoms, self.mol.atom_positions, n_walkers).to(device=device, dtype=dtype)\n",
    "\n",
    "for step in steps:\n",
    "    wf_walkers, wf_acc = wf_sampler(wf_walkers)\n",
    "    e_locs = compute_local_energy(wf, wf_walkers, self.mol.r_atoms,  self.mol.z_atoms)\n",
    "\n",
    "    walkers = sampler(wf, self, walkers)\n",
    "\n",
    "    up_dets, down_dets = hf_orbitals(walkers)\n",
    "    up_dets = tile_labels(up_dets, wf.n_determinants)\n",
    "    down_dets = tile_labels(down_dets, wf.n_determinants)\n",
    "\n",
    "    model_up_dets, model_down_dets = wf.generate_orbitals(walkers)\n",
    "\n",
    "    loss = mse_error(up_dets, model_up_dets)\n",
    "    loss += mse_error(down_dets, model_down_dets)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()  # in order for hook to work must call backward\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import trange\n",
    "from jax import value_and_grad, grad, vmap, jit\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as rnd\n",
    "from jax.experimental.optimizers import adam\n",
    "from jax.tree_util import tree_unflatten, tree_flatten\n",
    "\n",
    "from ops.pretraining import create_loss_and_sampler, equilibrate\n",
    "from ops.vmc import create_energy_fn\n",
    "from ops.\n",
    "\n",
    "\n",
    "\n",
    "compute_local_energy = create_energy_fn(wf, mol.r_atoms, mol.z_atoms)\n",
    "\n",
    "loss_function, sampler = create_loss_and_sampler(mol, wf, wf_orbitals)\n",
    "loss_function = value_and_grad(loss_function)\n",
    "\n",
    "walkers, step_size = equilibrate(params, walkers, compute_local_energy, sampler, key, n_it=50, step_size=0.02)\n",
    "wf_walkers = jnp.array(walkers, copy=True)\n",
    "\n",
    "init, update, get_params = adam(1e-3)\n",
    "state = init(params)\n",
    "\n",
    "steps = trange(0, n_it, initial=0, total=n_it, desc='pretraining', disable=None)\n",
    "for step in steps:\n",
    "    key, *subkeys = rnd.split(key, num=3)\n",
    "\n",
    "    wf_walkers, acc = wf_sampler(params, wf_walkers, subkeys[0], step_size)\n",
    "    e_locs = compute_local_energy(params, wf_walkers)\n",
    "\n",
    "    walkers, mix_acc = sampler(params, walkers, subkeys[1], step_size)\n",
    "\n",
    "    loss_value, grads = loss_function(params, walkers)\n",
    "\n",
    "    params = sgd(params, grads, lr)\n",
    "    # state = update(step, grads, state)\n",
    "    # params = get_params(state)\n",
    "\n",
    "\n",
    "    print('step %i | e_mean %.2f | loss %.2f | wf_acc %.2f | mix_acc %.2f |'\n",
    "          % (step, jnp.mean(e_locs), loss_value, acc, mix_acc))\n",
    "    # steps.set_postfix(E=f'{e_locs.mean():.6f}')\n",
    "\n",
    "return params, walkers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
