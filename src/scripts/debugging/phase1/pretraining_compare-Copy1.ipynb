{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heavy-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "express-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ops.utils import compare\n",
    "from functools import partial\n",
    "\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random as rnd\n",
    "from jax import lax, jit, vmap, value_and_grad, grad\n",
    "from jax.tree_util import tree_structure, tree_flatten, tree_unflatten\n",
    "\n",
    "from pytorch.models.og.model import fermiNet\n",
    "from pytorch.sampling import MetropolisHasting\n",
    "from pytorch.vmc import *\n",
    "from pytorch.pretraining_v2 import Pretrainer, tile_labels, mse_error\n",
    "from pytorch.systems import Molecule as Moleculetc\n",
    "from pytorch.utils import update_state_dict, from_np\n",
    "import torch as tc\n",
    "tc.set_default_dtype(tc.float64)\n",
    "\n",
    "from ops.vmc.utils import create_atom_batch\n",
    "from ops.systems import Molecule\n",
    "from ops.wf.ferminet import create_wf, create_masks\n",
    "from ops.wf.parameters import initialise_params, count_mixed_features\n",
    "from ops.sampling import create_sampler\n",
    "from ops.vmc import create_energy_fn, local_kinetic_energy, compute_potential_energy\n",
    "from ops.pretraining import create_loss_and_sampler\n",
    "\n",
    "def df(arr_tc, arr_jax):\n",
    "    arr_tc = arr_tc.detach().cpu().numpy()\n",
    "    diff = jnp.mean(jnp.abs(arr_tc - arr_jax)) \n",
    "    print(diff)\n",
    "    return diff\n",
    "    \n",
    "def compare_grads(model_tc, grads):\n",
    "    tmp = []\n",
    "    for k, value in grads.items():\n",
    "        if k == 'intermediate':\n",
    "            for intermediate in zip(*params[k]):\n",
    "                for ps in intermediate:\n",
    "                    tmp.append(ps)\n",
    "\n",
    "        elif k == 'envelopes':\n",
    "            order = ('linear', 'sigma', 'pi')\n",
    "            for spin in (0, 1):\n",
    "                for layer in order:\n",
    "                    ps = grads[k][layer][spin]\n",
    "                    tmp.append(ps)\n",
    "\n",
    "        else:\n",
    "            tmp.append(value)\n",
    "\n",
    "    sd = model_tc.state_dict(keep_vars=True)\n",
    "    for (k, val), p in zip(sd.items(), tmp):\n",
    "        g = val.grad\n",
    "        if not g is None: \n",
    "            diff = df(g, p)\n",
    "            if diff > 0.001:\n",
    "                print(k, diff)\n",
    "                print(g[0], '\\n', p[0], '\\n')\n",
    "                \n",
    "                print(g[2], '\\n', p[2], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sharp-martial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: \n",
      " n_atoms = 1 \n",
      " n_up    = 2 \n",
      " n_down  = 2 \n",
      "\n",
      "converged SCF energy = -14.351880476202\n",
      "System: \n",
      " Device  = cpu \n",
      " dtype   = torch.float64 \n",
      " n_atoms = 1 \n",
      " n_up    = 2 \n",
      " n_down  = 2 \n",
      "\n",
      "converged SCF energy = -14.351880476202\n",
      "Model: \n",
      " device   = cpu \n",
      " n_sh     = 4 \n",
      " n_ph     = 2 \n",
      " n_layers = 1 \n",
      " n_det    = 1 \n",
      "\n",
      "lin_split_in.w torch.Size([8, 4]) (8, 4)\n",
      "stream_s0.w torch.Size([13, 4]) (13, 4)\n",
      "stream_p0.w torch.Size([5, 2]) (5, 2)\n",
      "single_splits.0.w torch.Size([8, 4]) (8, 4)\n",
      "single_intermediate.0.w torch.Size([9, 4]) (9, 4)\n",
      "pairwise_intermediate.0.w torch.Size([3, 2]) (3, 2)\n",
      "env_up_linear.w torch.Size([1, 2, 5]) (1, 2, 5)\n",
      "env_up_sigma.sigma_einsum torch.Size([1, 2, 1, 3, 3]) (1, 2, 1, 3, 3)\n",
      "env_up_pi.pi torch.Size([1, 2, 1]) (1, 2, 1)\n",
      "env_down_linear.w torch.Size([1, 2, 5]) (1, 2, 5)\n",
      "env_down_sigma.sigma_einsum torch.Size([1, 2, 1, 3, 3]) (1, 2, 1, 3, 3)\n",
      "env_down_pi.pi torch.Size([1, 2, 1]) (1, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "# randomness\n",
    "key = rnd.PRNGKey(1)\n",
    "key, *subkeys = rnd.split(key, num=3)\n",
    "\n",
    "# system\n",
    "n_walkers = 1024\n",
    "n_el = 4\n",
    "r_atoms = jnp.array([[0.0, 0.0, 0.0]])\n",
    "z_atoms = jnp.array([4.])\n",
    "\n",
    "# ansatz\n",
    "n_layers = 1\n",
    "n_sh = 4\n",
    "n_ph = 2\n",
    "n_det = 1\n",
    "\n",
    "mol = Molecule(r_atoms, z_atoms, n_el, n_det=n_det, n_sh=n_sh, n_ph=n_ph, n_layers=n_layers)\n",
    "walkers = mol.initialise_walkers(n_walkers=n_walkers)\n",
    "wf, wf_orbitals = create_wf(mol)\n",
    "vwf = vmap(wf, in_axes=(None, 0, 0))\n",
    "sampler = create_sampler(wf, correlation_length=10)\n",
    "params = initialise_params(subkeys[0], mol)\n",
    "compute_energy = create_energy_fn(wf, r_atoms, z_atoms)\n",
    "laplacian_jax = jit(vmap(local_kinetic_energy(wf), in_axes=(None, 0)))\n",
    "loss_function, sampler = create_loss_and_sampler(mol, wf, wf_orbitals)\n",
    "\n",
    "loss_function2 = grad(loss_function)\n",
    "loss_function = value_and_grad(loss_function)\n",
    "\n",
    "\n",
    "walkers_tc = from_np(walkers)\n",
    "r_atoms_tc = from_np(create_atom_batch(r_atoms, n_walkers))\n",
    "z_atoms_tc = from_np(z_atoms)\n",
    "\n",
    "mol_tc = Moleculetc(r_atoms_tc, z_atoms_tc, n_el, device='cpu', dtype=r_atoms_tc.dtype)\n",
    "\n",
    "wf_tc = fermiNet(mol_tc, n_det=n_det, n_sh=n_sh, n_ph=n_ph, n_layers=n_layers, diagonal=False)\n",
    "wf_tc = update_state_dict(wf_tc, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "numerous-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class fermiNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 mol,\n",
    "                 diagonal: bool = False):\n",
    "\n",
    "        super(fermiNet, self).__init__()\n",
    "        \n",
    "        from pytorch.models.og.model import Mixer, LinearSplit, LinearSingle, LinearPairwise, EnvelopeLinear, EnvelopeSigma, EnvelopePi\n",
    "        \n",
    "        \n",
    "        self.device = mol.device\n",
    "        self.dtype = mol.dtype\n",
    "        dv, dt = self.device, self.dtype\n",
    "        self.diagonal = diagonal\n",
    "        \n",
    "        n_layers, n_sh, n_ph, n_det = mol.n_layers, mol.n_sh, mol.n_ph, mol.n_det\n",
    "        r_atoms, n_el, n_up, n_atoms = mol.r_atoms, mol.n_el, mol.n_up, mol.n_atoms\n",
    "        #r_atoms = from_np(r_atoms)\n",
    "\n",
    "        # things we need\n",
    "        self.n_layers = n_layers\n",
    "        self.r_atoms = r_atoms\n",
    "        self.n_el = int(n_el)\n",
    "        self.n_pairwise = int(n_el ** 2 - int(not diagonal) * n_el)\n",
    "        self.n_up = n_up\n",
    "        self.n_down = n_el - n_up\n",
    "        self.n_atoms = int(n_atoms)\n",
    "        n_down = n_el - n_up\n",
    "        self.n_determinants = n_det\n",
    "\n",
    "        # layers\n",
    "        s_in = 4 * n_atoms\n",
    "        p_in = 4\n",
    "        s_hidden = n_sh\n",
    "        self.s_hidden = s_hidden\n",
    "        p_hidden = n_ph\n",
    "        self.p_hidden = p_hidden\n",
    "        s_mixed_in = 4 * n_atoms + 4 * 2\n",
    "        s_mixed = n_sh * 3 + n_ph * 2\n",
    "\n",
    "        self.mix_in = Mixer(s_in, p_in, n_el, n_up, diagonal, dv, dt)\n",
    "        self.lin_split_in = LinearSplit(2 * s_in, s_hidden, dv, dt)\n",
    "\n",
    "        self.stream_s0 = LinearSingle(s_mixed_in, s_hidden, dv, dt)\n",
    "        self.stream_p0 = LinearPairwise(p_in, p_hidden, dv, dt)\n",
    "        self.m0 = Mixer(s_hidden, p_hidden, n_el, n_up, diagonal, dv, dt)\n",
    "\n",
    "        self.single_splits = \\\n",
    "            tc.nn.ModuleList([LinearSplit(2 * s_hidden, s_hidden, dv, dt) for _ in range(n_layers)])\n",
    "        self.single_intermediate = \\\n",
    "            tc.nn.ModuleList([LinearSingle(s_mixed - 2 * s_hidden, s_hidden, dv, dt) for _ in range(n_layers)])\n",
    "        self.pairwise_intermediate = \\\n",
    "            tc.nn.ModuleList([LinearPairwise(p_hidden, p_hidden, dv, dt) for _ in range(n_layers)])\n",
    "        self.intermediate_mix = Mixer(s_hidden, p_hidden, n_el, n_up, diagonal, dv, dt)\n",
    "\n",
    "        self.env_up_linear = EnvelopeLinear(s_hidden, n_up, n_det, dv, dt)\n",
    "        self.env_up_sigma = EnvelopeSigma(n_up, n_det, n_atoms, dv, dt)\n",
    "        self.env_up_pi = EnvelopePi(n_up, n_det, n_atoms, dv, dt)\n",
    "\n",
    "        self.env_down_linear = EnvelopeLinear(s_hidden, n_down, n_det, dv, dt)\n",
    "        self.env_down_sigma = EnvelopeSigma(n_down, n_det, n_atoms, dv, dt)\n",
    "        self.env_down_pi = EnvelopePi(n_down, n_det, n_atoms, dv, dt)\n",
    "\n",
    "        print('Model: \\n',\n",
    "              'device   = %s \\n' % self.device,\n",
    "              'n_sh     = %i \\n' % n_sh,\n",
    "              'n_ph     = %i \\n' % n_ph,\n",
    "              'n_layers = %i \\n' % n_layers,\n",
    "              'n_det    = %i \\n' % n_det)\n",
    "\n",
    "    def layers(self):\n",
    "        for m in self.children():\n",
    "            if len(list(m.parameters())) == 0:\n",
    "                continue\n",
    "            elif isinstance(m, tc.nn.ModuleList):\n",
    "                yield from m\n",
    "            else:\n",
    "                yield m\n",
    "\n",
    "#     def forward(self, walkers):\n",
    "#         from pytorch.models.og.model import logabssumdet\n",
    "\n",
    "#         up_orbitals, down_orbitals = self.generate_orbitals(walkers)\n",
    "\n",
    "#         return up_orbitals\n",
    "\n",
    "    def forward(self, walkers):\n",
    "        from pytorch.models.og.model import compute_ae_vectors, compute_inputs\n",
    "        #walkers = from_np(walkers)\n",
    "        n_walkers = int(walkers.shape[0])\n",
    "\n",
    "        self.single_input_residual = tc.zeros((n_walkers, self.n_el, self.s_hidden), device=walkers.device, dtype=walkers.dtype)\n",
    "        self.pairwise_input_residual = tc.zeros((n_walkers, self.n_pairwise, self.p_hidden), device=walkers.device, dtype=walkers.dtype)\n",
    "\n",
    "        ae_vectors = compute_ae_vectors(self.r_atoms, walkers)\n",
    "\n",
    "        # the inputs\n",
    "        single, pairwise = compute_inputs(walkers, n_walkers, ae_vectors, self.n_atoms, self.n_el)\n",
    "\n",
    "        if self.diagonal:\n",
    "            diagonal_pairwise_input = tc.zeros((n_walkers, self.n_el, 4), device=walkers.device, dtype=walkers.dtype)\n",
    "            pairwise = tc.cat((pairwise, diagonal_pairwise_input), dim=1)\n",
    "\n",
    "        # mix in\n",
    "        single_mixed, single_split = self.mix_in(single, pairwise)\n",
    "\n",
    "        # first layer\n",
    "        single_split = self.lin_split_in(single_split)\n",
    "        single = self.stream_s0(single_mixed, single_split, self.single_input_residual)\n",
    "        pairwise = self.stream_p0(pairwise, self.pairwise_input_residual)\n",
    "\n",
    "        # intermediate layers\n",
    "        for ss, ls, ps in zip(self.single_intermediate, self.single_splits, self.pairwise_intermediate):\n",
    "            single_mixed, single_split = self.intermediate_mix(single, pairwise)\n",
    "\n",
    "            single_split = ls(single_split)\n",
    "            single_res = single*0.\n",
    "            single = ss(single_mixed, single_split, single_res)\n",
    "\n",
    "        return single\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "express-tutorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: \n",
      " n_atoms = 1 \n",
      " n_up    = 2 \n",
      " n_down  = 2 \n",
      "\n",
      "converged SCF energy = -14.351880476202\n",
      "System: \n",
      " Device  = cpu \n",
      " dtype   = torch.float64 \n",
      " n_atoms = 1 \n",
      " n_up    = 2 \n",
      " n_down  = 2 \n",
      "\n",
      "converged SCF energy = -14.351880476202\n",
      "Model: \n",
      " device   = cpu \n",
      " n_sh     = 4 \n",
      " n_ph     = 2 \n",
      " n_layers = 1 \n",
      " n_det    = 1 \n",
      "\n",
      "lin_split_in.w torch.Size([8, 4]) (8, 4)\n",
      "stream_s0.w torch.Size([13, 4]) (13, 4)\n",
      "stream_p0.w torch.Size([5, 2]) (5, 2)\n",
      "single_splits.0.w torch.Size([8, 4]) (8, 4)\n",
      "single_intermediate.0.w torch.Size([9, 4]) (9, 4)\n",
      "pairwise_intermediate.0.w torch.Size([3, 2]) (3, 2)\n",
      "env_up_linear.w torch.Size([1, 2, 5]) (1, 2, 5)\n",
      "env_up_sigma.sigma_einsum torch.Size([1, 2, 1, 3, 3]) (1, 2, 1, 3, 3)\n",
      "env_up_pi.pi torch.Size([1, 2, 1]) (1, 2, 1)\n",
      "env_down_linear.w torch.Size([1, 2, 5]) (1, 2, 5)\n",
      "env_down_sigma.sigma_einsum torch.Size([1, 2, 1, 3, 3]) (1, 2, 1, 3, 3)\n",
      "env_down_pi.pi torch.Size([1, 2, 1]) (1, 2, 1)\n",
      "LOSS DIFF\n",
      "6.33031830889303e-17\n",
      "\n",
      "\n",
      "2.604035311735975e-06\n",
      "2.2947455901290734e-14\n",
      "7.869260798543109e-14\n",
      "1210.477442237797\n",
      "single_splits.0.w 1210.477442237797\n",
      "tensor([ -863.7882, -2014.6901,    17.2212,  -180.6102]) \n",
      " [ 0.19159925 -0.14835714  0.51060385  0.13056381] \n",
      "\n",
      "tensor([-2080.3637, -3371.2311,  -121.2219,  -305.8008]) \n",
      " [ 0.28646317 -0.08596921  0.31779283 -0.66303575] \n",
      "\n",
      "1119.0945499409368\n",
      "single_intermediate.0.w 1119.0945499409368\n",
      "tensor([-1032.7312, -2292.6753,    29.0930,  -185.3227]) \n",
      " [0.26117206 0.2263592  0.68536139 0.23530395] \n",
      "\n",
      "tensor([-2095.0743, -3379.3011,  -123.5705,  -305.4842]) \n",
      " [ 0.38036534 -0.26218987 -0.35897687 -0.45714402] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ops.wf.ferminet import *\n",
    "\n",
    "def create_wf(mol):\n",
    "\n",
    "    n_up, n_down, r_atoms, n_el = mol.n_up, mol.n_down, mol.r_atoms, mol.n_el\n",
    "    masks = create_masks(mol.n_atoms, mol.n_el, mol.n_up, mol.n_layers, mol.n_sh, mol.n_ph)\n",
    "\n",
    "    def _wf(params, walkers):\n",
    "\n",
    "        if len(walkers.shape) == 1:  # this is a hack to get around the jvp\n",
    "            walkers = walkers.reshape(n_up+n_down, 3)\n",
    "\n",
    "        ae_vectors = compute_ae_vectors_i(walkers, r_atoms)\n",
    "\n",
    "        single, pairwise = compute_inputs_i(walkers, ae_vectors)\n",
    "\n",
    "        single_mixed, split = mixer_i(single, pairwise, n_el, n_up, n_down, *masks[0])\n",
    "\n",
    "        split = linear_split(params['split0'], split)\n",
    "        single = linear(params['s0'], single_mixed, split)\n",
    "        pairwise = linear_pairwise(params['p0'], pairwise)\n",
    "\n",
    "        split_params, s_params, p_params = params['intermediate'][0]\n",
    "        mask = masks[1]\n",
    "\n",
    "        single_mixed, split = mixer_i(single, pairwise, n_el, n_up, n_down, *mask)\n",
    "\n",
    "        split = linear_split(split_params, split)\n",
    "        single = linear(s_params, single_mixed, split)\n",
    "\n",
    "        return single\n",
    "\n",
    "    return _wf\n",
    "\n",
    "\n",
    "# system\n",
    "n_walkers = 1024\n",
    "n_el = 4\n",
    "r_atoms = jnp.array([[0.0, 0.0, 0.0]])\n",
    "z_atoms = jnp.array([4.])\n",
    "\n",
    "# ansatz\n",
    "n_layers = 1\n",
    "n_sh = 4\n",
    "n_ph = 2\n",
    "n_det = 1\n",
    "\n",
    "mol = Molecule(r_atoms, z_atoms, n_el, n_det=n_det, n_sh=n_sh, n_ph=n_ph, n_layers=n_layers)\n",
    "walkers = mol.initialise_walkers(n_walkers=n_walkers)\n",
    "params = initialise_params(subkeys[0], mol)\n",
    "\n",
    "walkers_tc = from_np(walkers)\n",
    "r_atoms_tc = from_np(create_atom_batch(r_atoms, n_walkers))\n",
    "z_atoms_tc = from_np(z_atoms)\n",
    "mol_tc = Moleculetc(r_atoms_tc, z_atoms_tc, n_el, device='cpu', dtype=r_atoms_tc.dtype, n_det=n_det, n_sh=n_sh, n_ph=n_ph, n_layers=n_layers)\n",
    "wf_tc = fermiNet(mol_tc)\n",
    "wf_tc = update_state_dict(wf_tc, params)\n",
    "\n",
    "wf = create_wf(mol)\n",
    "vwf = vmap(wf, in_axes=(None, 0, 0))\n",
    "\n",
    "\n",
    "wf_tc.zero_grad()\n",
    "\n",
    "lp = vwf(params, walkers)\n",
    "lp_tc = wf_tc(walkers_tc)\n",
    "\n",
    "print('LOSS DIFF')\n",
    "df(lp_tc, lp)\n",
    "print('\\n')\n",
    "\n",
    "lp_loss_tc = lp_tc.sum()\n",
    "lp_loss_tc.backward()\n",
    "\n",
    "def swf(params, walkers):\n",
    "    lp = vwf(params, walkers)\n",
    "    return jnp.sum(lp)\n",
    "\n",
    "lp_grad_fn = grad(swf)\n",
    "grads = lp_grad_fn(params, walkers)\n",
    "\n",
    "compare_grads(wf_tc, grads)\n",
    "\n",
    "# print(lp[1])\n",
    "# print(lp_tc[1])\n",
    "# print(lp_tc.detach().cpu().numpy() - lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "physical-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pretrainer():\n",
    "    def __init__(self,\n",
    "                 mol,\n",
    "                 n_pretrain_iterations: int = 1000):\n",
    "\n",
    "        self.mol = mol\n",
    "\n",
    "        self.n_up = mol.n_up\n",
    "        self.n_down = mol.n_down\n",
    "        self.n_el = mol.n_el\n",
    "\n",
    "        self.n_iterations = n_pretrain_iterations\n",
    "\n",
    "    def compute_orbital_probability(self, samples):\n",
    "        up_dets, down_dets = self.hf_orbitals(samples)\n",
    "\n",
    "        spin_ups = up_dets ** 2\n",
    "        spin_downs = down_dets ** 2\n",
    "\n",
    "        p_up = tc.diagonal(spin_ups, dim1=-2, dim2=-1).prod(-1)\n",
    "        p_down = tc.diagonal(spin_downs, dim1=-2, dim2=-1).prod(-1)\n",
    "        # p_up = spin_ups.prod(1).prod(1)\n",
    "        # p_down = spin_downs.prod(1).prod(1)\n",
    "\n",
    "        probabilities = p_up * p_down\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    def pyscf_call(self, samples):\n",
    "        samples = samples.cpu().numpy()\n",
    "        ao_values = self.mol.pyscf_mol.eval_gto(\"GTOval_cart\", samples)\n",
    "        return tc.from_numpy(ao_values)\n",
    "\n",
    "    def hf_orbitals(self, coord):\n",
    "        coord = coord.view((-1, 3))\n",
    "\n",
    "        number_spin_down = self.n_down\n",
    "        number_spin_up = self.n_el - number_spin_down\n",
    "\n",
    "        ao_values = self.pyscf_call(coord).to(device=coord.device, dtype=coord.dtype)\n",
    "        ao_values = ao_values.view((int(len(ao_values) / self.n_el), self.n_el, len(ao_values[0])))\n",
    "\n",
    "        spin_up = tc.stack([(self.mol.moT[orb_number, :] * ao_values[:, el_number, :]).sum(-1)\n",
    "             for orb_number in range(number_spin_up) for el_number in\n",
    "             range(number_spin_up)], dim=1).view((-1, number_spin_up, number_spin_up))\n",
    "\n",
    "        spin_down = tc.stack([(self.mol.moT[orb_number, :] * ao_values[:, el_number, :]).sum(-1)\n",
    "                            for orb_number in range(number_spin_down) for el_number in\n",
    "                            range(number_spin_up, self.n_el)], dim=1).view((-1, number_spin_down, number_spin_down))\n",
    "\n",
    "        return spin_up, spin_down\n",
    "    \n",
    "tc_hf = Pretrainer(mol_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naughty-strain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7432, grad_fn=<AddBackward0>)\n",
      "0.7431866161590366\n",
      "single_splits.0.w\n",
      "[[ 0.0395846   0.21111888  0.00150585  0.02713028]\n",
      " [-0.02316328  0.35843016  0.00348127  0.03004971]\n",
      " [-0.02788671  0.40136708  0.0044372   0.03414911]\n",
      " [ 0.03642672 -0.2012093  -0.00100034  0.00042881]\n",
      " [ 0.01944948  0.27694805  0.00156295  0.02711742]\n",
      " [-0.02936083  0.38747432  0.00436606  0.03332011]\n",
      " [-0.0330114   0.40305125  0.00466554  0.03306731]\n",
      " [ 0.03739027 -0.34935674 -0.00373558 -0.020753  ]] \n",
      " [[ 0.19159925 -0.14835714  0.51060385  0.13056381]\n",
      " [ 0.02165198 -0.6838221  -0.18707593  0.3582895 ]\n",
      " [ 0.28646317 -0.08596921  0.31779283 -0.66303575]\n",
      " [ 0.0518322   0.28676125 -0.01401097 -0.11338016]\n",
      " [ 0.00448408 -0.5360741  -0.08405411 -0.536513  ]\n",
      " [-0.6326073  -0.22622964  0.59515196  0.08993056]\n",
      " [-0.32973337 -0.16543783 -0.48901087 -0.19934303]\n",
      " [ 0.6075665  -0.23415759  0.05191307  0.25775766]]\n",
      "2.9651579849493763\n"
     ]
    }
   ],
   "source": [
    "# compare the losses\n",
    "def compare_grads(model_tc, grads):\n",
    "    tmp = []\n",
    "    for k, value in grads.items():\n",
    "        if k == 'intermediate':\n",
    "            for intermediate in zip(*params[k]):\n",
    "                for ps in intermediate:\n",
    "                    tmp.append(ps)\n",
    "\n",
    "        elif k == 'envelopes':\n",
    "            order = ('linear', 'sigma', 'pi')\n",
    "            for spin in (0, 1):\n",
    "                for layer in order:\n",
    "                    ps = grads[k][layer][spin]\n",
    "                    tmp.append(ps)\n",
    "\n",
    "        else:\n",
    "            tmp.append(value)\n",
    "\n",
    "    sd = model_tc.state_dict(keep_vars=True)\n",
    "    for (k, val), p in zip(sd.items(), tmp):\n",
    "#         print(k, val.shape, p.shape)\n",
    "#         print(k)\n",
    "        assert val.shape == p.shape\n",
    "        if val.grad is None:   # the hanging pairwise stream is None in pytorch\n",
    "#             print(jnp.sum(jnp.abs(p)))\n",
    "            continue\n",
    "        g = val.grad.detach().cpu().numpy()\n",
    "#         print(jnp.mean(jnp.abs(g - p)))\n",
    "        \n",
    "#         if k in ('env_up_sigma.sigma_einsum', 'env_down_sigma.sigma_einsum'):\n",
    "#             print(g[0], '\\n', p[0])\n",
    "            \n",
    "        if k in ('single_splits.0.w',):\n",
    "            print(k)\n",
    "#             print(g[0], '\\n', p[0])\n",
    "            print(g, '\\n', p)\n",
    "            print(jnp.mean(jnp.abs(p)) / jnp.mean(jnp.abs(g)))\n",
    "#         sd[kprint(g[0], '\\n', p[0]) = from_np(p)\n",
    "\n",
    "#     model_tc.load_state_dict(sd, strict=True\n",
    "    \n",
    "    \n",
    "up_dets, down_dets = tc_hf.hf_orbitals(walkers_tc)\n",
    "up_dets = tile_labels(up_dets, wf_tc.n_determinants)\n",
    "down_dets = tile_labels(down_dets, wf_tc.n_determinants)\n",
    "\n",
    "model_up_dets, model_down_dets = wf_tc.generate_orbitals(walkers_tc)\n",
    "\n",
    "loss = mse_error(up_dets, model_up_dets)\n",
    "loss += mse_error(down_dets, model_down_dets)\n",
    "wf_tc.zero_grad()\n",
    "print(loss)\n",
    "\n",
    "loss.backward()  # in order for hook to work must call backward\n",
    "\n",
    "grads1 = loss_function2(params, walkers)\n",
    "loss_value, grads2 = loss_function(params, walkers)\n",
    "print(loss_value)\n",
    "\n",
    "compare_grads(wf_tc, grads1)\n",
    "# compare_grads(wf_tc, grads2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-cursor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "metropolitan-petite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('split0', DeviceArray([[   66.65078 ,    58.176144,  -133.46118 ,   243.43398 ],\n",
      "             [  167.34445 ,   256.2817  ,    95.12666 ,  -236.2991  ],\n",
      "             [  -55.878025,   171.31535 ,   308.44946 ,   585.5462  ],\n",
      "             [  758.3378  ,   340.0263  ,   246.6875  , -2330.7363  ],\n",
      "             [  243.97282 ,   166.17392 ,  -191.01616 ,   181.22307 ],\n",
      "             [  225.89394 ,  -170.51274 ,    66.91763 ,   394.34787 ],\n",
      "             [  102.54219 ,   268.52792 ,  -308.95078 ,   566.5387  ],\n",
      "             [  740.1543  ,   498.4542  ,   597.3778  , -1961.298   ]],            dtype=float32)), ('s0', DeviceArray([[ 1534.15635844, -1689.07992037,   160.82784695,\n",
      "               1502.8496008 ],\n",
      "             [  776.49583645,  -360.58406003,  -114.11196112,\n",
      "                823.73215607],\n",
      "             [  983.99286244,  3588.98830435,  -338.39412403,\n",
      "               -179.76773983],\n",
      "             [ -896.06693427,  2283.62528911,    -4.42706734,\n",
      "              -2821.91394965],\n",
      "             [ 1467.50558043, -1747.25606292,   294.28902854,\n",
      "               1259.41562816],\n",
      "             [  609.15138026,  -616.86578008,  -209.23862261,\n",
      "               1060.03126062],\n",
      "             [ 1039.87088889,  3417.6729442 ,  -646.84359405,\n",
      "               -765.31395878],\n",
      "             [  898.31898817,    76.95471375,   289.79544252,\n",
      "              -1711.27724179],\n",
      "             [ 1290.1835326 , -1855.25383769,   351.84400617,\n",
      "               1321.62652955],\n",
      "             [  550.60190504,  -190.071314  ,  -181.02959611,\n",
      "                429.38429136],\n",
      "             [  881.45067042,  3320.46038262,   -29.4433425 ,\n",
      "               -746.30640884],\n",
      "             [  484.35697795,  2152.89467257,   533.44439688,\n",
      "              -2406.42718726],\n",
      "             [  455.95001272,   201.20777506,   318.98285174,\n",
      "              -1529.47839619]], dtype=float64)), ('p0', DeviceArray([[ 1510.68560762,  1084.8755521 ],\n",
      "             [  776.78679   ,  -333.21031557],\n",
      "             [-1272.25431114, -1841.57793061],\n",
      "             [ 2159.25413292, -1753.74492018],\n",
      "             [ 1414.8377747 ,  -702.63218365]], dtype=float64)), ('intermediate', [[DeviceArray([[  183.6698   ,   809.15594  ,    34.306767 ,    22.678896 ],\n",
      "             [  102.29617  ,  1146.0999   ,   -32.80656  ,    23.587055 ],\n",
      "             [  181.14221  ,  1195.0973   ,   -38.616882 ,    30.692125 ],\n",
      "             [ -112.318886 ,  -707.1855   ,    20.522854 ,    -4.3645854],\n",
      "             [  216.15027  ,   959.50354  ,    17.281933 ,    29.693459 ],\n",
      "             [   97.7413   ,  1204.7654   ,   -42.25277  ,    26.927898 ],\n",
      "             [  202.08496  ,  1195.9984   ,   -42.09794  ,    27.603783 ],\n",
      "             [ -187.49252  , -1099.5944   ,    40.572803 ,   -18.160631 ]],            dtype=float32), DeviceArray([[ 5.70206199e+02,  1.10163237e+03,  7.68131402e+01,\n",
      "               7.08319993e+01],\n",
      "             [-1.88184395e+02,  1.47707613e+03, -3.57540678e+01,\n",
      "               1.13920374e+01],\n",
      "             [ 2.25431067e+02,  1.05450744e+03, -3.56076775e+01,\n",
      "               2.69415592e+01],\n",
      "             [ 1.08012837e+02, -1.98053179e+03,  3.43401368e+01,\n",
      "               1.38517331e+01],\n",
      "             [ 2.41609154e+01, -3.52903444e+02, -1.11971182e+01,\n",
      "              -2.64804899e+01],\n",
      "             [ 4.60825064e+02,  1.08956985e+03, -2.20115530e+00,\n",
      "               4.60262394e+01],\n",
      "             [-1.26672543e+02,  6.66118852e+01, -3.79214391e+01,\n",
      "              -5.40993367e+00],\n",
      "             [ 2.44525606e+02,  2.68608208e+03, -3.52444869e+01,\n",
      "               6.88775185e+01],\n",
      "             [-2.10028307e+02, -1.27950952e+03,  4.15898303e+01,\n",
      "              -2.99143310e+01]], dtype=float64), array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]])]]), ('envelopes', OrderedDict([('linear', [DeviceArray([[[ 1253.37195747,  1583.20825588,  1834.96767646,\n",
      "               -2847.94852463, -1036.0878688 ],\n",
      "              [ -861.20288397,   233.1476577 ,  -801.06208454,\n",
      "                -246.9773476 ,   306.6967026 ]]], dtype=float64), DeviceArray([[[-1606.12362247,  -377.72817326, -1484.18586977,\n",
      "                1070.3786941 ,   779.46685097],\n",
      "              [  -24.66631889, -1050.80880168,  -494.76337114,\n",
      "                1029.36242752,   230.30155447]]], dtype=float64)]), ('sigma', [DeviceArray([[[[[-3495.428  ,  1834.4387 ,  1120.7567 ],\n",
      "                [ 1537.4379 ,   112.56445,   948.0846 ],\n",
      "                [  727.9429 , -4065.6958 , -1432.3579 ]]],\n",
      "\n",
      "\n",
      "              [[[  784.5653 ,  2064.838  ,  4007.1758 ],\n",
      "                [ -923.9963 ,  -422.6921 ,  -497.11932],\n",
      "                [ 1258.7809 , -1323.2184 , -4554.4985 ]]]]],            dtype=float32), DeviceArray([[[[[  411.4424 ,  2198.1074 ,  1666.4762 ],\n",
      "                [ 1436.2612 ,  -578.30133, -1127.6361 ],\n",
      "                [  993.0808 ,  -900.56665,  1354.8756 ]]],\n",
      "\n",
      "\n",
      "              [[[ 1295.1854 ,  1363.838  ,   745.1109 ],\n",
      "                [-1183.8291 ,   741.96844,  1750.0898 ],\n",
      "                [  669.74786, -1132.5428 ,  -182.61581]]]]],            dtype=float32)]), ('pi', [DeviceArray([[[1036.54800875],\n",
      "              [1022.27055836]]], dtype=float64), DeviceArray([[[1027.32725288],\n",
      "              [1024.26532689]]], dtype=float64)])]))])\n"
     ]
    }
   ],
   "source": [
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "gentle-settlement",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MetropolisHastingsPretrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7af9a0128cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf_tc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwf_tc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetropolisHastingsPretrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwf_walkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwalkers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwf_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetropolisHasting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MetropolisHastingsPretrain' is not defined"
     ]
    }
   ],
   "source": [
    "device, dtype = wf_tc.device, wf_tc.dtype\n",
    "sampler = MetropolisHastingsPretrain()\n",
    "wf_walkers = walkers\n",
    "\n",
    "wf_sampler = MetropolisHasting(wf)\n",
    "for i in range(500):\n",
    "    wf_walkers, wf_acc = wf_sampler(wf_walkers)\n",
    "    e_locs = compute_local_energy(wf, wf_walkers, self.mol.r_atoms, self.mol.z_atoms)\n",
    "    print(e_locs.mean())\n",
    "\n",
    "\n",
    "opt = tc.optim.Adam(list(wf.parameters()), lr=lr)\n",
    "steps = trange(\n",
    "    0,  # init_step = 0\n",
    "    n_it,\n",
    "    initial=0,\n",
    "    total=n_it,\n",
    "    desc='pretraining',\n",
    "    disable=None,\n",
    ")\n",
    "\n",
    "# walkers = initialize_walkers(self.mol.n_el_atoms, self.mol.atom_positions, n_walkers).to(device=device, dtype=dtype)\n",
    "\n",
    "for step in steps:\n",
    "    wf_walkers, wf_acc = wf_sampler(wf_walkers)\n",
    "    e_locs = compute_local_energy(wf, wf_walkers, self.mol.r_atoms,  self.mol.z_atoms)\n",
    "\n",
    "    walkers = sampler(wf, self, walkers)\n",
    "\n",
    "    up_dets, down_dets = hf_orbitals(walkers)\n",
    "    up_dets = tile_labels(up_dets, wf.n_determinants)\n",
    "    down_dets = tile_labels(down_dets, wf.n_determinants)\n",
    "\n",
    "    model_up_dets, model_down_dets = wf.generate_orbitals(walkers)\n",
    "\n",
    "    loss = mse_error(up_dets, model_up_dets)\n",
    "    loss += mse_error(down_dets, model_down_dets)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()  # in order for hook to work must call backward\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import trange\n",
    "from jax import value_and_grad, grad, vmap, jit\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as rnd\n",
    "from jax.experimental.optimizers import adam\n",
    "from jax.tree_util import tree_unflatten, tree_flatten\n",
    "\n",
    "from ops.pretraining import create_loss_and_sampler, equilibrate\n",
    "from ops.vmc import create_energy_fn\n",
    "from ops.\n",
    "\n",
    "\n",
    "\n",
    "compute_local_energy = create_energy_fn(wf, mol.r_atoms, mol.z_atoms)\n",
    "\n",
    "loss_function, sampler = create_loss_and_sampler(mol, wf, wf_orbitals)\n",
    "loss_function = value_and_grad(loss_function)\n",
    "\n",
    "walkers, step_size = equilibrate(params, walkers, compute_local_energy, sampler, key, n_it=50, step_size=0.02)\n",
    "wf_walkers = jnp.array(walkers, copy=True)\n",
    "\n",
    "init, update, get_params = adam(1e-3)\n",
    "state = init(params)\n",
    "\n",
    "steps = trange(0, n_it, initial=0, total=n_it, desc='pretraining', disable=None)\n",
    "for step in steps:\n",
    "    key, *subkeys = rnd.split(key, num=3)\n",
    "\n",
    "    wf_walkers, acc = wf_sampler(params, wf_walkers, subkeys[0], step_size)\n",
    "    e_locs = compute_local_energy(params, wf_walkers)\n",
    "\n",
    "    walkers, mix_acc = sampler(params, walkers, subkeys[1], step_size)\n",
    "\n",
    "    loss_value, grads = loss_function(params, walkers)\n",
    "\n",
    "    params = sgd(params, grads, lr)\n",
    "    # state = update(step, grads, state)\n",
    "    # params = get_params(state)\n",
    "\n",
    "\n",
    "    print('step %i | e_mean %.2f | loss %.2f | wf_acc %.2f | mix_acc %.2f |'\n",
    "          % (step, jnp.mean(e_locs), loss_value, acc, mix_acc))\n",
    "    # steps.set_postfix(E=f'{e_locs.mean():.6f}')\n",
    "\n",
    "return params, walkers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
