{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "competitive-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random as rnd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chubby-locator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0218])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as tc\n",
    "from torch import nn\n",
    "tc.set_default_dtype(tc.float64)\n",
    "tc.normal(0., 1., (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compatible-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(tc_arr, jnp_arr):\n",
    "    tc_arr = tc_arr.detach().cpu().numpy()\n",
    "    diff = tc_arr - jnp_arr\n",
    "    sum_diff = jnp.sum(diff)\n",
    "    abs_sum_diff = jnp.sum(jnp.abs(diff))\n",
    "    print('abs sum diff %.8f, sum diff %.8f' % (abs_sum_diff, sum_diff))\n",
    "    return sum_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "british-offering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 3) (1000, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "n_atoms = 1\n",
    "n_electrons = 5\n",
    "n_sh = 20\n",
    "n_ph = 16\n",
    "n_up = 3\n",
    "n_down = n_electrons - n_up\n",
    "n_determinants = 2\n",
    "\n",
    "re = np.random.normal(0, 1, (n_samples, n_electrons, 3))\n",
    "ra = np.random.normal(0, 1, (n_atoms, 3))\n",
    "ra = np.concatenate([ra[None, ...] for _ in range(n_samples)], axis=0)\n",
    "\n",
    "ra_tc = tc.from_numpy(ra)\n",
    "re_tc = tc.from_numpy(re)\n",
    "\n",
    "print(ra.shape, re.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rocky-discovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5, 1, 3)\n",
      "abs sum diff 0.00000000, sum diff 0.000000\n"
     ]
    }
   ],
   "source": [
    "def compute_ae_vectors(r_electrons: jnp.array, \n",
    "                       r_atoms: jnp.array) -> jnp.array:\n",
    "    \n",
    "    r_atoms = jnp.expand_dims(r_atoms, axis=1)\n",
    "    r_electrons = jnp.expand_dims(r_electrons, axis=2)\n",
    "    ae_vectors = r_electrons - r_atoms\n",
    "    return ae_vectors\n",
    "\n",
    "def compute_ae_vectors_tc(r_atoms: tc.Tensor, r_electrons: tc.Tensor) -> tc.Tensor:\n",
    "    # ae_vectors (n_samples, n_electrons, n_atoms, 3)\n",
    "    r_atoms = r_atoms.unsqueeze(1)\n",
    "    r_electrons = r_electrons.unsqueeze(2)\n",
    "    ae_vectors = r_electrons - r_atoms\n",
    "    return ae_vectors\n",
    "\n",
    "ae_vectors_tc = compute_ae_vectors_tc(ra_tc, re_tc)\n",
    "ae_vectors = compute_ae_vectors(re, ra)\n",
    "print(ae_vectors.shape)\n",
    "ae_diff = compare(ae_vectors_tc, ae_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "narrative-closure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.71 ms ± 8.53 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "968 µs ± 14.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "75.7 µs ± 7.4 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def compute_inputs_tc(r_electrons, \n",
    "                   n_samples : int, \n",
    "                   ae_vectors, \n",
    "                   n_atoms : int, \n",
    "                   n_electrons : int):\n",
    "    \n",
    "    # r_atoms: (n_atoms, 3)\n",
    "    # r_electrons: (n_samples, n_electrons, 3)\n",
    "    # ae_vectors: (n_samples, n_electrons, n_atoms, 3)\n",
    "    \n",
    "    ae_distances = tc.norm(ae_vectors, dim=-1, keepdim=True)\n",
    "    single_inputs = tc.cat((ae_vectors, ae_distances), dim=-1)\n",
    "    single_inputs = single_inputs.view((-1, n_electrons, 4 * n_atoms))\n",
    "\n",
    "    re1 = r_electrons.unsqueeze(2)\n",
    "    re2 = re1.permute((0, 2, 1, 3))\n",
    "    ee_vectors = re1 - re2\n",
    "\n",
    "#     mask = tc.eye(n_electrons, dtype=tc.bool)\n",
    "#     mask = ~mask.unsqueeze(0).unsqueeze(3).repeat((n_samples, 1, 1, 3))\n",
    "\n",
    "#     ee_vectors = ee_vectors[mask]\n",
    "#     ee_vectors = ee_vectors.view((-1, int(n_electrons ** 2 - n_electrons), 3))\n",
    "    \n",
    "    ee_vectors = ee_vectors.view((-1, int(n_electrons ** 2), 3))\n",
    "    ee_distances = tc.norm(ee_vectors, dim=-1, keepdim=True)\n",
    "\n",
    "    pairwise_inputs = tc.cat((ee_vectors, ee_distances), dim=-1)\n",
    "\n",
    "    return single_inputs, pairwise_inputs\n",
    "\n",
    "\n",
    "def compute_inputs(r_electrons, ae_vectors):\n",
    "    n_samples, n_electrons, n_atoms = ae_vectors.shape[:3]\n",
    "\n",
    "    ae_distances = jnp.linalg.norm(ae_vectors, axis=-1, keepdims=True)\n",
    "    single_inputs = jnp.concatenate([ae_vectors, ae_distances], axis=-1)\n",
    "    single_inputs = single_inputs.reshape(n_samples, n_electrons, 4 * n_atoms)\n",
    "    \n",
    "    re1 = jnp.expand_dims(r_electrons, axis=2)\n",
    "    re2 = jnp.transpose(re1, [0, 2, 1, 3])\n",
    "    \n",
    "    ee_vectors = re1 - re2\n",
    "    ee_distances = jnp.linalg.norm(ee_vectors, axis=-1, keepdims=True)\n",
    "    pairwise_inputs = jnp.concatenate([ee_vectors, ee_distances], axis=-1)\n",
    "    pairwise_inputs = pairwise_inputs.reshape(n_samples, n_electrons**2, 4)\n",
    "\n",
    "    return single_inputs, pairwise_inputs\n",
    "\n",
    "jit_compute_inputs = jax.jit(compute_inputs)\n",
    "\n",
    "%timeit compute_inputs_tc(re_tc, n_samples, ae_vectors_tc, n_atoms, n_electrons)\n",
    "%timeit compute_inputs(re, ae_vectors)[0].block_until_ready()\n",
    "%timeit jit_compute_inputs(re, ae_vectors)[0].block_until_ready()\n",
    "\n",
    "sin_tc, pin_tc = compute_inputs_tc(re_tc, n_samples, ae_vectors_tc, n_atoms, n_electrons)\n",
    "\n",
    "single_inputs, pairwise_inputs = compute_inputs(re, ae_vectors)\n",
    "\n",
    "compare(sin_tc, single_inputs)\n",
    "compare(pin_tc, pairwise_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "animal-mining",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-176fd8e6460b>:115: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  spin_up_mask = tc.tensor(spin_up_mask, dtype=tc.bool)\n",
      "<ipython-input-50-176fd8e6460b>:120: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  spin_down_mask = tc.tensor(spin_down_mask, dtype=tc.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs sum diff 0.00000000, sum diff -0.00000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(-1.22780475e-15, dtype=float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_masks(n_sh, n_ph, n_electrons, n_up):\n",
    "    \n",
    "    # single spin masks\n",
    "    n_down = n_electrons - n_up\n",
    "    n_pairwise = n_electrons**2\n",
    "\n",
    "    tmp1 = jnp.ones((1, n_up, n_sh))\n",
    "    tmp2 = jnp.zeros((1, n_down, n_sh))\n",
    "    single_up_mask = jnp.concatenate((tmp1, tmp2), axis=1)\n",
    "    single_down_mask = (jnp.concatenate((tmp1, tmp2), axis=1)-1.)*-1.\n",
    "\n",
    "    # pairwise spin masks\n",
    "    ups = np.ones(n_electrons)\n",
    "    ups[n_up:] = 0\n",
    "    downs = (ups-1.)*-1.\n",
    "\n",
    "    pairwise_up_mask = []\n",
    "    pairwise_down_mask = []\n",
    "    mask = np.zeros((n_electrons, n_electrons))\n",
    "\n",
    "    for electron in range(n_electrons):\n",
    "        e_mask_up = np.zeros((n_electrons,))\n",
    "        e_mask_down = np.zeros((n_electrons,))\n",
    "\n",
    "        mask_up = np.copy(mask)\n",
    "        mask_up[electron, :] = ups\n",
    "        mask_up = mask_up.reshape(-1)\n",
    "\n",
    "        mask_down = np.copy(mask)\n",
    "        mask_down[electron, :] = downs\n",
    "        mask_down = mask_down.reshape(-1)\n",
    "\n",
    "        pairwise_up_mask.append(mask_up)\n",
    "        pairwise_down_mask.append(mask_down)\n",
    "\n",
    "    pairwise_up_mask = jnp.array(pairwise_up_mask).reshape((1, n_electrons, n_pairwise, 1))\n",
    "    pairwise_up_mask = jnp.repeat(pairwise_up_mask, n_ph, axis=-1)\n",
    "\n",
    "    pairwise_down_mask = jnp.array(pairwise_down_mask).reshape((1, n_electrons, n_pairwise, 1))\n",
    "    pairwise_down_mask = jnp.repeat(pairwise_down_mask, n_ph, axis=-1)\n",
    "    return single_up_mask, single_down_mask, pairwise_up_mask, pairwise_down_mask\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def generate_pairwise_masks(n_electrons: int, \n",
    "                            n_pairwise: int, \n",
    "                            n_spin_up: int, \n",
    "                            n_pairwise_features: int):\n",
    "    \n",
    "    eye_mask = ~np.eye(n_electrons, dtype=bool)\n",
    "    ups = np.ones(n_electrons, dtype=bool)\n",
    "    ups[n_spin_up:] = False\n",
    "    downs = ~ups\n",
    "\n",
    "    spin_up_mask = []\n",
    "    spin_down_mask = []\n",
    "    mask = np.zeros((n_electrons, n_electrons), dtype=bool)\n",
    "\n",
    "    for electron in range(n_electrons):\n",
    "        e_mask_up = np.zeros((n_electrons,), dtype=bool)\n",
    "        e_mask_down = np.zeros((n_electrons,), dtype=bool)\n",
    "\n",
    "        mask_up = np.copy(mask)\n",
    "        mask_up[electron, :] = ups\n",
    "        mask_up = mask_up.reshape(-1)\n",
    "\n",
    "\n",
    "        mask_down = np.copy(mask)\n",
    "        mask_down[electron, :] = downs\n",
    "        mask_down = mask_down.reshape(-1)\n",
    "\n",
    "        spin_up_mask.append(mask_up)\n",
    "        spin_down_mask.append(mask_down)\n",
    "\n",
    "    spin_up_mask = tc.tensor(spin_up_mask, dtype=tc.bool)\n",
    "    # (n_samples, n_electrons, n_electrons, n_pairwise_features)\n",
    "    spin_up_mask = spin_up_mask.view((1, n_electrons, n_pairwise, 1))\n",
    "    spin_up_mask = spin_up_mask.repeat((1, 1, 1, n_pairwise_features))\n",
    "\n",
    "    spin_down_mask = tc.tensor(spin_down_mask, dtype=tc.bool)\n",
    "    spin_down_mask = spin_down_mask.view((1, n_electrons, n_pairwise, 1))\n",
    "    spin_down_mask = spin_down_mask.repeat((1, 1, 1, n_pairwise_features))\n",
    "\n",
    "    return spin_up_mask, spin_down_mask\n",
    "\n",
    "\n",
    "class Mixer(nn.Module):\n",
    "    def __init__(self, n_single_features, n_pairwise_features, n_electrons, n_spin_up, device, dtype):\n",
    "        super(Mixer, self).__init__()\n",
    "        self.dv = device\n",
    "        self.dt = dtype\n",
    "\n",
    "        n_spin_down = n_electrons - n_spin_up\n",
    "        n_pairwise = n_electrons**2\n",
    "\n",
    "        self.n_electrons = n_electrons\n",
    "        self.n_spin_up = float(n_spin_up)\n",
    "        self.n_spin_down = float(n_spin_down)\n",
    "\n",
    "        tmp1 = tc.ones((1, n_spin_up, n_single_features), dtype=tc.bool, device=device)\n",
    "        tmp2 = tc.zeros((1, n_spin_down, n_single_features), dtype=tc.bool, device=device)\n",
    "        self.spin_up_mask = tc.cat((tmp1, tmp2), dim=1).type(dtype)\n",
    "        self.spin_down_mask = (~tc.cat((tmp1, tmp2), dim=1)).type(dtype)\n",
    "\n",
    "        self.pairwise_spin_up_mask, self.pairwise_spin_down_mask = \\\n",
    "            generate_pairwise_masks(n_electrons, n_pairwise, n_spin_up, n_pairwise_features)\n",
    "        self.pairwise_spin_up_mask = self.pairwise_spin_up_mask.type(dtype).to(device)\n",
    "        self.pairwise_spin_down_mask = self.pairwise_spin_down_mask.type(dtype).to(device)\n",
    "\n",
    "    def forward(self, single: tc.Tensor, pairwise: tc.Tensor):\n",
    "        # single (n_samples, n_electrons, n_single_features)\n",
    "        # pairwise (n_samples, n_electrons, n_pairwise_features)\n",
    "        # spin_up_mask = self.spin_up_mask.repeat((n_samples, 1, 1))\n",
    "        # spin_down_mask = self.spin_down_mask.repeat((n_samples, 1, 1))\n",
    "\n",
    "        # --- Single summations\n",
    "        # up\n",
    "        sum_spin_up = self.spin_up_mask * single\n",
    "        sum_spin_up = sum_spin_up.sum(1, keepdim=True) / self.n_spin_up\n",
    "        sum_spin_up = sum_spin_up.repeat((1, self.n_electrons, 1))\n",
    "\n",
    "        # down\n",
    "        sum_spin_down = self.spin_down_mask * single\n",
    "        sum_spin_down = sum_spin_down.sum(1, keepdim=True) / self.n_spin_down\n",
    "        sum_spin_down = sum_spin_down.repeat((1, self.n_electrons, 1))\n",
    "\n",
    "        # --- Pairwise summations\n",
    "        sum_pairwise = pairwise.unsqueeze(1).repeat((1, self.n_electrons, 1, 1))\n",
    "\n",
    "        # up\n",
    "        sum_pairwise_up = self.pairwise_spin_up_mask * sum_pairwise\n",
    "        sum_pairwise_up = sum_pairwise_up.sum(2) / self.n_spin_up\n",
    "\n",
    "        # down\n",
    "        sum_pairwise_down = self.pairwise_spin_down_mask * sum_pairwise\n",
    "        sum_pairwise_down = sum_pairwise_down.sum(2) / self.n_spin_down\n",
    "\n",
    "        features = tc.cat((single, sum_pairwise_up, sum_pairwise_down, sum_spin_up, sum_spin_down), dim=2)\n",
    "        return features\n",
    "\n",
    "single = np.random.normal(0, 1, (n_samples, n_electrons, n_sh))\n",
    "pairwise = np.random.normal(0, 1, (n_samples, n_electrons**2, n_ph))\n",
    "\n",
    "single_tc = tc.from_numpy(single)\n",
    "pairwise_tc = tc.from_numpy(pairwise)\n",
    "\n",
    "tc_mixer = Mixer(n_sh, n_ph, n_electrons, n_up, 'cpu', tc.float64)\n",
    "features_tc = tc_mixer(single_tc, pairwise_tc)\n",
    "\n",
    "smu, smd, pmu, pmd = create_masks(n_sh, n_ph, n_electrons, n_up)\n",
    "features = mixer(single, pairwise, smu, smd, pmu, pmd, n_electrons, n_up, n_down)\n",
    "\n",
    "compare(features_tc, features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "communist-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs sum diff 0.00000000, sum diff 0.00000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(3.30568906e-14, dtype=float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EnvelopeLinear():\n",
    "    def __init__(self,\n",
    "                 w,\n",
    "                 n_hidden,\n",
    "                 n_spin_det,\n",
    "\n",
    "                 n_samples,\n",
    "                 n_determinants):\n",
    "        \n",
    "        self.out_shape = (-1, n_spin_det, n_determinants, n_spin_det)\n",
    "        self.w = nn.Parameter(w, requires_grad=True)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        n_samples, n_spin_det = data.shape[:2]\n",
    "        \n",
    "        bias_data = tc.ones((n_samples, n_spin_det, 1))\n",
    "        data_w_bias = tc.cat((data, bias_data), dim=-1)\n",
    "        \n",
    "        out = tc.einsum('njf,kif->njki', data_w_bias, self.w)\n",
    "        return out.view(self.out_shape)\n",
    "\n",
    "def env_linear(params: jnp.array, data: jnp.array):\n",
    "    n_samples, n_spin_det = data.shape[:2]\n",
    "    \n",
    "    bias = jnp.ones((n_samples, n_spin_det, 1))\n",
    "    data = jnp.concatenate((data, bias), axis=-1)\n",
    "    return jnp.einsum('njf,kif->njki', data, params)\n",
    "\n",
    "w = np.random.normal(0, 1, (n_determinants, n_up, n_sh+1))\n",
    "data = np.random.normal(0, 1, (n_samples, n_up, n_sh))\n",
    "data_tc = tc.from_numpy(data)\n",
    "w_tc = tc.from_numpy(w)\n",
    "\n",
    "env_lin_tc = EnvelopeLinear(w_tc, n_sh, n_up, n_samples, n_determinants)\n",
    "\n",
    "e_tc = env_lin_tc(data_tc)\n",
    "e = env_linear(w, data)\n",
    "\n",
    "compare(e_tc, e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "compressed-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixer(single: jnp.array, \n",
    "          pairwise: jnp.array,\n",
    "          n_electrons,\n",
    "          n_up,\n",
    "          n_down,\n",
    "          single_up_mask,\n",
    "          single_down_mask,\n",
    "          pairwise_up_mask,\n",
    "          pairwise_down_mask):\n",
    "    # single (n_samples, n_electrons, n_single_features)\n",
    "    # pairwise (n_samples, n_electrons, n_pairwise_features)\n",
    "    # spin_up_mask = self.spin_up_mask.repeat((n_samples, 1, 1))\n",
    "    # spin_down_mask = self.spin_down_mask.repeat((n_samples, 1, 1))\n",
    "\n",
    "    # --- Single summations\n",
    "    # up\n",
    "    sum_spin_up = single_up_mask * single\n",
    "    sum_spin_up = jnp.sum(sum_spin_up, axis=1, keepdims=True) / n_up\n",
    "    sum_spin_up = jnp.repeat(sum_spin_up, n_electrons, axis=1)  # not needed in split\n",
    "\n",
    "    # down\n",
    "    sum_spin_down = single_down_mask * single\n",
    "    sum_spin_down = jnp.sum(sum_spin_down, axis=1, keepdims=True) / n_down\n",
    "    sum_spin_down = jnp.repeat(sum_spin_down, n_electrons, axis=1) # not needed in split\n",
    "\n",
    "    # --- Pairwise summations\n",
    "    sum_pairwise = jnp.repeat(jnp.expand_dims(pairwise, axis=1), n_electrons, axis=1)\n",
    "\n",
    "    # up\n",
    "    sum_pairwise_up = pairwise_up_mask * sum_pairwise\n",
    "    sum_pairwise_up = jnp.sum(sum_pairwise_up, axis=2) / n_up\n",
    "\n",
    "    # down\n",
    "    sum_pairwise_down = pairwise_down_mask * sum_pairwise\n",
    "    sum_pairwise_down = jnp.sum(sum_pairwise_down, axis=2) / n_down\n",
    "\n",
    "    features = jnp.concatenate((single, sum_pairwise_up, sum_pairwise_down, sum_spin_up, sum_spin_down), axis=2)\n",
    "    # split = jnp.concatenate((sum_spin_up, sum_spin_down), axis=2)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "located-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(n_atom, n_up, n_layers, n_sh, n_ph):\n",
    "    n_sh_in = 4 * n_atom\n",
    "    n_ph_in = 4\n",
    "    \n",
    "    masks = [create_masks_layer(n_sh_in, n_ph_in, n_electrons, n_up)]\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        masks.append(create_masks_layer(n_sh, n_ph, n_electrons, n_up))\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def create_masks_layer(n_sh, n_ph, n_electrons, n_up):\n",
    "    \n",
    "    # single spin masks\n",
    "    n_down = n_electrons - n_up\n",
    "    n_pairwise = n_electrons**2\n",
    "\n",
    "    tmp1 = jnp.ones((1, n_up, n_sh))\n",
    "    tmp2 = jnp.zeros((1, n_down, n_sh))\n",
    "    single_up_mask = jnp.concatenate((tmp1, tmp2), axis=1)\n",
    "    single_down_mask = (jnp.concatenate((tmp1, tmp2), axis=1)-1.)*-1.\n",
    "\n",
    "    # pairwise spin masks\n",
    "    ups = np.ones(n_electrons)\n",
    "    ups[n_up:] = 0\n",
    "    downs = (ups-1.)*-1.\n",
    "\n",
    "    pairwise_up_mask = []\n",
    "    pairwise_down_mask = []\n",
    "    mask = np.zeros((n_electrons, n_electrons))\n",
    "\n",
    "    for electron in range(n_electrons):\n",
    "        e_mask_up = np.zeros((n_electrons,))\n",
    "        e_mask_down = np.zeros((n_electrons,))\n",
    "\n",
    "        mask_up = np.copy(mask)\n",
    "        mask_up[electron, :] = ups\n",
    "        mask_up = mask_up.reshape(-1)\n",
    "\n",
    "        mask_down = np.copy(mask)\n",
    "        mask_down[electron, :] = downs\n",
    "        mask_down = mask_down.reshape(-1)\n",
    "\n",
    "        pairwise_up_mask.append(mask_up)\n",
    "        pairwise_down_mask.append(mask_down)\n",
    "\n",
    "    pairwise_up_mask = jnp.array(pairwise_up_mask).reshape((1, n_electrons, n_pairwise, 1))\n",
    "    pairwise_up_mask = jnp.repeat(pairwise_up_mask, n_ph, axis=-1)\n",
    "\n",
    "    pairwise_down_mask = jnp.array(pairwise_down_mask).reshape((1, n_electrons, n_pairwise, 1))\n",
    "    pairwise_down_mask = jnp.repeat(pairwise_down_mask, n_ph, axis=-1)\n",
    "    return single_up_mask, single_down_mask, pairwise_up_mask, pairwise_down_mask\n",
    "\n",
    "def compute_ae_vectors(r_electrons: jnp.array, \n",
    "                       r_atoms: jnp.array) -> jnp.array:\n",
    "    \n",
    "    r_atoms = jnp.expand_dims(r_atoms, axis=1)\n",
    "    r_electrons = jnp.expand_dims(r_electrons, axis=2)\n",
    "    ae_vectors = r_electrons - r_atoms\n",
    "    return ae_vectors\n",
    "\n",
    "def compute_inputs(r_electrons, ae_vectors):\n",
    "    n_samples, n_electrons, n_atoms = ae_vectors.shape[:3]\n",
    "\n",
    "    ae_distances = jnp.linalg.norm(ae_vectors, axis=-1, keepdims=True)\n",
    "    single_inputs = jnp.concatenate([ae_vectors, ae_distances], axis=-1)\n",
    "    single_inputs = single_inputs.reshape(n_samples, n_electrons, 4 * n_atoms)\n",
    "    \n",
    "    re1 = jnp.expand_dims(r_electrons, axis=2)\n",
    "    re2 = jnp.transpose(re1, [0, 2, 1, 3])\n",
    "    \n",
    "    ee_vectors = re1 - re2\n",
    "    ee_distances = jnp.linalg.norm(ee_vectors, axis=-1, keepdims=True)\n",
    "    pairwise_inputs = jnp.concatenate([ee_vectors, ee_distances], axis=-1)\n",
    "    pairwise_inputs = pairwise_inputs.reshape(n_samples, n_electrons**2, 4)\n",
    "\n",
    "    return single_inputs, pairwise_inputs\n",
    "\n",
    "def linear(p: jnp.array, \n",
    "           data: jnp.array)-> jnp.array:\n",
    "    bias = jnp.ones((*data.shape[:-1], 1))\n",
    "    data = jnp.concatenate([data, bias], axis=-1)\n",
    "\n",
    "    return jnp.tanh(jnp.dot(data, p))\n",
    "\n",
    "def env_linear(params: jnp.array, \n",
    "               data: jnp.array) -> jnp.array:\n",
    "    bias = jnp.ones((*data.shape[:-1], 1))\n",
    "    data = jnp.concatenate((data, bias), axis=-1)\n",
    "    \n",
    "    return jnp.einsum('njf,kif->njki', data, params)\n",
    "    \n",
    "def env_sigma(sigma: jnp.array,\n",
    "              ae_vectors: jnp.array) -> jnp.array:\n",
    "    \n",
    "    exponent = jnp.einsum('njmv,kimvc->njkimc', ae_vectors, sigma)\n",
    "    return jnp.exp(-jnp.linalg.norm(exponent, axis=-1))\n",
    "    \n",
    "def env_pi(pi: jnp.array,\n",
    "           factor: jnp.array,\n",
    "           exponential: jnp.array) -> jnp.array:\n",
    "    \n",
    "    orbitals = factor * jnp.einsum('njkim,kim->njki', exponential, pi)\n",
    "    return jnp.transpose(orbitals, [0, 2, 1, 3])\n",
    "\n",
    "def logabssumdet(orb_up: jnp.array,\n",
    "                 orb_down: jnp.array) -> jnp.array:\n",
    "    \n",
    "    s_up, log_up = jnp.linalg.slogdet(orb_up)\n",
    "    s_down, log_down = jnp.linalg.slogdet(orb_down)\n",
    "    \n",
    "    logdet_sum = log_up + log_down\n",
    "    logdet_max = jnp.max(logdet_sum)\n",
    "    \n",
    "    argument = s_up * s_down * jnp.exp(logdet_sum - logdet_max)\n",
    "    \n",
    "    return jnp.log(jnp.abs(jnp.sum(argument, axis=1))) + logdet_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "offensive-marks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 3) (100, 2, 3)\n",
      "(100, 5, 8) (100, 25, 4)\n",
      "[(1, 5, 8), (1, 5, 8), (1, 5, 25, 4), (1, 5, 25, 4)]\n",
      "(100, 5, 32) (100, 25, 4) (33, 20) (5, 10)\n",
      "(81, 20) (11, 10) [(1, 5, 20), (1, 5, 20), (1, 5, 25, 10), (1, 5, 25, 10)]\n",
      "(100, 5, 80)\n",
      "(100, 5, 20) (100, 25, 10)\n",
      "(100, 3, 5, 3, 2) (100, 2, 5, 2, 2) (5, 3, 2) (5, 2, 2)\n",
      "(100, 5, 3, 3) (100, 5, 2, 2)\n",
      "(100, 5, 8) (100, 25, 4)\n",
      "[(1, 5, 8), (1, 5, 8), (1, 5, 25, 4), (1, 5, 25, 4)]\n",
      "(100, 5, 32) (100, 25, 4) (33, 20) (5, 10)\n",
      "(81, 20) (11, 10) [(1, 5, 20), (1, 5, 20), (1, 5, 25, 10), (1, 5, 25, 10)]\n",
      "(100, 5, 80)\n",
      "(100, 5, 20) (100, 25, 10)\n",
      "(100, 3, 5, 3, 2) (100, 2, 5, 2, 2) (5, 3, 2) (5, 2, 2)\n",
      "(100, 5, 3, 3) (100, 5, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "def count_mixed_features(n_sh, n_ph):\n",
    "    #     n_sh_mix = 2 * n_ph + n_sh # change mixer\n",
    "    return 3 * n_sh + 2 * n_ph\n",
    "\n",
    "def initialise_params(key,\n",
    "                      n_atom: int,\n",
    "                      n_up: int,\n",
    "                      n_down: int,\n",
    "                      n_layers: int = 2,\n",
    "                      n_sh: int = 16,\n",
    "                      n_ph: int = 8,\n",
    "                      n_det: int = 1):\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    Notes:\n",
    "    zip(*([iter(nums)]*2) nice idiom for iterating over in sets of 2\n",
    "    '''\n",
    "    \n",
    "    # count the number of input features\n",
    "    n_sh_in = 4 * n_atom\n",
    "    n_ph_in = 4\n",
    "    \n",
    "    # count the features in the intermediate layers\n",
    "    n_sh_mix = count_mixed_features(n_sh, n_ph)\n",
    "\n",
    "\n",
    "    params = {'envelopes':{}}\n",
    "    \n",
    "    # initial layers\n",
    "    key, subkey = rnd.split(key)\n",
    "    params['s0'] = rnd.normal(subkey, (count_mixed_features(n_sh_in, n_ph_in) + 1, n_sh))\n",
    "    \n",
    "    key, subkey = rnd.split(key)\n",
    "    params['p0'] = rnd.normal(subkey, (n_ph_in + 1, n_ph)) \n",
    "    \n",
    "    # intermediate layers\n",
    "    key, *subkeys = rnd.split(key, num=(n_layers*2))\n",
    "    params['intermediate'] = [[rnd.normal(sk1, (n_sh_mix + 1, n_sh)), rnd.normal(sk2, (n_ph + 1, n_ph))] \n",
    "                              for sk1, sk2 in zip(*([iter(subkeys)]*2))]\n",
    "    \n",
    "    # env_linear\n",
    "    key, *subkeys = rnd.split(key, num=3)\n",
    "    params['envelopes']['linear'] = [rnd.normal(subkeys[0], (n_det, n_up, n_sh + 1)),\n",
    "                                     rnd.normal(subkeys[1], (n_det, n_down, n_sh + 1))]\n",
    "\n",
    "    # env_sigma\n",
    "    key, *subkeys = rnd.split(key, num=3)\n",
    "    params['envelopes']['sigma'] = [rnd.normal(subkeys[0], (n_det, n_up, n_atom, 3, 3)),\n",
    "                                    rnd.normal(subkeys[1], (n_det, n_down, n_atom, 3, 3))]\n",
    "    \n",
    "    # env_pi\n",
    "    key, *subkeys = rnd.split(key, num=3)\n",
    "    params['envelopes']['pi'] = [rnd.normal(subkeys[0], (n_det, n_up, n_atom)),\n",
    "                                 rnd.normal(subkeys[1], (n_det, n_down, n_atom))]\n",
    "    \n",
    "    return params\n",
    "\n",
    "\n",
    "def model(params, r_electrons, r_atoms, masks):\n",
    "    n_samples, n_electrons = r_electrons.shape[:2]\n",
    "    n_atoms = r_atoms.shape[1]\n",
    "    \n",
    "    # ae_vectors\n",
    "    ae_vectors = compute_ae_vectors(r_electrons, r_atoms)\n",
    "    \n",
    "    # compute the inputs\n",
    "    single, pairwise = compute_inputs(r_electrons, ae_vectors)\n",
    "    print(single.shape, pairwise.shape)\n",
    "    \n",
    "    # mix the inputs\n",
    "    print([x.shape for x in masks[0]])\n",
    "    single = mixer(single, pairwise, n_electrons, n_up, n_down, *masks[0])\n",
    "    \n",
    "    # initial streams s0 and p0\n",
    "    print(single.shape, pairwise.shape, params['s0'].shape, params['p0'].shape)\n",
    "    single = linear(params['s0'], single)\n",
    "    pairwise = linear(params['p0'], pairwise)\n",
    "    \n",
    "    # intermediate layers including mix\n",
    "    for (s_params, p_params), mask in zip(params['intermediate'], masks[1:]):\n",
    "        print(s_params.shape, p_params.shape, [x.shape for x in mask])\n",
    "        \n",
    "        single_mixed = mixer(single, pairwise, n_electrons, n_up, n_down, *mask)\n",
    "        print(single_mixed.shape)\n",
    "        \n",
    "        single = linear(s_params, single_mixed) + single\n",
    "        pairwise = linear(p_params, pairwise) + pairwise\n",
    "        print(single.shape, pairwise.shape)\n",
    "    \n",
    "    # split\n",
    "    ae_up, ae_down = jnp.split(ae_vectors, [n_up], axis=1)\n",
    "    data_up, data_down = jnp.split(single, [n_up], axis=1)\n",
    "    \n",
    "    # envelopes\n",
    "    # linear\n",
    "    factor_up = env_linear(params['envelopes']['linear'][0], data_up)\n",
    "    factor_down = env_linear(params['envelopes']['linear'][1], data_down)\n",
    "    \n",
    "    # sigma\n",
    "    exp_up = env_sigma(params['envelopes']['sigma'][0], ae_up)\n",
    "    exp_down = env_sigma(params['envelopes']['sigma'][1], ae_down)\n",
    "    \n",
    "    # pi\n",
    "    print(exp_up.shape, exp_down.shape, params['envelopes']['pi'][0].shape, params['envelopes']['pi'][1].shape)\n",
    "    orb_up = env_pi(params['envelopes']['pi'][0], factor_up, exp_up)\n",
    "    orb_down = env_pi(params['envelopes']['pi'][1], factor_down, exp_down)\n",
    "        \n",
    "    # logabssumdet\n",
    "    print(orb_up.shape, orb_down.shape)\n",
    "    log_psi = logabssumdet(orb_up, orb_down)\n",
    "    \n",
    "    return jnp.sum(log_psi)\n",
    "\n",
    "def create_atom_batch(r_atoms, n_samples):\n",
    "    return jnp.repeat(jnp.expand_dims(r_atoms, axis=0), n_samples, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "amazing-arabic",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret '1' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-444480b9a665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/xmax/lib/python3.8/site-packages/jax/_src/random.py\u001b[0m in \u001b[0;36mnormal\u001b[0;34m(key, shape, dtype)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m   \"\"\"\n\u001b[0;32m--> 621\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m     raise ValueError(f\"dtype argument to `normal` must be a float or complex dtype, \"\n\u001b[1;32m    623\u001b[0m                      f\"got {dtype}\")\n",
      "\u001b[0;32m~/anaconda3/envs/xmax/lib/python3.8/site-packages/jax/dtypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# explicitly cast the second argument to a NumPy type object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0mcan_cast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_cast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \"\"\"\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0marg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret '1' as a data type"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "korean-architect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3818937504 2085278926]\n",
      "[ 798071906 3899491848]\n",
      "[1393771798 3194384582]\n",
      "[ 175757679 2955691801]\n",
      "669256.02 6117662.09\n",
      "669258.61 6117664.39\n",
      "669258.05 6117665.08\n",
      "[[669256.02, 6117662.09, 669258.61, 6117664.39, 669258.05, 6117665.08], []]\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (<ipython-input-50-c88e322d9ef0>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-c88e322d9ef0>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    (*[5]*4)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": [
    "key, *subkeys = rnd.split(key, num=8)\n",
    "for k in subkeys[::2]:\n",
    "    print(k)\n",
    "    \n",
    "nums = (669256.02, 6117662.09, 669258.61, 6117664.39, 669258.05, 6117665.08)\n",
    "ls = [iter(nums)]*2\n",
    "for x, y in zip(*[iter(nums)]*2):\n",
    "        print(x, y)\n",
    "        \n",
    "print(list([list(l) for l in ls]))      \n",
    "list(zip(*([iter(nums)]*2) ))\n",
    "\n",
    "def create_iterator(lst, n=2):\n",
    "#     for a, b in zip(*([iter(nums)]*n):  # hacky way to do this\n",
    "    it = iter(lst)\n",
    "    for a, b in zip(it, it):\n",
    "        print(a, b) # goes in sets of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "african-wrapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2, 3, 3) (1000, 2, 2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Buffer([[ 1., -1.],\n",
       "         [ 1.,  1.],\n",
       "         [ 1.,  1.],\n",
       "         ...,\n",
       "         [-1., -1.],\n",
       "         [-1., -1.],\n",
       "         [ 1., -1.]], dtype=float64),\n",
       " Buffer([[-2.82008323, -0.09710386],\n",
       "         [-2.47097002, -3.10294813],\n",
       "         [ 1.54502232,  1.7057895 ],\n",
       "         ...,\n",
       "         [-0.41479045,  0.7050965 ],\n",
       "         [-0.71533259,  1.07479973],\n",
       "         [ 0.19064791,  0.66715483]], dtype=float64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "x = np.random.normal(0, 1, (n_samples, n_determinants, n_up, n_up))\n",
    "y = np.random.normal(0, 1, (n_samples, n_determinants, n_down, n_down))\n",
    "print(x.shape, y.shape)\n",
    "z = jnp.linalg.slogdet(x)\n",
    "xs = [x, y]\n",
    "slogdets = [jnp.linalg.slogdet(x) for x in xs]\n",
    "sign_in, logdet = functools.reduce(\n",
    "      lambda a, b: (a[0]*b[0], a[1]+b[1]), slogdets)\n",
    "\n",
    "logdet.shape\n",
    "slogdets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import itertools\n",
    "\n",
    "# import jax\n",
    "# import jax.numpy as np\n",
    "# # Current convention is to import original numpy as \"onp\"\n",
    "# import numpy as onp\n",
    "\n",
    "# Sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Computes our network's output\n",
    "def net(params, x):\n",
    "    w1, b1, w2, b2 = params\n",
    "    hidden = np.tanh(np.dot(w1, x) + b1)\n",
    "    return sigmoid(np.dot(w2, hidden) + b2)\n",
    "\n",
    "# Cross-entropy loss\n",
    "def loss(params, x, y):\n",
    "    out = net(params, x)\n",
    "    cross_entropy = -y * np.log(out) - (1 - y)*np.log(1 - out)\n",
    "    return cross_entropy\n",
    "\n",
    "# Utility function for testing whether the net produces the correct\n",
    "# output for all possible inputs\n",
    "def test_all_inputs(inputs, params):\n",
    "    predictions = [int(net(params, inp) > 0.5) for inp in inputs]\n",
    "    for inp, out in zip(inputs, predictions):\n",
    "        print(inp, '->', out)\n",
    "    return (predictions == [onp.bitwise_xor(*inp) for inp in inputs])\n",
    "\n",
    "\n",
    "def initial_params():\n",
    "    return [\n",
    "        onp.random.randn(3, 2),  # w1\n",
    "        onp.random.randn(3),  # b1\n",
    "        onp.random.randn(3),  # w2\n",
    "        onp.random.randn(),  #b2\n",
    "    ]\n",
    "\n",
    "loss_grad = jax.grad(loss)\n",
    "\n",
    "# Stochastic gradient descent learning rate\n",
    "learning_rate = 1.\n",
    "# All possible inputs\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Initialize parameters randomly\n",
    "params = initial_params()\n",
    "\n",
    "for n in itertools.count():\n",
    "    # Grab a single random input\n",
    "    x = inputs[onp.random.choice(inputs.shape[0])]\n",
    "    # Compute the target output\n",
    "    y = onp.bitwise_xor(*x)\n",
    "    # Get the gradient of the loss for this input/output pair\n",
    "    grads = loss_grad(params, x, y)\n",
    "    # Update parameters via gradient descent\n",
    "    params = [param - learning_rate * grad\n",
    "              for param, grad in zip(params, grads)]\n",
    "    # Every 100 iterations, check whether we've solved XOR\n",
    "    if not n % 100:\n",
    "        print('Iteration {}'.format(n))\n",
    "        if test_all_inputs(inputs, params):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomness\n",
    "key = rnd.PRNGKey(1)\n",
    "print(key)\n",
    "key, subkey = rnd.split(key)\n",
    "print(key)\n",
    "print(subkey)\n",
    "key, *subkeys = rnd.split(key, num=3)\n",
    "print(key, subkeys)\n",
    "rnd.split(subkeys[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bias layer \n",
    "m = 2\n",
    "ne = 3\n",
    "v = 4\n",
    "data = rnd.normal(key, (m, ne, v))\n",
    "p = rnd.normal(key, (v + 1, v))\n",
    "print(data)\n",
    "bias = jnp.ones((*data.shape[:-1], 1))\n",
    "data = jnp.concatenate([data, bias], axis=-1)\n",
    "print(data.shape, p.shape)\n",
    "out = jnp.dot(data, p)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "recovered-emergency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10, 5, 10)\n"
     ]
    }
   ],
   "source": [
    "# jax einsum\n",
    "m, ne, v = 2, 5, 10\n",
    "key = rnd.PRNGKey(1)\n",
    "x = rnd.normal(key, (m, ne, v))\n",
    "y = rnd.normal(key, (m, ne, v))\n",
    "z = jnp.einsum('ijk,imn->jkmn', x, y)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block until ready only works on a single output\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "\n",
    "def slow_f(x):\n",
    "  # Element-wise ops see a large benefit from fusion\n",
    "  return x * x + x * 2.0, x\n",
    "\n",
    "x = jnp.ones((5000, 5000))\n",
    "%timeit slow_f(x).block_until_ready()\n",
    "\n",
    "fast_f = jit(slow_f)\n",
    "\n",
    "# Results are the same\n",
    "assert jnp.allclose(slow_f(x), fast_f(x))\n",
    "\n",
    "%timeit fast_f(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "# By default, jax.grad will find the gradient with respect to the first argument.\n",
    "# To find the gradient with respect to a different argument (or several), you can set argnums\n",
    "# jax.grad(sum_squared_error, argnums=(0, 1))(x, y)  # Find gradient wrt both x & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "victorian-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "re.shape\n",
    "x = jnp.repeat(re, 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "handmade-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-start",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
